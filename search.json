[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nMcKinney, Wes. 2010. “Data Structures for Statistical Computing in Python.” In Proceedings of the 9th Python in Science Conference, edited by Stéfan van der Walt and Jarrod Millman, 56–61. https://doi.org/10.25080/Majora-92bf1922-00a .\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "syllabus.html#class-meetings",
    "href": "syllabus.html#class-meetings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Class Meetings",
    "text": "Class Meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nLSN 111\nMon & Wed 3:30 - 4:45pm"
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Instructor",
    "text": "Instructor\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\nSergio Rey\nMon 9:00 - 10:00 (by appointment)\nPSFA 361G"
  },
  {
    "objectID": "syllabus.html#introduction",
    "href": "syllabus.html#introduction",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Introduction",
    "text": "Introduction\nWelcome to GEOG 385: Spatial Data Analysis!\nThe purpose of this course is to introduce you to methods of spatial data analysis. The focus is on both the conceptual and applied aspects of spatial statistical methods. We will place particular emphasis on the computational aspects of Exploratory Spatial Data Analysis (ESDA) methods for diﬀerent types of spatial data including point processes, lattice data, geostatistical data, network data, and spatial interaction. Throughout the course you will gain valuable hands-on experience with several specialized software packages for spatial data analysis. The overriding goal of the course is for you to acquire familiarity with the fundamental methodological and operational issues in the statistical analysis of geographic information and the ability to extend these methods in your own research.\nThe course takes an explicitly computational thinking approach to its pedagogy. Students are introduced to computational concepts and tools that are increasingly important to research that engages with geospatial data. By adopting these tools, students acquire a deeper engagement with, and mastery of, the substantive concepts. Put differently, students will learn to code. But this is a means to the end goal: students will code to learn spatial data analysis.\nIn the scope of a 15-week semester course we can only introduce a handful of the key concepts and methods relevant to the field of spatial data analysis. As such, the course is not intended as an exhaustive treatment. Instead, the goal is that students will acquire an understanding of the more common and useful methods and practices, and use the course as an entry point for further engagement with the field."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGEOG 101 or GEOG 102\nSTAT 250 or comparable course in statistics.\n\nAll students are required to complete the prerequisite assessment quiz before 2024-08-28 3:30pm."
  },
  {
    "objectID": "syllabus.html#computational-learning",
    "href": "syllabus.html#computational-learning",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Computational Learning",
    "text": "Computational Learning\nWe will be using open source geospatial software throughout the course together with Jupyter Notebooks, and Python as our scripting language.\nAll software for the course will be made available through JupyterHub, a web-based framework. Students wishing to install these materials on their own machines will be given instructions to do so, but this is not required."
  },
  {
    "objectID": "syllabus.html#readings",
    "href": "syllabus.html#readings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Readings",
    "text": "Readings\nAll required readings are available through the links listed below. Assigned readings should be completed before the date listed in the schedule (see below). Readings are a critical part of the discussions we will hold in class, and therefore being prepared for class means having completed the readings and thought about the content. It will be difficult to do well in this course without having completed the readings.\n\n\n\nAbbrevation\nSource\n\n\n\n\nGDA\nTenkanen, H., V. Heikinheimo, D. Whipp (2023) Python for Geographic Data Analysis. CRC Press.\n\n\nGDS\nRey, S.J., D. Arribas-Bel, L.J. Wolf (2023) Geographic Data Science with Python. CRC Press."
  },
  {
    "objectID": "syllabus.html#schedule-planned",
    "href": "syllabus.html#schedule-planned",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Schedule (Planned)",
    "text": "Schedule (Planned)\n\n\n\nWeek\nDate\nTopic\nReading\nDue\n\n\n\n\n1\n8-26\nIntroduction\n\nPrerequisite Quiz\n\n\n\n8-28\nJupyter\n\n\n\n\n2\n9-02\nLabor Day (Holiday)\n\n\n\n\n\n9-04\nPandas\nGDA 3\n\n\n\n3\n9-09\nSpatial Data Analysis\nGDS 1\n\n\n\n\n9-11\nGeopandas\nGDA 6\n\n\n\n4\n9-16\nArea Unit Data\nGDS 3\nTopic Approval\n\n\n\n9-18\nGeoprocessing: Area Units\nGDA 6\n\n\n\n5\n9-23\nVisualizing Area Unit Data\nGDS 5\nPython Primer\n\n\n\n9-25\nChoropleth Mapping\n\n\n\n\n6\n9-30\nSpatial Weights\nGDS 4\nProject Proposal\n\n\n\n10-02\nNeighbor Relations\n\nPeer Evaluation 1\n\n\n7\n10-07\nGlobal Spatial Autocorrelation\nGDS 6\n\n\n\n\n10-09\nTesting for Clustering\n\n\n\n\n8\n10-14\nLocal Spatial Autocorrelation\nGDS 7\nData Acquisition\n\n\n\n10-16\nCluster Detection\n\nPeer Evaluation 2\n\n\n9\n10-21\nClustering Area Unit Data\nGDS 10\n\n\n\n\n10-23\nRegion Building\n\n\n\n\n10\n10-28\nPoint Pattern Data\nGDS 8.1\n\n\n\n\n10-30\nGeoprocessing: Points\n\n\n\n\n11\n11-04\nCentrography\nGDS8.2\nData Visualization\n\n\n\n11-06\nDescribing Point Patterns\n\nPeer Evaluation 3\n\n\n12\n11-11\nVeteran’s Day (Holiday)\n\n\n\n\n\n11-13\nPoint Process Simulation\nGDS 8.3\n\n\n\n13\n11-18\nNearest Neighbor Statistics\n\nData Analysis\n\n\n\n11-20\nTesting for Randomness\n\nPeer Evaluation 4\n\n\n14\n11-25\nDistance Based Statistics\n\n\n\n\n\n11-27\nThanksgiving (Holiday)\n\n\n\n\n15\n12-02\nClustering Point Pattern Data\n\nNarrative\n\n\n\n12-04\nDBScan\n\n\n\n\n16\n12-09\nIntegrating Point and Area Data\n\n\n\n\n\n12-11\nGeoprocessing: Synthesis\n\nComputational Notebook\n\n\n17\n12-18\nFinal Presentations (1-3pm)"
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Grading",
    "text": "Grading\nGEOG 385 uses specification grading in evaluating student work and in determining your final course grade. Your course grade will be based on the quality and quantity of the work that you submit that is evaluated to be of an acceptable level of quality. The acceptable level of quality demonstrates competency in the concepts and methods covered in the course.\nThere is a two-step process for determination of your final course grade at the end of the quarter:\n\nUsing your quizzes and exercises, your base grade is determined.\nUsing your final exam results, determine if your base grade includes a \"plus\", \"minus\", or level drop to form the course grade.\n\n\nBase Grade\nFor Step 1, the base grade is determined using the following specification:\n\n\n\nLevel\nThresholds\n\n\n\n\nA-\nAll the B- Thresholds\n\n\n\nPass 11 or more reading quizzes\n\n\n\nParticipate in 12 or more studios\n\n\n\nComplete 4 peer evaluations\n\n\n\nPresentation of Computational Essay\n\n\nB-\nAll the C- Thresholds\n\n\n\nPass 9 or more reading quizzes\n\n\n\nParticipate in 8 or more studios\n\n\n\nComplete 3 peer evaluations\n\n\n\nComputational Essay\n\n\nC-\nAll the D- Thresholds\n\n\n\nPass 6 or more reading quizzes\n\n\n\nParticipate in 6 or more studios\n\n\n\nComplete 2 peer evaluations\n\n\nD-\nPass 4 or more reading quizzes\n\n\n\nParticipate in 4 or more studios\n\n\n\nComplete 1 peer evaluation\n\n\nF\nFailing to clear all the D- Thresholds\n\n\n\n\n\nFinal Grade\nFor Step 2, your final course grade is determined as follows:\nIf your base grade is not an A-:\n\n2 tokens can increment a B(C,D)- to a B(CD)\n3 tokens can increment a B(C,D)- to a B(CD)+\n\nIf your base grade is an A-:\n\n2 tokens increments an A- to an A\n3 tokens increments an A- to an A and earns a recommendation certificate\n\n\n\n\n\n\n\nNote\n\n\n\nNote that SDSU grading policy does not allow A+ grades."
  },
  {
    "objectID": "syllabus.html#quizzes",
    "href": "syllabus.html#quizzes",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Quizzes",
    "text": "Quizzes\nStarting in week three, there will be a quiz due before a session that pertains to the background reading that is required before our work in class. Quizzes are graded on a pass/fail basis."
  },
  {
    "objectID": "syllabus.html#studio-participation",
    "href": "syllabus.html#studio-participation",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Studio Participation",
    "text": "Studio Participation\nEach Wednesday, we will focus on hands-on exercises that explore the material from lecture. Each student will be assigned to a small group that works together to carry out a set of spatial data analysis tasks. At the end of the session each group will submit a single notebook demonstrating their work.\nEach notebook is graded using a CRN rubric that classifies work with marks of C (\"Demonstrates Competence\"), R (\"Needs Revision\"), or N (\"Not assessable\"):\nOf each notebook the following questions will be asked: Does the work demonstrate that the student understands the concepts? Does the work demonstrate competence and meet the expectations outlined in the exercise?\nIf the answer is \"yes\" to both of the questions, the group passes the hurdle for that studio.\nIf the initial submission does not clear the hurdle, then a second question is asked: Is there evidence of partial understanding of the concepts? If the answer to this question is \"Yes\" the group can exchange one token (from each student) to attempt a revision of their work. If the answer is \"No\", the group does not clear the hurdle for this exercise and will not have the opportunity to revise their work.\nFor our studio sessions on Wednesdays, it is essential that you bring your own device, such as a laptop or tablet. These sessions will involve hands-on activities that require access to software and online resources. Having your own device will allow you to fully participate and engage with the exercises. Please ensure your device is charged and ready to use at the start of each studio session. If you have any concerns about this requirement, please reach out to me in advance so we can make necessary arrangements."
  },
  {
    "objectID": "syllabus.html#computational-essay",
    "href": "syllabus.html#computational-essay",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Computational Essay",
    "text": "Computational Essay\nEach student will have the opportunity to write a computational essay using Jupyter notebooks to apply the methods of ESDA to a topic of their choice, approved by the instructor. The essay should demonstrate your ability to analyze spatial data, identify patterns, and interpret the results using ESDA techniques.\n\nInstructions\n\n1. Topic Selection\nSelect a topic of interest that involves spatial data. The topic should be relevant to your field of study or personal interest. Ensure that the data is accessible and suitable for spatial analysis. Submit your topic for approval by the instructor by September 16. If you are unsure about a topic, speak to the professor.\n\n\n2. Data Acquisition\nIdentify and acquire spatial data related to your chosen topic. This may include data from public repositories, government databases, or other reliable sources.\n\n\n3. ESDA Techniques\nApply appropriate ESDA methods such as spatial autocorrelation, clustering, and visualization techniques to explore your data. Use libraries like PySAL, GeoPandas, or others as needed.\n\n\n4. Analysis and Interpretation\nDocument your analysis in a Jupyter notebook. Include clear explanations of the methods used, the rationale behind your choices, and a discussion of your findings. Visualizations should be integrated into the narrative to support your analysis.\n\n\n5. Submission\nSubmit your Jupyter notebook along with a brief (500-word) reflection on what you learned from the analysis and how ESDA techniques enhanced your understanding of the topic. At submission you can indicate whether you wish to present your computational essay during the final period.\n\n\n\n\n\n\nImportant\n\n\n\nYou must demonstrate competency on each of the stages above to have the computational essay count towards your base grade.\n\n\n\n\n\nDeadline\nSubmit your completed essay by December 12, Midnight."
  },
  {
    "objectID": "syllabus.html#final-exam-activity",
    "href": "syllabus.html#final-exam-activity",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Final Exam Activity",
    "text": "Final Exam Activity\nOur final exam activity is scheduled for December 18 from 1-3pm. Students who applied to submit their computational essay will present during this period."
  },
  {
    "objectID": "syllabus.html#sec-tokens",
    "href": "syllabus.html#sec-tokens",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Tokens",
    "text": "Tokens\nEach student is provided with three tokens at the beginning of the semester.\n\nUsing Tokens\n\nCredit for a reading quiz that was failed (1 token).\nObtaining a one-day extension for a milestone prior to due date (1 token).\nHanding in a milestone activity one day late without permission (2 tokens).\nRevising a milestone that was submitted on-time but evaluated as \"Needing Revision\" (1 token).\nRevising a studio exercise that needs revision (1 token).\nRequesting a make-up date for the presentation by 2024-12-01 17:00 (3 tokens)\nMissing a studio session (3 tokens).\nAny tokens remaining after determination of the base grade will be used to determine the final course grade (see above).\n\nTo use a token you must complete a request using the token spending form.\n\n\nEarning Tokens\nAdditional tokens can be earned in several ways:\n\nSubmitting topics for discussion in lectures in our board\nAttending an in-person office hour to discuss a proposed question/topic\nAttending a geography colloquium (write a paragraph description)\nCompleting the python primer (3 tokens)"
  },
  {
    "objectID": "syllabus.html#policies",
    "href": "syllabus.html#policies",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Policies",
    "text": "Policies\n\nAccommodations\nIf you are a student with a disability and are in need of accommodations for this class, please contact Student Ability Success Center at (619) 594-6473 as soon as possible. Please know accommodations are not retroactive, and I cannot provide accommodations based upon disability until I have received an accommodation letter from Student Ability Success Center.\n\n\nPrivacy and Intellectual Property\nStudent Privacy and Intellectual Property: The Family Educational Rights and Privacy Act (FERPA) mandates the protection of student information, including contact information, grades, and graded assignments. I will use Canvas to communicate with you, and I will not post grades or leave graded assignments in public places. Students will be notified at the time of an assignment if copies of student work will be retained beyond the end of the semester or used as examples for future students or the wider public. Students maintain intellectual property rights to work products they create as part of this course unless they are formally notified otherwise.\n\n\nAcademic Integrity\nThe SDSU student academic integrity policy lists violations in detail. These violations fall into eight broad areas that include but are not limited to: cheating, fabrication, plagiarism, facilitating academic misconduct, unauthorized collaboration, interference or sabotage, non-compliance with research regulations and retaliation. For more information about the SDSU student academic integrity policy, please see the following: https://sacd.sdsu.edu/student-rights/academic-dishonesty.\n\n\nCode of Conduct\nAs course instructor, I am dedicated to providing a harassment-free learning experience for all students, regardless of gender, sexual orientation, disability, physical appearance, body size, race, religion, or choice of operating system. All course participants are expected to show respect and courtesy to other students throughout the semester. As a learning community we do not tolerate harassment of participants in any form.\n\nAll communication should be appropriate for a professional audience including people of many different backgrounds. Sexual language and imagery are not appropriate in this course.\nBe kind to others. Do not insult or put down other students. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are not appropriate for this course.\nStudents violating these rules may be asked to leave the course, and their violations will be reported to the SDSU administration.\n\nThis code of conduct is an adaptation of the SciPy 2018 Code of Conduct."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Home",
    "section": "",
    "text": "This course will take you through 15 weeks of engaging lectures and hands-on studios, designed to give you practical experience in Spatial Data Analysis .\nUse the sidebar to navigate through the weekly content.\n\n\nPlease refer to the course syllabus for detailed information on course structure, grading, and policies."
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Course Home",
    "section": "",
    "text": "Please refer to the course syllabus for detailed information on course structure, grading, and policies."
  },
  {
    "objectID": "lectures/week01/index.html",
    "href": "lectures/week01/index.html",
    "title": "Week 1 Lecture: Course Overview",
    "section": "",
    "text": "In this first lecture we will provide an overview of the course.",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/index.html#syllabus",
    "href": "lectures/week01/index.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/index.html#spatial-data-analysis",
    "href": "lectures/week01/index.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week01/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week01/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#eda-approach",
    "href": "lectures/week01/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week01/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#historical-context",
    "href": "lectures/week01/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#snow-map",
    "href": "lectures/week01/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#snow-map-1",
    "href": "lectures/week01/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week01/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#vector-data",
    "href": "lectures/week01/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#vector-data-1",
    "href": "lectures/week01/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#raster-data",
    "href": "lectures/week01/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#raster-data-1",
    "href": "lectures/week01/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#attribute-data",
    "href": "lectures/week01/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#attribute-data-1",
    "href": "lectures/week01/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week01/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week01/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#remote-sensing",
    "href": "lectures/week01/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week01/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week01/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week01/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week01/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week01/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week01/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week01/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week01/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week01/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#questions",
    "href": "lectures/week01/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#references",
    "href": "lectures/week01/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "lectures/week03/index.html",
    "href": "lectures/week03/index.html",
    "title": "Week 3 Lecture: Spatial Data Analysis",
    "section": "",
    "text": "lecture",
    "crumbs": [
      "Home",
      "09-09 Spatial Data Analysis"
    ]
  },
  {
    "objectID": "lectures/week03/index.html#spatial-data-analysis",
    "href": "lectures/week03/index.html#spatial-data-analysis",
    "title": "Week 3 Lecture: Spatial Data Analysis",
    "section": "",
    "text": "lecture",
    "crumbs": [
      "Home",
      "09-09 Spatial Data Analysis"
    ]
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week03/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week03/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#eda-approach",
    "href": "lectures/week03/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week03/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#historical-context",
    "href": "lectures/week03/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#snow-map",
    "href": "lectures/week03/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#snow-map-1",
    "href": "lectures/week03/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week03/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#vector-data",
    "href": "lectures/week03/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#vector-data-1",
    "href": "lectures/week03/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#raster-data",
    "href": "lectures/week03/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#raster-data-1",
    "href": "lectures/week03/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#attribute-data",
    "href": "lectures/week03/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#attribute-data-1",
    "href": "lectures/week03/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week03/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week03/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#remote-sensing",
    "href": "lectures/week03/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week03/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week03/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week03/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week03/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week03/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week03/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week03/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week03/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week03/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#questions",
    "href": "lectures/week03/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#references",
    "href": "lectures/week03/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "studio/python_course.html",
    "href": "studio/python_course.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "studio/python_course.html#instructions",
    "href": "studio/python_course.html#instructions",
    "title": "",
    "section": "Instructions",
    "text": "Instructions\n\nGo to http://www.codeacademy.com and create a free account, or sign in with a social media or GitHub account.\nTake the self-paced entry-level minicourse on Python 2.3\nThe minicourse has 12 units, each with 1-2 lessons to be done in a browser. Complete the first 9 units of the course, up to and including “Exam Statistics.”\n\n\n\n\n\n\n\nTime Requirements\n\n\n\nCompleting this primer should take between 6-8 hours. You should spread out your effort in 30-minute chunks over a few weeks."
  },
  {
    "objectID": "studio/python_course.html#submission-due-september-23-330-pm",
    "href": "studio/python_course.html#submission-due-september-23-330-pm",
    "title": "",
    "section": "Submission (Due: September 23, 3:30 PM)",
    "text": "Submission (Due: September 23, 3:30 PM)\nWhen you have completed the nine units, take a screenshot that shows your name on the screen as well as all the checks. Upload the screenshot to Canvas."
  },
  {
    "objectID": "studio/python_course.html#footnotes",
    "href": "studio/python_course.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe Python Primer is inspired by and modeled after the work of Robert Talbert.↩︎\nIf you are interested in further exploring Python for geography, an excellent course is Geog 383.↩︎\nDo not sign up for the Python 3 course as it is not free. We will cover the main differences between Python 2 and Python 3 in the studio sessions.↩︎"
  },
  {
    "objectID": "studio/week01/index.html",
    "href": "studio/week01/index.html",
    "title": "Studio 1: Jupyter Hub",
    "section": "",
    "text": "In this first studio session, we will do three things:\n\nGet started with Jupyter Hub\nSet up collaboration in studios\nCollaborate on our first studio activity",
    "crumbs": [
      "Home",
      "08-28 Studio 1: Jupyter Hub"
    ]
  },
  {
    "objectID": "studio/week01/jupyter.html",
    "href": "studio/week01/jupyter.html",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "",
    "text": "In this exercise, you will practice basic operations in Jupyter notebooks, including writing and running Python code, working with Markdown cells, and performing simple data operations."
  },
  {
    "objectID": "studio/week01/jupyter.html#setting-up-the-notebook",
    "href": "studio/week01/jupyter.html#setting-up-the-notebook",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "1. Setting Up the Notebook",
    "text": "1. Setting Up the Notebook\n\nCreate a new notebook.\nRename it to GroupX.ipynb where X is your group number.\n\nAdd some structure at the top cells:\n# Group Exercise 1\n\nThis notebook is for practicing basic operations in Jupyter notebooks. It includes examples of using Python code and Markdown cells to document the work.\nAdd a subsection with the name Team and underneath the subsection add a bulleted list with the names of the team members.\nPut the leader’s name in bold.\nAdd a second subsection that contains a second bulleted list. Give the subsection the title Links In this list add a link to a site that each group member suggests as interesting to the class."
  },
  {
    "objectID": "studio/week01/jupyter.html#basic-code-operations",
    "href": "studio/week01/jupyter.html#basic-code-operations",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "2. Basic Code Operations",
    "text": "2. Basic Code Operations\nIn this section, you’ll write and run some simple Python code.\n# Task 1: Print a welcome message\nprint(\"Welcome to JupyterHub!\")\n# Task 2: Perform a simple arithmetic operation\n10 * 3\nprint(f'The value 10 * 3 is equal to {10 * 3}')\nRun these cells, and explore what happens as you change some of the values.\nCreate some new code cells that extend on these ideas."
  },
  {
    "objectID": "studio/week01/jupyter.html#working-with-data",
    "href": "studio/week01/jupyter.html#working-with-data",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "3. Working with Data",
    "text": "3. Working with Data\nIn this section, you’ll work with a small dataset.\n\nLoad and Display the Dataset\ndata = [100, 20, 90, 40, 50, 30, 10]\n\n# Display the dataset\ndata\n\n\nPerform a Basic Analysis\n# Task: Calculate the sum of the numbers in the dataset\nsum(data)\n# Task: Calculate the mean of the numbers in the dataset\nmean_value = sum(data) / len(data)\nmean_value\nHow would you sort the data using python? Show your answer in a code cell.\nAs a group, come up with an answer to the questions: Is the data skewed? If so, in what way? Add Markdown cells that describe your reasoning used to come up with your answers."
  },
  {
    "objectID": "studio/week01/jupyter.html#documenting-the-analysis",
    "href": "studio/week01/jupyter.html#documenting-the-analysis",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "4. Documenting the Analysis",
    "text": "4. Documenting the Analysis\nUse Markdown cells to document your code and results. For example:\n## Dataset Analysis\n\nWe loaded a dataset containing the numbers 10, 20, 30, 40, 50, 90, 100. Below is the sum and mean of these numbers.\n\nWith regard to skewness, we find ...."
  },
  {
    "objectID": "studio/week01/jupyter.html#final-touches-and-submission",
    "href": "studio/week01/jupyter.html#final-touches-and-submission",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "5. Final Touches and Submission",
    "text": "5. Final Touches and Submission\nReview your notebook as a group. Ensure that it is well-organized and the code is properly documented. Use the ability to move cells around to reorganize as needed.\nOnce done, save your notebook as a pdf.\nHave the group leader turn the pdf in on canvas."
  },
  {
    "objectID": "studio/week02/pandas.html",
    "href": "studio/week02/pandas.html",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "In this notebook we introduce pandas (McKinney 2010) which is the main package for working with data in Python."
  },
  {
    "objectID": "studio/week02/pandas.html#introduction",
    "href": "studio/week02/pandas.html#introduction",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "In this notebook we introduce pandas (McKinney 2010) which is the main package for working with data in Python."
  },
  {
    "objectID": "studio/week02/pandas.html#import",
    "href": "studio/week02/pandas.html#import",
    "title": "Introduction to Pandas",
    "section": "Import",
    "text": "Import\nWe start by importing the package, and aliasing it as pd\n\nimport pandas as pd\n\nAliasing allows us to use pd in place of having to type out pandas in what follows."
  },
  {
    "objectID": "studio/week02/pandas.html#dataframe-creation",
    "href": "studio/week02/pandas.html#dataframe-creation",
    "title": "Introduction to Pandas",
    "section": "DataFrame Creation",
    "text": "DataFrame Creation\nPandas main data structure is called a DataFrame. We will create our first DataFrame by reading a csv file.\n\n1home = \"/home/serge\"\ncities_df = pd.read_csv(f\"{home}/data/385/studio02/cities.csv\")\n\n\n1\n\nChange the value home to be equal to jupyter-student where student is your id.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe sure to reread the instructions to change the path in the previous cell if you wish to follow along in your own notebook.\n\n\nAsking for the values of the cities_df give us:\n\ncities_df\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\n\n\n\n\n\n\n\nThis data set is composed of the capital cities for the 50 states.\nWe can see what type of object cities_df is using type:\n\ntype(cities_df)\n\npandas.core.frame.DataFrame\n\n\nAs an analogy, you can think of a DataFrame as a spreadsheet with rows and columns. This mental model will help to orient you. We will see that the DataFrame extends spreadsheets in powerful ways for data analysis.\nA DataFrame, like most Python objects, has a number of attributes and methods.\nIts shape attribute tells us how many observations and variables we have.\n\ncities_df.shape\n\n(50, 4)\n\n\nIn this case our data set has 50 observations on 4 variables."
  },
  {
    "objectID": "studio/week02/pandas.html#series",
    "href": "studio/week02/pandas.html#series",
    "title": "Introduction to Pandas",
    "section": "Series",
    "text": "Series\nEach variable is stored as a Series:\n\ntype(cities_df.longitude)\n\npandas.core.series.Series\n\n\n\ncities_df.longitude\n\n0     -86.300568\n1    -134.420212\n2    -112.096962\n3     -92.288986\n4    -121.493629\n5    -104.984856\n6     -72.682198\n7     -75.519722\n8    -157.857376\n9     -84.281296\n10    -84.388229\n11   -116.199722\n12    -89.654961\n13    -86.162643\n14    -93.603729\n15    -95.677956\n16    -84.875374\n17    -91.187393\n18    -69.781693\n19    -76.490936\n20    -71.063698\n21    -84.555328\n22    -93.102211\n23    -90.182106\n24    -92.172935\n25   -112.018417\n26    -96.699654\n27   -119.766121\n28    -71.537994\n29    -74.769913\n30   -105.939728\n31    -78.639099\n32   -100.783318\n33    -73.757874\n34    -82.999069\n35    -97.503342\n36   -123.030403\n37    -76.883598\n38    -71.414963\n39    -81.033211\n40   -100.346405\n41    -86.784241\n42    -97.740349\n43   -111.888237\n44    -72.580536\n45    -77.433640\n46   -122.905014\n47    -81.612328\n48    -89.384445\n49   -104.820236\nName: longitude, dtype: float64\n\n\nWhen we ask for the contents of the series, we see two columns of numbers. The first is a set of integers which is the index. Each value in the index locates the particular observation in the series.\nThe next column of values stores the values of the series. Here the values are decimal degrees of longitude for the capital cities."
  },
  {
    "objectID": "studio/week02/pandas.html#data-types",
    "href": "studio/week02/pandas.html#data-types",
    "title": "Introduction to Pandas",
    "section": "Data Types",
    "text": "Data Types\nThe info method of the DataFrame will summarize information about our DataFrame\n\ncities_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50 entries, 0 to 49\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   name         50 non-null     object \n 1   description  50 non-null     object \n 2   latitude     50 non-null     float64\n 3   longitude    50 non-null     float64\ndtypes: float64(2), object(2)\nmemory usage: 1.7+ KB\n\n\nWe have four columns, the first two of which are of type object and the last two are of type float64.\nThe names of our variables in the DataFrame are stored in the columns attribute:\n\ncities_df.columns\n\nIndex(['name', 'description', 'latitude', 'longitude'], dtype='object')\n\n\nWe can use the column name to access the particular series:\n\ncities_df.longitude\n\n0     -86.300568\n1    -134.420212\n2    -112.096962\n3     -92.288986\n4    -121.493629\n5    -104.984856\n6     -72.682198\n7     -75.519722\n8    -157.857376\n9     -84.281296\n10    -84.388229\n11   -116.199722\n12    -89.654961\n13    -86.162643\n14    -93.603729\n15    -95.677956\n16    -84.875374\n17    -91.187393\n18    -69.781693\n19    -76.490936\n20    -71.063698\n21    -84.555328\n22    -93.102211\n23    -90.182106\n24    -92.172935\n25   -112.018417\n26    -96.699654\n27   -119.766121\n28    -71.537994\n29    -74.769913\n30   -105.939728\n31    -78.639099\n32   -100.783318\n33    -73.757874\n34    -82.999069\n35    -97.503342\n36   -123.030403\n37    -76.883598\n38    -71.414963\n39    -81.033211\n40   -100.346405\n41    -86.784241\n42    -97.740349\n43   -111.888237\n44    -72.580536\n45    -77.433640\n46   -122.905014\n47    -81.612328\n48    -89.384445\n49   -104.820236\nName: longitude, dtype: float64\n\n\n\ncities_df.name\n\n0            Alabama\n1             Alaska\n2            Arizona\n3           Arkansas\n4         California\n5           Colorado\n6        Connecticut\n7           Delaware\n8             Hawaii\n9            Florida\n10           Georgia\n11             Idaho\n12          Illinois\n13           Indiana\n14              Iowa\n15            Kansas\n16          Kentucky\n17         Louisiana\n18             Maine\n19          Maryland\n20     Massachusetts\n21          Michigan\n22         Minnesota\n23       Mississippi\n24          Missouri\n25           Montana\n26          Nebraska\n27            Nevada\n28     New Hampshire\n29        New Jersey\n30        New Mexico\n31    North Carolina\n32      North Dakota\n33          New York\n34              Ohio\n35          Oklahoma\n36            Oregon\n37      Pennsylvania\n38      Rhode Island\n39    South Carolina\n40      South Dakota\n41         Tennessee\n42             Texas\n43              Utah\n44           Vermont\n45          Virginia\n46        Washington\n47     West Virginia\n48         Wisconsin\n49           Wyoming\nName: name, dtype: object\n\n\nAs each series is an object, it too comes with attributes and methods:\n\ncities_df.longitude.max()\n\nnp.float64(-69.781693)\n\n\n\ncities_df.name.max()\n\n'Wyoming'\n\n\n\ncities_df.longitude.mean()\n\nnp.float64(-93.46593707999999)\n\n\n\ncities_df.name.min()\n\n'Alabama'\n\n\n\ncities_df.longitude.describe()\n\ncount     50.000000\nmean     -93.465937\nstd       18.669710\nmin     -157.857376\n25%     -103.811006\n50%      -89.918533\n75%      -79.237627\nmax      -69.781693\nName: longitude, dtype: float64\n\n\n\ncities_df.name.describe()\n\ncount          50\nunique         50\ntop       Alabama\nfreq            1\nName: name, dtype: object\n\n\nNote how the same method behaves for series of different types."
  },
  {
    "objectID": "studio/week02/pandas.html#creating-new-series",
    "href": "studio/week02/pandas.html#creating-new-series",
    "title": "Introduction to Pandas",
    "section": "Creating new series",
    "text": "Creating new series\nA common workflow in data analysis is to create, or derive, new variables based upon existing variables. For example, let’s define a variable that will denote whether a capital city is in the east or west of the country. Here we will use the median longitude as the comparison point:\n\ncities_df.longitude.median()\n\nnp.float64(-89.9185335)\n\n\n\ncities_df.longitude &lt; cities_df.longitude.median()\n\n0     False\n1      True\n2      True\n3      True\n4      True\n5      True\n6     False\n7     False\n8      True\n9     False\n10    False\n11     True\n12    False\n13    False\n14     True\n15     True\n16    False\n17     True\n18    False\n19    False\n20    False\n21    False\n22     True\n23     True\n24     True\n25     True\n26     True\n27     True\n28    False\n29    False\n30     True\n31    False\n32     True\n33    False\n34    False\n35     True\n36     True\n37    False\n38    False\n39    False\n40     True\n41    False\n42     True\n43     True\n44    False\n45    False\n46     True\n47    False\n48    False\n49     True\nName: longitude, dtype: bool\n\n\nThis creates a series that has data type bool, meaning True if the city is at a longitude less than that of the median longitude. False if it is east of that value. We can use this information to create a new series on the DataFrame called east:\n\ncities_df['east'] = cities_df.longitude &gt; cities_df.longitude.median()\n\nAnd, we can do this for a second variable south:\n\ncities_df['south'] = cities_df.latitude &lt; cities_df.latitude.median()\n\nBased on those two Boolean variables we can create an additional variable called region that tells us which of four regions the capital city is located in.\n\ncities_df['region'] = 4 * cities_df.east * cities_df.south + 3 * (1 - cities_df.east) * cities_df.south \\\n                      + 2 * (1-cities_df.east) * (1-cities_df.south) + cities_df.east * (1-cities_df.south)\n\nregion takes on four values, 1 if the city is in the North East, 2 North West, 3 South West, and 4 South East.\n\ncities_df.head(20)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\n4\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\n2\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\n3\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\n3\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\n3\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\n3\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\n1\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\n4\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\n3\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\n4\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\n4\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\n2\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\n1\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\n4\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\n2\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\n3\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\n4\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\n3\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\n1\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\n4"
  },
  {
    "objectID": "studio/week02/pandas.html#plotting",
    "href": "studio/week02/pandas.html#plotting",
    "title": "Introduction to Pandas",
    "section": "Plotting",
    "text": "Plotting\nPandas comes with built-in plotting facilities. We can try out the default plot method:\n\ncities_df.plot('longitude', 'latitude')\n\n\n\n\n\n\n\n\nThis isn’t quite what we want as the default is to plot the first series and the second series together with line segments connecting each pair of sequential observations.\nBut we can try a different method to get what we want:\n\ncities_df.plot.scatter('longitude', 'latitude')\n\n\n\n\n\n\n\n\nThat’s better as now we see the cities represented as points.\n\n\n\n\n\n\nWarning\n\n\n\nWe are treating longitude and latitude as Cartesian coordinates in the plots. This is technically not correct as they are spherical coordinates. We will correct this later on in the course when we get to spatial data analysis proper.\n\n\nThere are a number of powerful visualization packages in Python that allow us to go beyond what is available in Pandas. To see one of them here, we import seaborn\n\nimport seaborn as sbn\n\nand redo our plot:\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude');\n\n\n\n\n\n\n\n\nSo far, not much difference from what we did with pandas. But we can specify a hue variable to distinguish what region the cities are in:\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude', hue='region');\n\n\n\n\n\n\n\n\nGreat. But the numbers on the legend are not that informative. Let’s change them:\n\ncities_df.region.map({1:'NE', 2:'NW', 3:'SW', 4:'SE'})\n\n0     SE\n1     NW\n2     SW\n3     SW\n4     SW\n5     SW\n6     NE\n7     SE\n8     SW\n9     SE\n10    SE\n11    NW\n12    NE\n13    SE\n14    NW\n15    SW\n16    SE\n17    SW\n18    NE\n19    SE\n20    NE\n21    NE\n22    NW\n23    SW\n24    SW\n25    NW\n26    NW\n27    SW\n28    NE\n29    NE\n30    SW\n31    SE\n32    NW\n33    NE\n34    NE\n35    SW\n36    NW\n37    NE\n38    NE\n39    SE\n40    NW\n41    SE\n42    SW\n43    NW\n44    NE\n45    SE\n46    NW\n47    SE\n48    NE\n49    NW\nName: region, dtype: object\n\n\n\ncities_df['region'] = cities_df.region.map({1:'NE', 2:'NW', 3:'SW', 4:'SE'})\n\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude', hue='region');\n\n\n\n\n\n\n\n\nMuch better.\n\ncities_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW"
  },
  {
    "objectID": "studio/week02/pandas.html#dataframe-operations",
    "href": "studio/week02/pandas.html#dataframe-operations",
    "title": "Introduction to Pandas",
    "section": "DataFrame Operations",
    "text": "DataFrame Operations\nPandas has a number of powerful methods that allow us to manipulate the DataFrame in interesting ways. Here we look at three:\n\nsorting\ngrouping\nfiltering\n\n\nSorting\nWe can sort the DataFrame by the values of a given column. For example, to find the southern-most capital city:\n\ncities_df.sort_values(by='latitude')\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n\n\n\n\n\nTo find the northern-most city:\n\ncities_df.sort_values(by='latitude', ascending=False)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n\n\n\n\n\n\n\nIf we don’t want to see all the other columns, we can subset the dataframe first:\n\ncities_df[['name', 'description', 'latitude']].sort_values(by='latitude', ascending=False)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n\n\n46\nWashington\nOlympia\n47.035805\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n\n\n25\nMontana\nHelena\n46.585709\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n\n\n36\nOregon\nSalem\n44.938461\n\n\n40\nSouth Dakota\nPierre\n44.367031\n\n\n18\nMaine\nAugusta\n44.307167\n\n\n44\nVermont\nMontpelier\n44.262436\n\n\n11\nIdaho\nBoise\n43.617775\n\n\n28\nNew Hampshire\nConcord\n43.206898\n\n\n48\nWisconsin\nMadison\n43.074684\n\n\n21\nMichigan\nLansing\n42.733635\n\n\n33\nNew York\nAlbany\n42.652843\n\n\n20\nMassachusetts\nBoston\n42.358162\n\n\n38\nRhode Island\nProvidence\n41.830914\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n\n\n14\nIowa\nDes Moines\n41.591087\n\n\n49\nWyoming\nCheyenne\n41.140259\n\n\n26\nNebraska\nLincoln\n40.808075\n\n\n43\nUtah\nSalt Lake City\n40.777477\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n\n\n29\nNew Jersey\nTrenton\n40.220596\n\n\n34\nOhio\nColumbus\n39.961346\n\n\n12\nIllinois\nSpringfield\n39.798363\n\n\n13\nIndiana\nIndianapolis\n39.768623\n\n\n5\nColorado\nDenver\n39.739227\n\n\n27\nNevada\nCarson City\n39.163914\n\n\n7\nDelaware\nDover\n39.157307\n\n\n15\nKansas\nTopeka\n39.048191\n\n\n19\nMaryland\nAnnapolis\n38.978764\n\n\n24\nMissouri\nJefferson City\n38.579201\n\n\n4\nCalifornia\nSacramento\n38.576668\n\n\n47\nWest Virginia\nCharleston\n38.336246\n\n\n16\nKentucky\nFrankfort\n38.186722\n\n\n45\nVirginia\nRichmond\n37.538857\n\n\n41\nTennessee\nNashville\n36.165810\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n\n\n3\nArkansas\nLittle Rock\n34.746613\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n\n\n2\nArizona\nPhoenix\n33.448143\n\n\n0\nAlabama\nMontgomery\n32.377716\n\n\n23\nMississippi\nJackson\n32.303848\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n\n\n9\nFlorida\nTallahassee\n30.438118\n\n\n42\nTexas\nAustin\n30.274670\n\n\n8\nHawaii\nHonolulu\n21.307442\n\n\n\n\n\n\n\n\n\nGrouping\nThe groupby method of the DataFrame allows us to split the dataframe, apply a function, and combine the results. This allows us to group data in interesting ways.\nSuppose we wanted to know how many cities were in the east and west?\n\ncities_df.groupby(by='east').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\nsouth\nregion\n\n\neast\n\n\n\n\n\n\n\n\n\n\nFalse\n25\n25\n25\n25\n25\n25\n\n\nTrue\n25\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\nAnd for south and north:\n\ncities_df.groupby(by='south').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nregion\n\n\nsouth\n\n\n\n\n\n\n\n\n\n\nFalse\n25\n25\n25\n25\n25\n25\n\n\nTrue\n25\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\nHow about by region?\n\ncities_df.groupby(by='region').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\n\n\nregion\n\n\n\n\n\n\n\n\n\n\nNE\n13\n13\n13\n13\n13\n13\n\n\nNW\n12\n12\n12\n12\n12\n12\n\n\nSE\n12\n12\n12\n12\n12\n12\n\n\nSW\n13\n13\n13\n13\n13\n13\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs we will see later in the course, there are different notions of a spatial median. This will unravel the mystery of why we have equal numbers of cities in the north and south, and east and west, but not in the four regions.\n\n\nIn addition to applying the count method on the groubby object, we could use other functions. For example, we may want to know the median coordinate values in each of the four regions:\n\ncities_df[['region', 'longitude', 'latitude']].groupby(by='region').median()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\n\n\nregion\n\n\n\n\n\n\nNE\n-73.757874\n42.358162\n\n\nNW\n-108.354236\n44.652746\n\n\nSE\n-82.946812\n36.852334\n\n\nSW\n-97.740349\n35.492207\n\n\n\n\n\n\n\n\n\nFiltering\nFiltering allows us to subset the DataFrame based on some conditions. For example, what if we wanted to create a new DataFrame that only contained the southern capital cities:\n\nsouth_df = cities_df[cities_df.south]\n\n\nsouth_df.shape\n\n(25, 7)\n\n\n\nsouth_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n\n\n\n\n\nAnd to get a DataFrame for the northern cities, we could use a complement filter:\n\nnorth_df = cities_df[~cities_df.south]\n\nThe ~ operator can be thought of flipping the boolean condition.\n\nnorth_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n\n\n\n\n\nWe could combine these to get the DataFrame for cities in the North East region:\n\nne_df = cities_df[~cities_df.south & cities_df.east]\n\n\nne_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n\n\n\n\n\nLike most things we will want to do, there are typically multiple ways to accomplish this in Python. Here we can get a set of regional DataFrames in one shot:\n\ndfs = {r:data for r, data in cities_df.groupby('region')}\n\n\ndfs\n\n{'NE':              name   description   latitude  longitude  east  south region\n 6     Connecticut  Hartford&lt;br&gt;  41.764046 -72.682198  True  False     NE\n 12       Illinois   Springfield  39.798363 -89.654961  True  False     NE\n 18          Maine       Augusta  44.307167 -69.781693  True  False     NE\n 20  Massachusetts        Boston  42.358162 -71.063698  True  False     NE\n 21       Michigan       Lansing  42.733635 -84.555328  True  False     NE\n 28  New Hampshire       Concord  43.206898 -71.537994  True  False     NE\n 29     New Jersey       Trenton  40.220596 -74.769913  True  False     NE\n 33       New York        Albany  42.652843 -73.757874  True  False     NE\n 34           Ohio      Columbus  39.961346 -82.999069  True  False     NE\n 37   Pennsylvania    Harrisburg  40.264378 -76.883598  True  False     NE\n 38   Rhode Island    Providence  41.830914 -71.414963  True  False     NE\n 44        Vermont    Montpelier  44.262436 -72.580536  True  False     NE\n 48      Wisconsin       Madison  43.074684 -89.384445  True  False     NE,\n 'NW':             name     description   latitude   longitude   east  south region\n 1         Alaska          Juneau  58.301598 -134.420212  False  False     NW\n 11         Idaho           Boise  43.617775 -116.199722  False  False     NW\n 14          Iowa      Des Moines  41.591087  -93.603729  False  False     NW\n 22     Minnesota        St. Paul  44.955097  -93.102211  False  False     NW\n 25       Montana          Helena  46.585709 -112.018417  False  False     NW\n 26      Nebraska         Lincoln  40.808075  -96.699654  False  False     NW\n 32  North Dakota        Bismarck  46.820850 -100.783318  False  False     NW\n 36        Oregon           Salem  44.938461 -123.030403  False  False     NW\n 40  South Dakota          Pierre  44.367031 -100.346405  False  False     NW\n 43          Utah  Salt Lake City  40.777477 -111.888237  False  False     NW\n 46    Washington         Olympia  47.035805 -122.905014  False  False     NW\n 49       Wyoming        Cheyenne  41.140259 -104.820236  False  False     NW,\n 'SE':               name   description   latitude  longitude  east  south region\n 0          Alabama    Montgomery  32.377716 -86.300568  True   True     SE\n 7         Delaware         Dover  39.157307 -75.519722  True   True     SE\n 9          Florida   Tallahassee  30.438118 -84.281296  True   True     SE\n 10         Georgia   Atlanta&lt;br&gt;  33.749027 -84.388229  True   True     SE\n 13         Indiana  Indianapolis  39.768623 -86.162643  True   True     SE\n 16        Kentucky     Frankfort  38.186722 -84.875374  True   True     SE\n 19        Maryland     Annapolis  38.978764 -76.490936  True   True     SE\n 31  North Carolina       Raleigh  35.780430 -78.639099  True   True     SE\n 39  South Carolina      Columbia  34.000343 -81.033211  True   True     SE\n 41       Tennessee     Nashville  36.165810 -86.784241  True   True     SE\n 45        Virginia      Richmond  37.538857 -77.433640  True   True     SE\n 47   West Virginia    Charleston  38.336246 -81.612328  True   True     SE,\n 'SW':            name     description   latitude   longitude   east  south region\n 2       Arizona         Phoenix  33.448143 -112.096962  False   True     SW\n 3      Arkansas     Little Rock  34.746613  -92.288986  False   True     SW\n 4    California      Sacramento  38.576668 -121.493629  False   True     SW\n 5      Colorado          Denver  39.739227 -104.984856  False   True     SW\n 8        Hawaii        Honolulu  21.307442 -157.857376  False   True     SW\n 15       Kansas          Topeka  39.048191  -95.677956  False   True     SW\n 17    Louisiana     Baton Rouge  30.457069  -91.187393  False   True     SW\n 23  Mississippi         Jackson  32.303848  -90.182106  False   True     SW\n 24     Missouri  Jefferson City  38.579201  -92.172935  False   True     SW\n 27       Nevada     Carson City  39.163914 -119.766121  False   True     SW\n 30   New Mexico        Santa Fe  35.682240 -105.939728  False   True     SW\n 35     Oklahoma   Oklahoma City  35.492207  -97.503342  False   True     SW\n 42        Texas          Austin  30.274670  -97.740349  False   True     SW}\n\n\nThey are stored in a dictionary, so we could access each one using the region ‘key’.\n\ndfs['NE'].head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE"
  },
  {
    "objectID": "studio/week02/pandas.html#merge",
    "href": "studio/week02/pandas.html#merge",
    "title": "Introduction to Pandas",
    "section": "Merge",
    "text": "Merge\nA common workflow in spatial analysis is combining different data sets. Often we will have information on the locations or geographical coordinates in one data set, but that data set may not include any substantive attribute information. We may have a second data set that has the attribute information we are interested in, but this second data set lacks geographical coordinates. So we will have cause to merge the two data sets\n\npopulation_df = pd.read_csv(f\"{home}/data/385/studio02/captial_population.csv\")\n\n\npopulation_df.head()\n\n\n\n\n\n\n\n\nState\nCapital\nSince\nArea\nCityPop\nMSAPop\nCSAPop\nrank_in_state\narea\n\n\n\n\n0\nAlabama\nMontgomery\n1846\n159.8 sq mi (414 km2)\n200603\n386047\n476207.0\n3\n159.8\n\n\n1\nAlaska\nJuneau\n1906\n2,716.7 sq mi (7,036 km2)\n32255\n32255\nNaN\n3\n2716.7\n\n\n2\nArizona\nPhoenix\n1889\n517.6 sq mi (1,341 km2)\n1608139\n4845832\n4899104.0\n1\n517.6\n\n\n3\nArkansas\nLittle Rock\n1821\n116.2 sq mi (301 km2)\n202591\n748031\n912604.0\n1\n116.2\n\n\n4\nCalifornia\nSacramento\n1854\n97.9 sq mi (254 km2)\n524943\n2397382\n2680831.0\n6\n97.9\n\n\n\n\n\n\n\n\nmerged = pd.merge(cities_df, population_df, left_on='name', right_on='State')\n\n\nmerged.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nState\nCapital\nSince\nArea\nCityPop\nMSAPop\nCSAPop\nrank_in_state\narea\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\nAlabama\nMontgomery\n1846\n159.8 sq mi (414 km2)\n200603\n386047\n476207.0\n3\n159.8\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\nAlaska\nJuneau\n1906\n2,716.7 sq mi (7,036 km2)\n32255\n32255\nNaN\n3\n2716.7\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\nArizona\nPhoenix\n1889\n517.6 sq mi (1,341 km2)\n1608139\n4845832\n4899104.0\n1\n517.6\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\nArkansas\nLittle Rock\n1821\n116.2 sq mi (301 km2)\n202591\n748031\n912604.0\n1\n116.2\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\nCalifornia\nSacramento\n1854\n97.9 sq mi (254 km2)\n524943\n2397382\n2680831.0\n6\n97.9\n\n\n\n\n\n\n\n\nmerged.shape\n\n(50, 16)\n\n\n\nmerged = pd.merge(cities_df, population_df[['CityPop', 'rank_in_state', 'area', 'State']], left_on='name', right_on='State')\n\n\nmerged.shape\n\n(50, 11)"
  },
  {
    "objectID": "studio/week02/pandas.html#saving-files",
    "href": "studio/week02/pandas.html#saving-files",
    "title": "Introduction to Pandas",
    "section": "Saving Files",
    "text": "Saving Files\nIn addition to reading data files, as we did at the beginning of this session, pandas can also create files to save to disk. It is very useful to separate your more complicated data analysis workflows into stages. Typically, the earlier stages will involve data reading, creation of new variables, and or merging different data sets. Much like we have done here. Subsequent steps would be analyzing the data that we have just constructed.\nWe do not want to have to repeat the data processing steps each time we need to carry out the analysis. To avoid this, we have our data processing notebooks save the newly created data to external files. This way the analysis notebooks only have to read these newly created files - we do not have to recreate them.\nLet’s save our latest DataFrame to a csv so we can use it again later.\n\nmerged.to_csv(\"merged.csv\", index=False)\n\nWe can show that the merge above will work irrespective of order.\n\nmerged.sort_values(by='description')\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n99224\n6\n21.40\nNew York\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n40812\n7\n6.73\nMaryland\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n498715\n1\n133.50\nGeorgia\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n18899\n10\n55.40\nMaine\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n961855\n4\n305.10\nTexas\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n227470\n2\n76.80\nLouisiana\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n73622\n2\n26.90\nNorth Dakota\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n235684\n1\n63.80\nIdaho\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n675647\n1\n89.60\nMassachusetts\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n58639\n6\n143.40\nNevada\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n48864\n1\n31.60\nWest Virginia\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n65132\n1\n21.10\nWyoming\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n136632\n2\n125.20\nSouth Carolina\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n905748\n1\n210.30\nOhio\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n43976\n3\n64.30\nNew Hampshire\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n715522\n1\n153.30\nColorado\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n214133\n1\n75.80\nIowa\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n39403\n2\n22.40\nDelaware\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n28602\n15\n14.70\nKentucky\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n50099\n9\n8.11\nPennsylvania\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n121054\n4\n17.30\nConnecticut\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n32091\n6\n14.00\nMontana\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n350964\n1\n68.40\nHawaii\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n887642\n1\n361.50\nIndiana\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n153701\n1\n104.90\nMississippi\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n43228\n15\n27.30\nMissouri\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.70\nAlaska\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n112644\n5\n35.00\nMichigan\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n291082\n2\n74.60\nNebraska\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.20\nArkansas\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n269840\n2\n68.70\nWisconsin\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.80\nAlabama\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n8074\n6\n10.20\nVermont\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n689447\n1\n525.90\nTennessee\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n681054\n1\n620.30\nOklahoma\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n55605\n23\n16.70\nWashington\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.60\nArizona\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n14091\n9\n13.00\nSouth Dakota\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n190934\n1\n18.50\nRhode Island\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n467665\n2\n114.60\nNorth Carolina\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n226610\n4\n60.10\nVirginia\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.90\nCalifornia\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n175535\n3\n45.70\nOregon\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n199723\n1\n109.10\nUtah\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n87505\n4\n37.30\nNew Mexico\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n114394\n7\n54.00\nIllinois\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n311527\n2\n52.80\nMinnesota\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n196169\n8\n95.70\nFlorida\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n126587\n5\n56.00\nKansas\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n90871\n10\n7.66\nNew Jersey\n\n\n\n\n\n\n\nLet’s write this out to a second new file:\n\nmerged.sort_values(by='description').to_csv('merged1.csv', index=False)\n\nNow read it in and redo a merge to compare to what we did above\n\npop_df = pd.read_csv('merged1.csv')\n\n\npop_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n99224\n6\n21.40\nNew York\n\n\n1\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n40812\n7\n6.73\nMaryland\n\n\n2\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n498715\n1\n133.50\nGeorgia\n\n\n3\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n18899\n10\n55.40\nMaine\n\n\n4\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n961855\n4\n305.10\nTexas\n\n\n\n\n\n\n\n\nmerged1 = pd.merge(cities_df, pop_df[['CityPop', 'rank_in_state', 'area', 'State']], left_on='name', right_on='State')\n\n\nmerged1.shape\n\n(50, 11)\n\n\n\nmerged1.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.8\nAlabama\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.7\nAlaska\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.6\nArizona\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.2\nArkansas\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.9\nCalifornia\n\n\n\n\n\n\n\n\nmerged.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.8\nAlabama\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.7\nAlaska\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.6\nArizona\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.2\nArkansas\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.9\nCalifornia"
  },
  {
    "objectID": "studio/week02/index.html",
    "href": "studio/week02/index.html",
    "title": "Week 2 Studio: Pandas",
    "section": "",
    "text": "This week we introduce Pandas:\n\nIntroduction to Pandas\nStudio exercise",
    "crumbs": [
      "Home",
      "09-04 Studio 2: Pandas"
    ]
  },
  {
    "objectID": "studio/week02/key.html",
    "href": "studio/week02/key.html",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Using the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/key.html#instructions",
    "href": "studio/week02/key.html#instructions",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Using the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/key.html#setup",
    "href": "studio/week02/key.html#setup",
    "title": "Studio 02 Pandas",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\n\ndf = pd.read_csv(\"merged.csv\")"
  },
  {
    "objectID": "studio/week02/key.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "href": "studio/week02/key.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital city with the largest population of all capital cities?",
    "text": "Which region has the capital city with the largest population of all capital cities?\n\ndf[['region', 'CityPop', 'description']].sort_values(by='CityPop', ascending=False)\n\n\n\n\n\n\n\n\nregion\nCityPop\ndescription\n\n\n\n\n2\nSW\n1608139\nPhoenix\n\n\n42\nSW\n961855\nAustin\n\n\n34\nNE\n905748\nColumbus\n\n\n13\nSE\n887642\nIndianapolis\n\n\n5\nSW\n715522\nDenver\n\n\n41\nSE\n689447\nNashville\n\n\n35\nSW\n681054\nOklahoma City\n\n\n20\nNE\n675647\nBoston\n\n\n4\nSW\n524943\nSacramento\n\n\n10\nSE\n498715\nAtlanta&lt;br&gt;\n\n\n31\nSE\n467665\nRaleigh\n\n\n8\nSW\n350964\nHonolulu\n\n\n22\nNW\n311527\nSt. Paul\n\n\n26\nNW\n291082\nLincoln\n\n\n48\nNE\n269840\nMadison\n\n\n11\nNW\n235684\nBoise\n\n\n17\nSW\n227470\nBaton Rouge\n\n\n45\nSE\n226610\nRichmond\n\n\n14\nNW\n214133\nDes Moines\n\n\n3\nSW\n202591\nLittle Rock\n\n\n0\nSE\n200603\nMontgomery\n\n\n43\nNW\n199723\nSalt Lake City\n\n\n9\nSE\n196169\nTallahassee\n\n\n38\nNE\n190934\nProvidence\n\n\n36\nNW\n175535\nSalem\n\n\n23\nSW\n153701\nJackson\n\n\n39\nSE\n136632\nColumbia\n\n\n15\nSW\n126587\nTopeka\n\n\n6\nNE\n121054\nHartford&lt;br&gt;\n\n\n12\nNE\n114394\nSpringfield\n\n\n21\nNE\n112644\nLansing\n\n\n33\nNE\n99224\nAlbany\n\n\n29\nNE\n90871\nTrenton\n\n\n30\nSW\n87505\nSanta Fe\n\n\n32\nNW\n73622\nBismarck\n\n\n49\nNW\n65132\nCheyenne\n\n\n27\nSW\n58639\nCarson City\n\n\n46\nNW\n55605\nOlympia\n\n\n37\nNE\n50099\nHarrisburg\n\n\n47\nSE\n48864\nCharleston\n\n\n28\nNE\n43976\nConcord\n\n\n24\nSW\n43228\nJefferson City\n\n\n19\nSE\n40812\nAnnapolis\n\n\n7\nSE\n39403\nDover\n\n\n1\nNW\n32255\nJuneau\n\n\n25\nNW\n32091\nHelena\n\n\n16\nSE\n28602\nFrankfort\n\n\n18\nNE\n18899\nAugusta\n\n\n40\nNW\n14091\nPierre\n\n\n44\nNE\n8074\nMontpelier"
  },
  {
    "objectID": "studio/week02/key.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "href": "studio/week02/key.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region contains the largest number of people living in its capital cities?",
    "text": "Which region contains the largest number of people living in its capital cities?\n\ndf[['region', 'CityPop']].groupby(by='region').sum()\n\n\n\n\n\n\n\n\nCityPop\n\n\nregion\n\n\n\n\n\nNE\n2701404\n\n\nNW\n1700480\n\n\nSE\n3461164\n\n\nSW\n5742198"
  },
  {
    "objectID": "studio/week02/key.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "href": "studio/week02/key.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital cities with the highest population density (median)?",
    "text": "Which region has the capital cities with the highest population density (median)?\n\ndf['density'] = df.CityPop / df.area\ndf[['density', 'region']].groupby(by='region').median()\n\n\n\n\n\n\n\n\ndensity\n\n\nregion\n\n\n\n\n\nNE\n4306.932953\n\n\nNW\n2955.899130\n\n\nSE\n1997.773548\n\n\nSW\n2345.978552"
  },
  {
    "objectID": "studio/week02/studio.html",
    "href": "studio/week02/studio.html",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 11, 2024 3:30pm\nUsing the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/studio.html#instructions",
    "href": "studio/week02/studio.html#instructions",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 11, 2024 3:30pm\nUsing the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/studio.html#setup",
    "href": "studio/week02/studio.html#setup",
    "title": "Studio 02 Pandas",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\n\ndf = pd.read_csv(\"merged.csv\")"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "href": "studio/week02/studio.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital city with the largest population of all capital cities?",
    "text": "Which region has the capital city with the largest population of all capital cities?\n\n# your code here"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "href": "studio/week02/studio.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region contains the largest number of people living in its capital cities?",
    "text": "Which region contains the largest number of people living in its capital cities?\n\n# your code here"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "href": "studio/week02/studio.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital cities with the highest population density (median)?",
    "text": "Which region has the capital cities with the highest population density (median)?\n\n# your code here"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html",
    "href": "studio/week03/studio3_geopandas.html",
    "title": "GeoPandas",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon as MplPolygon\n\n# Data for streets (line strings)\nstreets = [\n    [(0, 0), (1, 2), (3, 3)],\n    [(3, 3), (5, 2), (7, 5)],\n    [(7, 5), (8, 8), (10, 10)],\n    [(1, 2), (2, 5), (4, 6)],\n]\n\n# Data for school catchments (polygons)\ncatchments = [\n    [(0.5, 0.5), (2, 1), (1.5, 3), (0.5, 2)],\n    [(3, 4), (5, 3.5), (6, 6), (4, 6.5)],\n    [(7, 7), (8.5, 7.5), (9, 9), (7.5, 9)],\n]\n\n# Adjusting the data for one school per catchment\nschools = [(1.2, 1.8), (4.7, 5.3), (8.2, 8.2)]\n\n# Plotting the GIS map with one school per catchment\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plotting the streets with one legend entry\nax.plot(*zip(*streets[0]), color='blue', linewidth=2, label=\"Streets\")\nfor street in streets[1:]:\n    street_x, street_y = zip(*street)\n    ax.plot(street_x, street_y, color='blue', linewidth=2)\n\n# Plotting the catchments with legend\nfor i, catchment in enumerate(catchments):\n    polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n    ax.add_patch(polygon)\n    if i == 0:\n        polygon.set_label(\"School Catchments\")\n\n# Plotting the schools (points) with one per catchment\nschool_x, school_y = zip(*schools)\nax.scatter(school_x, school_y, color='green', s=100, label=\"Schools\")\n\n# Set the legend and title\nax.legend()\nax.set_title('Vector GIS: Street Network, School Catchments, and Schools')\nax.set_xlim(-1, 11)\nax.set_ylim(-1, 11)\nax.set_aspect('equal')\n\n# Save the figure to a file\nplt.savefig(\"vector.png\", dpi=300)\n\n# Show the plot\nplt.show()\n\n\n/tmp/ipykernel_2058626/3972444099.py:33: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n  polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n\n\n\n\n\n\n\n\n\nHere, we are faking it regarding a GIS, as matplotlib is a visualization library and doesn’t actually allow us to do any spatial analysis per se.\n\n\nCode\nfrom shapely import Point\n\n\n\n\nCode\nschool_points = [Point(school) for school in schools]\n\n\n\n\nCode\nschool_points\n\n\n[&lt;POINT (1.2 1.8)&gt;, &lt;POINT (4.7 5.3)&gt;, &lt;POINT (8.2 8.2)&gt;]\n\n\n\n\nCode\nschool_points[0]\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_0, school_1, school_2 = school_points\n\n\n\n\nCode\nschool_0\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_1\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_2\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom shapely import Polygon\n\n\n\n\nCode\ncatchment_polygons = [Polygon(catchment) for catchment in catchments]\n\n\n\n\nCode\ncatchment_0, catchment_1, catchment_2 = catchment_polygons\n\n\n\n\nCode\ncatchment_0\n\n\n\n\n\n\n\n\n\n\n\nCode\ncatchment_1\n\n\n\n\n\n\n\n\n\n\n\nCode\ncatchment_2\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom shapely import LineString\n\n\n\n\nCode\nstreet_lines = [LineString(street) for street in streets]\n\n\n\n\nCode\nstreet_0, street_1, street_2, street_3 = street_lines\n\n\n\n\nCode\nstreet_0\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreet_1\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreet_2\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreet_3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_0.geom_type\n\n\n'Point'\n\n\n\n\nCode\nschool_2.geom_type\n\n\n'Point'\n\n\n\n\nCode\nschool_0.area\n\n\n0.0\n\n\n\n\nCode\nschool_0.length\n\n\n0.0\n\n\n\n\nCode\nlist(school_0.coords)\n\n\n[(1.2, 1.8)]\n\n\n\n\nCode\nlist(school_2.coords)\n\n\n[(8.2, 8.2)]\n\n\n\n\nCode\nschool_0.distance(school_2)\n\n\n9.4847245611035\n\n\n\n\nCode\nstreet_1.geom_type\n\n\n'LineString'\n\n\n\n\nCode\nstreet_1.area\n\n\n0.0\n\n\n\n\nCode\nstreet_1.length\n\n\n5.841619252963779\n\n\n\n\nCode\nschool_0.distance(street_1)\n\n\n2.1633307652783933\n\n\n\n\nCode\ncatchment_0.geom_type\n\n\n'Polygon'\n\n\n\n\nCode\ncatchment_0.area\n\n\n2.375\n\n\n\n\nCode\nlist(catchment_0.exterior.coords)\n\n\n[(0.5, 0.5), (2.0, 1.0), (1.5, 3.0), (0.5, 2.0), (0.5, 0.5)]\n\n\n\n\nCode\ncatchment_0.bounds\n\n\n(0.5, 0.5, 2.0, 3.0)\n\n\n\n\nCode\nschool_0.distance(catchment_0)\n\n\n0.0\n\n\n\n\nCode\ncatchment_0.contains(school_0)\n\n\nTrue\n\n\n\n\nCode\ncatchment_0.contains(school_1)\n\n\nFalse"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#geometries-for-vector-spatial-data",
    "href": "studio/week03/studio3_geopandas.html#geometries-for-vector-spatial-data",
    "title": "GeoPandas",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon as MplPolygon\n\n# Data for streets (line strings)\nstreets = [\n    [(0, 0), (1, 2), (3, 3)],\n    [(3, 3), (5, 2), (7, 5)],\n    [(7, 5), (8, 8), (10, 10)],\n    [(1, 2), (2, 5), (4, 6)],\n]\n\n# Data for school catchments (polygons)\ncatchments = [\n    [(0.5, 0.5), (2, 1), (1.5, 3), (0.5, 2)],\n    [(3, 4), (5, 3.5), (6, 6), (4, 6.5)],\n    [(7, 7), (8.5, 7.5), (9, 9), (7.5, 9)],\n]\n\n# Adjusting the data for one school per catchment\nschools = [(1.2, 1.8), (4.7, 5.3), (8.2, 8.2)]\n\n# Plotting the GIS map with one school per catchment\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plotting the streets with one legend entry\nax.plot(*zip(*streets[0]), color='blue', linewidth=2, label=\"Streets\")\nfor street in streets[1:]:\n    street_x, street_y = zip(*street)\n    ax.plot(street_x, street_y, color='blue', linewidth=2)\n\n# Plotting the catchments with legend\nfor i, catchment in enumerate(catchments):\n    polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n    ax.add_patch(polygon)\n    if i == 0:\n        polygon.set_label(\"School Catchments\")\n\n# Plotting the schools (points) with one per catchment\nschool_x, school_y = zip(*schools)\nax.scatter(school_x, school_y, color='green', s=100, label=\"Schools\")\n\n# Set the legend and title\nax.legend()\nax.set_title('Vector GIS: Street Network, School Catchments, and Schools')\nax.set_xlim(-1, 11)\nax.set_ylim(-1, 11)\nax.set_aspect('equal')\n\n# Save the figure to a file\nplt.savefig(\"vector.png\", dpi=300)\n\n# Show the plot\nplt.show()\n\n\n/tmp/ipykernel_2058626/3972444099.py:33: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n  polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n\n\n\n\n\n\n\n\n\nHere, we are faking it regarding a GIS, as matplotlib is a visualization library and doesn’t actually allow us to do any spatial analysis per se.\n\n\nCode\nfrom shapely import Point\n\n\n\n\nCode\nschool_points = [Point(school) for school in schools]\n\n\n\n\nCode\nschool_points\n\n\n[&lt;POINT (1.2 1.8)&gt;, &lt;POINT (4.7 5.3)&gt;, &lt;POINT (8.2 8.2)&gt;]\n\n\n\n\nCode\nschool_points[0]\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_0, school_1, school_2 = school_points\n\n\n\n\nCode\nschool_0\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_1\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_2\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom shapely import Polygon\n\n\n\n\nCode\ncatchment_polygons = [Polygon(catchment) for catchment in catchments]\n\n\n\n\nCode\ncatchment_0, catchment_1, catchment_2 = catchment_polygons\n\n\n\n\nCode\ncatchment_0\n\n\n\n\n\n\n\n\n\n\n\nCode\ncatchment_1\n\n\n\n\n\n\n\n\n\n\n\nCode\ncatchment_2\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom shapely import LineString\n\n\n\n\nCode\nstreet_lines = [LineString(street) for street in streets]\n\n\n\n\nCode\nstreet_0, street_1, street_2, street_3 = street_lines\n\n\n\n\nCode\nstreet_0\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreet_1\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreet_2\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreet_3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nschool_0.geom_type\n\n\n'Point'\n\n\n\n\nCode\nschool_2.geom_type\n\n\n'Point'\n\n\n\n\nCode\nschool_0.area\n\n\n0.0\n\n\n\n\nCode\nschool_0.length\n\n\n0.0\n\n\n\n\nCode\nlist(school_0.coords)\n\n\n[(1.2, 1.8)]\n\n\n\n\nCode\nlist(school_2.coords)\n\n\n[(8.2, 8.2)]\n\n\n\n\nCode\nschool_0.distance(school_2)\n\n\n9.4847245611035\n\n\n\n\nCode\nstreet_1.geom_type\n\n\n'LineString'\n\n\n\n\nCode\nstreet_1.area\n\n\n0.0\n\n\n\n\nCode\nstreet_1.length\n\n\n5.841619252963779\n\n\n\n\nCode\nschool_0.distance(street_1)\n\n\n2.1633307652783933\n\n\n\n\nCode\ncatchment_0.geom_type\n\n\n'Polygon'\n\n\n\n\nCode\ncatchment_0.area\n\n\n2.375\n\n\n\n\nCode\nlist(catchment_0.exterior.coords)\n\n\n[(0.5, 0.5), (2.0, 1.0), (1.5, 3.0), (0.5, 2.0), (0.5, 0.5)]\n\n\n\n\nCode\ncatchment_0.bounds\n\n\n(0.5, 0.5, 2.0, 3.0)\n\n\n\n\nCode\nschool_0.distance(catchment_0)\n\n\n0.0\n\n\n\n\nCode\ncatchment_0.contains(school_0)\n\n\nTrue\n\n\n\n\nCode\ncatchment_0.contains(school_1)\n\n\nFalse"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#geopandas",
    "href": "studio/week03/studio3_geopandas.html#geopandas",
    "title": "GeoPandas",
    "section": "Geopandas",
    "text": "Geopandas\n\n\nCode\nimport geopandas as gpd\n\n\n\n\nCode\nstreets = gpd.GeoSeries(street_lines)\n\n\n\n\nCode\nstreets.plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\ncatchments = gpd.GeoSeries(catchment_polygons)\n\n\n\n\nCode\ncatchments.plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nschools = gpd.GeoSeries(school_points)\n\n\n\n\nCode\nschools.plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\ntype(schools)\n\n\ngeopandas.geoseries.GeoSeries\n\n\n\n\nCode\ndir(schools)\n\n\n['T',\n '_AXIS_LEN',\n '_AXIS_ORDERS',\n '_AXIS_TO_AXIS_NUMBER',\n '_HANDLED_TYPES',\n '__abs__',\n '__add__',\n '__and__',\n '__annotations__',\n '__array__',\n '__array_priority__',\n '__array_ufunc__',\n '__bool__',\n '__class__',\n '__column_consortium_standard__',\n '__contains__',\n '__copy__',\n '__deepcopy__',\n '__delattr__',\n '__delitem__',\n '__dict__',\n '__dir__',\n '__divmod__',\n '__doc__',\n '__eq__',\n '__finalize__',\n '__float__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__geo_interface__',\n '__getattr__',\n '__getattribute__',\n '__getitem__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__ifloordiv__',\n '__imod__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__lt__',\n '__matmul__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__nonzero__',\n '__or__',\n '__pandas_priority__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdivmod__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__rfloordiv__',\n '__rmatmul__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__round__',\n '__rpow__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__setitem__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__truediv__',\n '__weakref__',\n '__xor__',\n '_accessors',\n '_accum_func',\n '_agg_examples_doc',\n '_agg_see_also_doc',\n '_align_for_op',\n '_align_frame',\n '_align_series',\n '_append',\n '_arith_method',\n '_as_manager',\n '_attrs',\n '_binop',\n '_can_hold_na',\n '_check_inplace_and_allows_duplicate_labels',\n '_check_is_chained_assignment_possible',\n '_check_label_or_level_ambiguity',\n '_check_setitem_copy',\n '_clear_item_cache',\n '_clip_with_one_bound',\n '_clip_with_scalar',\n '_cmp_method',\n '_consolidate',\n '_consolidate_inplace',\n '_construct_axes_dict',\n '_construct_result',\n '_constructor',\n '_constructor_expanddim',\n '_constructor_expanddim_from_mgr',\n '_constructor_from_mgr',\n '_data',\n '_deprecate_downcast',\n '_dir_additions',\n '_dir_deletions',\n '_drop_axis',\n '_drop_labels_or_levels',\n '_duplicated',\n '_find_valid_index',\n '_flags',\n '_flex_method',\n '_from_mgr',\n '_from_wkb_or_wkt',\n '_get_axis',\n '_get_axis_name',\n '_get_axis_number',\n '_get_axis_resolvers',\n '_get_block_manager_axis',\n '_get_bool_data',\n '_get_cacher',\n '_get_cleaned_column_resolvers',\n '_get_index_resolvers',\n '_get_label_or_level_values',\n '_get_numeric_data',\n '_get_rows_with_mask',\n '_get_value',\n '_get_values_tuple',\n '_get_with',\n '_getitem_slice',\n '_gotitem',\n '_hidden_attrs',\n '_indexed_same',\n '_info_axis',\n '_info_axis_name',\n '_info_axis_number',\n '_init_dict',\n '_init_mgr',\n '_inplace_method',\n '_internal_names',\n '_internal_names_set',\n '_is_cached',\n '_is_copy',\n '_is_label_or_level_reference',\n '_is_label_reference',\n '_is_level_reference',\n '_is_mixed_type',\n '_is_view',\n '_is_view_after_cow_rules',\n '_item_cache',\n '_ixs',\n '_logical_func',\n '_logical_method',\n '_map_values',\n '_maybe_update_cacher',\n '_memory_usage',\n '_metadata',\n '_mgr',\n '_min_count_stat_function',\n '_name',\n '_needs_reindex_multi',\n '_pad_or_backfill',\n '_protect_consolidate',\n '_reduce',\n '_references',\n '_reindex_axes',\n '_reindex_indexer',\n '_reindex_multi',\n '_reindex_with_indexers',\n '_rename',\n '_replace_single',\n '_repr_data_resource_',\n '_repr_latex_',\n '_reset_cache',\n '_reset_cacher',\n '_set_as_cached',\n '_set_axis',\n '_set_axis_name',\n '_set_axis_nocheck',\n '_set_is_copy',\n '_set_labels',\n '_set_name',\n '_set_value',\n '_set_values',\n '_set_with',\n '_set_with_engine',\n '_shift_with_freq',\n '_slice',\n '_stat_function',\n '_stat_function_ddof',\n '_take_with_is_copy',\n '_to_latex_via_styler',\n '_typ',\n '_update_inplace',\n '_validate_dtype',\n '_values',\n '_where',\n '_wrapped_pandas_method',\n 'abs',\n 'add',\n 'add_prefix',\n 'add_suffix',\n 'affine_transform',\n 'agg',\n 'aggregate',\n 'align',\n 'all',\n 'any',\n 'append',\n 'apply',\n 'area',\n 'argmax',\n 'argmin',\n 'argsort',\n 'array',\n 'asfreq',\n 'asof',\n 'astype',\n 'at',\n 'at_time',\n 'attrs',\n 'autocorr',\n 'axes',\n 'backfill',\n 'between',\n 'between_time',\n 'bfill',\n 'bool',\n 'boundary',\n 'bounds',\n 'buffer',\n 'build_area',\n 'case_when',\n 'centroid',\n 'clip',\n 'clip_by_rect',\n 'combine',\n 'combine_first',\n 'compare',\n 'concave_hull',\n 'contains',\n 'contains_properly',\n 'convert_dtypes',\n 'convex_hull',\n 'copy',\n 'corr',\n 'count',\n 'count_coordinates',\n 'count_geometries',\n 'count_interior_rings',\n 'cov',\n 'covered_by',\n 'covers',\n 'crosses',\n 'crs',\n 'cummax',\n 'cummin',\n 'cumprod',\n 'cumsum',\n 'cx',\n 'delaunay_triangles',\n 'describe',\n 'diff',\n 'difference',\n 'disjoint',\n 'distance',\n 'div',\n 'divide',\n 'divmod',\n 'dot',\n 'drop',\n 'drop_duplicates',\n 'droplevel',\n 'dropna',\n 'dtype',\n 'dtypes',\n 'duplicated',\n 'dwithin',\n 'empty',\n 'envelope',\n 'eq',\n 'equals',\n 'estimate_utm_crs',\n 'ewm',\n 'expanding',\n 'explode',\n 'explore',\n 'exterior',\n 'extract_unique_points',\n 'factorize',\n 'ffill',\n 'fillna',\n 'filter',\n 'first',\n 'first_valid_index',\n 'flags',\n 'floordiv',\n 'force_2d',\n 'force_3d',\n 'frechet_distance',\n 'from_arrow',\n 'from_file',\n 'from_wkb',\n 'from_wkt',\n 'from_xy',\n 'ge',\n 'geom_almost_equals',\n 'geom_equals',\n 'geom_equals_exact',\n 'geom_type',\n 'geometry',\n 'get',\n 'get_coordinates',\n 'get_geometry',\n 'get_precision',\n 'groupby',\n 'gt',\n 'has_sindex',\n 'has_z',\n 'hasnans',\n 'hausdorff_distance',\n 'head',\n 'hilbert_distance',\n 'hist',\n 'iat',\n 'idxmax',\n 'idxmin',\n 'iloc',\n 'index',\n 'infer_objects',\n 'info',\n 'interiors',\n 'interpolate',\n 'intersection',\n 'intersection_all',\n 'intersects',\n 'is_ccw',\n 'is_closed',\n 'is_empty',\n 'is_monotonic_decreasing',\n 'is_monotonic_increasing',\n 'is_ring',\n 'is_simple',\n 'is_unique',\n 'is_valid',\n 'is_valid_reason',\n 'isin',\n 'isna',\n 'isnull',\n 'item',\n 'items',\n 'keys',\n 'kurt',\n 'kurtosis',\n 'last',\n 'last_valid_index',\n 'le',\n 'length',\n 'line_merge',\n 'list',\n 'loc',\n 'lt',\n 'make_valid',\n 'map',\n 'mask',\n 'max',\n 'mean',\n 'median',\n 'memory_usage',\n 'min',\n 'minimum_bounding_circle',\n 'minimum_bounding_radius',\n 'minimum_clearance',\n 'minimum_rotated_rectangle',\n 'mod',\n 'mode',\n 'mul',\n 'multiply',\n 'name',\n 'nbytes',\n 'ndim',\n 'ne',\n 'nlargest',\n 'normalize',\n 'notna',\n 'notnull',\n 'nsmallest',\n 'nunique',\n 'offset_curve',\n 'overlaps',\n 'pad',\n 'pct_change',\n 'pipe',\n 'plot',\n 'polygonize',\n 'pop',\n 'pow',\n 'prod',\n 'product',\n 'project',\n 'quantile',\n 'radd',\n 'rank',\n 'ravel',\n 'rdiv',\n 'rdivmod',\n 'reindex',\n 'reindex_like',\n 'relate',\n 'relate_pattern',\n 'remove_repeated_points',\n 'rename',\n 'rename_axis',\n 'reorder_levels',\n 'repeat',\n 'replace',\n 'representative_point',\n 'resample',\n 'reset_index',\n 'reverse',\n 'rfloordiv',\n 'rmod',\n 'rmul',\n 'rolling',\n 'rotate',\n 'round',\n 'rpow',\n 'rsub',\n 'rtruediv',\n 'sample',\n 'sample_points',\n 'scale',\n 'searchsorted',\n 'segmentize',\n 'select',\n 'sem',\n 'set_axis',\n 'set_crs',\n 'set_flags',\n 'set_precision',\n 'shape',\n 'shared_paths',\n 'shift',\n 'shortest_line',\n 'simplify',\n 'sindex',\n 'size',\n 'skew',\n 'snap',\n 'sort_index',\n 'sort_values',\n 'squeeze',\n 'std',\n 'struct',\n 'sub',\n 'subtract',\n 'sum',\n 'swapaxes',\n 'swaplevel',\n 'symmetric_difference',\n 'tail',\n 'take',\n 'to_arrow',\n 'to_clipboard',\n 'to_crs',\n 'to_csv',\n 'to_dict',\n 'to_excel',\n 'to_file',\n 'to_frame',\n 'to_hdf',\n 'to_json',\n 'to_latex',\n 'to_list',\n 'to_markdown',\n 'to_numpy',\n 'to_period',\n 'to_pickle',\n 'to_sql',\n 'to_string',\n 'to_timestamp',\n 'to_wkb',\n 'to_wkt',\n 'to_xarray',\n 'total_bounds',\n 'touches',\n 'transform',\n 'translate',\n 'transpose',\n 'truediv',\n 'truncate',\n 'type',\n 'tz_convert',\n 'tz_localize',\n 'unary_union',\n 'union',\n 'union_all',\n 'unique',\n 'unstack',\n 'update',\n 'value_counts',\n 'values',\n 'var',\n 'view',\n 'voronoi_polygons',\n 'where',\n 'within',\n 'x',\n 'xs',\n 'y',\n 'z']\n\n\n\n\nCode\nschools_gdf = gpd.GeoDataFrame(geometry=schools)\n\n\n\n\nCode\nschools_gdf.head()\n\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOINT (1.2 1.8)\n\n\n1\nPOINT (4.7 5.3)\n\n\n2\nPOINT (8.2 8.2)\n\n\n\n\n\n\n\n\n\nCode\ntype(schools_gdf)\n\n\ngeopandas.geodataframe.GeoDataFrame\n\n\n\n\nCode\nschools_gdf['students'] = [124, 94, 100]\n\n\n\n\nCode\nschools_gdf.head()\n\n\n\n\n\n\n\n\n\ngeometry\nstudents\n\n\n\n\n0\nPOINT (1.2 1.8)\n124\n\n\n1\nPOINT (4.7 5.3)\n94\n\n\n2\nPOINT (8.2 8.2)\n100\n\n\n\n\n\n\n\n\n\nCode\nschools_gdf.plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nschools_gdf.plot(column='students')\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreets_gdf = gpd.GeoDataFrame(geometry=streets)\n\n\n\n\nCode\nstreets_gdf.plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nstreets_gdf['length'] = streets_gdf.length\n\n\n\n\nCode\nstreets_gdf.head()\n\n\n\n\n\n\n\n\n\ngeometry\nlength\n\n\n\n\n0\nLINESTRING (0 0, 1 2, 3 3)\n4.472136\n\n\n1\nLINESTRING (3 3, 5 2, 7 5)\n5.841619\n\n\n2\nLINESTRING (7 5, 8 8, 10 10)\n5.990705\n\n\n3\nLINESTRING (1 2, 2 5, 4 6)\n5.398346\n\n\n\n\n\n\n\n\n\nCode\nstreets_gdf.plot(column='length', legend=True)\n\n\n\n\n\n\n\n\n\n\n\nCode\ncatchments_gdf = gpd.GeoDataFrame(geometry=catchment_polygons)\n\n\n\n\nCode\ncatchments_gdf['area'] = catchments_gdf.area\ncatchments_gdf.plot(column='area', legend=True)"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#southern-california-census-tracts",
    "href": "studio/week03/studio3_geopandas.html#southern-california-census-tracts",
    "title": "GeoPandas",
    "section": "Southern California Census Tracts",
    "text": "Southern California Census Tracts\n\n\nCode\ngdf = gpd.read_parquet(\"~/data/scag_region.parquet\")\n\n\n\n\nCode\ngdf.shape\n\n\n(4580, 194)\n\n\n\n\nCode\ntype(gdf)\n\n\ngeopandas.geodataframe.GeoDataFrame\n\n\n\n\nCode\ngdf.head()\n\n\n\n\n\n\n\n\n\ngeoid\nn_asian_under_15\nn_black_under_15\nn_hispanic_under_15\nn_native_under_15\nn_white_under_15\nn_persons_under_18\nn_asian_over_60\nn_black_over_60\nn_hispanic_over_60\n...\nyear\nn_total_housing_units_sample\np_nonhisp_white_persons\np_white_over_60\np_black_over_60\np_hispanic_over_60\np_native_over_60\np_asian_over_60\np_disabled\ngeometry\n\n\n\n\n0\n06037128702\n58.0\n0.0\n223.0\n0.0\n475.0\n986.0\nNaN\nNaN\nNaN\n...\n2010\n2903.0\n64.726214\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.4487 34.16485, -118.43997 34.16...\n\n\n1\n06037131600\n83.0\n62.0\n777.0\n0.0\n135.0\n1355.0\nNaN\nNaN\nNaN\n...\n2010\n1487.0\n28.679979\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.56229 34.22033, -118.55792 34.2...\n\n\n2\n06037134104\n287.0\n17.0\n816.0\n0.0\n61.0\n1323.0\nNaN\nNaN\nNaN\n...\n2010\n1388.0\n14.846188\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.57976 34.21558, -118.57539 34.2...\n\n\n3\n06037134304\n90.0\n24.0\n298.0\n0.0\n89.0\n520.0\nNaN\nNaN\nNaN\n...\n2010\n928.0\n33.378933\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.61472 34.21952, -118.61039 34.2...\n\n\n4\n06037242000\n0.0\n229.0\n681.0\n0.0\n0.0\n1164.0\nNaN\nNaN\nNaN\n...\n2010\n1054.0\n0.058565\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.25416 33.93882, -118.25413 33.9...\n\n\n\n\n5 rows × 194 columns\n\n\n\n\n\nCode\ngdf.columns.values\n\n\narray(['geoid', 'n_asian_under_15', 'n_black_under_15',\n       'n_hispanic_under_15', 'n_native_under_15', 'n_white_under_15',\n       'n_persons_under_18', 'n_asian_over_60', 'n_black_over_60',\n       'n_hispanic_over_60', 'n_native_over_60', 'n_persons_over_60',\n       'n_white_over_60', 'n_asian_over_65', 'n_black_over_65',\n       'n_hispanic_over_65', 'n_native_over_65', 'n_white_over_65',\n       'n_persons_over_75', 'n_persons_over_15', 'n_civilians_over_16',\n       'n_civilians_over_18', 'n_persons_over_25', 'n_age_5_older',\n       'n_asian_age_distribution', 'n_black_age_distribution',\n       'n_hispanic_age_distribution', 'n_native_age_distribution',\n       'n_white_age_distribution', 'n_asian_persons', 'n_black_persons',\n       'n_chinese_persons', 'n_labor_force', 'n_civilians_16_64',\n       'n_edu_college_greater', 'n_cuban_pop',\n       'n_poverty_determined_asian', 'n_poverty_determined_black',\n       'n_total_pop_sample', 'n_female_over_16',\n       'n_poverty_determined_families', 'n_poverty_determined_hispanic',\n       'n_disabled', 'n_housing_units_multiunit_structures_denom',\n       'n_poverty_determined_native', 'n_poverty_determined_persons',\n       'n_poverty_determined_white', 'n_employed_over_16',\n       'n_total_families', 'n_foreign_born_pop',\n       'n_female_headed_families', 'n_filipino_persons',\n       'n_female_labor_force', 'n_german_pop', 'n_german_born_pop',\n       'n_household_recent_move', 'n_structures_30_old',\n       'n_hawaiian_persons', 'n_total_households', 'n_asian_households',\n       'n_black_households', 'n_hispanic_households',\n       'n_white_households', 'median_household_income',\n       'median_income_asianhh', 'median_income_blackhh',\n       'median_income_hispanichh', 'median_income_whitehh',\n       'n_hispanic_persons', 'n_edu_hs_less', 'n_total_housing_units',\n       'per_capita_income', 'n_asian_indian_persons', 'n_irish_pop',\n       'n_irish_born_pop', 'n_italian_pop', 'n_italian_born_pop',\n       'n_japanese_persons', 'n_korean_persons', 'n_limited_english',\n       'n_employed_manufacturing', 'n_married', 'n_mexican_pop',\n       'median_home_value', 'median_contract_rent',\n       'n_housing_units_multiunit_structures', 'n_recent_immigrant_pop',\n       'n_poverty_over_65', 'n_poverty_asian', 'n_naturalized_pop',\n       'n_poverty_black', 'n_poverty_families_children',\n       'n_nonhisp_black_persons', 'n_poverty_hispanic',\n       'n_nonhisp_white_persons', 'n_poverty_native', 'n_poverty_persons',\n       'n_native_persons', 'n_poverty_white', 'n_occupied_housing_units',\n       'n_other_language', 'n_owner_occupied_housing_units',\n       'p_recent_immigrant_pop', 'p_household_recent_move',\n       'p_asian_under_15', 'p_black_under_15', 'p_hispanic_under_15',\n       'p_native_under_15', 'p_white_under_15', 'p_persons_under_18',\n       'p_structures_30_old', 'p_persons_over_60', 'p_asian_over_65',\n       'p_black_over_65', 'p_hispanic_over_65', 'p_native_over_65',\n       'p_poverty_rate_over_65', 'p_white_over_65', 'p_persons_over_75',\n       'p_poverty_rate_asian', 'p_asian_persons', 'p_poverty_rate_black',\n       'p_chinese_persons', 'p_edu_college_greater', 'p_cuban_pop',\n       'p_foreign_born_pop', 'p_female_headed_families',\n       'p_filipino_persons', 'p_female_labor_force',\n       'p_poverty_rate_children', 'p_german_pop', 'p_german_born_pop',\n       'p_hawaiian_persons', 'p_hispanic_persons',\n       'p_poverty_rate_hispanic', 'p_edu_hs_less',\n       'p_asian_indian_persons', 'p_irish_pop', 'p_irish_born_pop',\n       'p_italian_pop', 'p_italian_born_pop', 'p_japanese_persons',\n       'p_korean_persons', 'p_limited_english',\n       'p_employed_manufacturing', 'p_married', 'p_mexican_pop',\n       'p_housing_units_multiunit_structures', 'p_poverty_rate_native',\n       'p_naturalized_pop', 'p_nonhisp_black_persons', 'p_black_persons',\n       'p_native_persons', 'p_other_language', 'n_total_pop',\n       'p_owner_occupied_units', 'p_poverty_rate', 'p_puerto_rican_pop',\n       'p_employed_professional', 'n_puerto_rican_pop',\n       'n_employed_professional', 'p_russian_pop', 'p_russian_born_pop',\n       'p_scandanavian_pop', 'p_scandanavian_born_pop',\n       'p_employed_self_employed', 'p_unemployment_rate',\n       'p_vacant_housing_units', 'p_veterans', 'p_vietnamese_persons',\n       'p_widowed_divorced', 'p_poverty_rate_white',\n       'n_renter_occupied_housing_units', 'n_russian_pop',\n       'n_russian_born_pop', 'n_scandaniavian_pop',\n       'n_scandaniavian__born_pop', 'n_employed_self_employed',\n       'n_unemployed_persons', 'n_vacant_housing_units', 'n_veterans',\n       'n_vietnamese_persons', 'n_widowed_divorced', 'n_white_persons',\n       'year', 'n_total_housing_units_sample', 'p_nonhisp_white_persons',\n       'p_white_over_60', 'p_black_over_60', 'p_hispanic_over_60',\n       'p_native_over_60', 'p_asian_over_60', 'p_disabled', 'geometry'],\n      dtype=object)\n\n\n\n\nCode\ngdf.n_total_pop\n\n\n0       5497.0\n1       5659.0\n2       4486.0\n3       2924.0\n4       3415.0\n         ...  \n4575    3672.0\n4576    5257.0\n4577    6765.0\n4578    2981.0\n4579    3994.0\nName: n_total_pop, Length: 4580, dtype: float64\n\n\n\n\nCode\ngdf.geometry\n\n\n0       POLYGON ((-118.4487 34.16485, -118.43997 34.16...\n1       POLYGON ((-118.56229 34.22033, -118.55792 34.2...\n2       POLYGON ((-118.57976 34.21558, -118.57539 34.2...\n3       POLYGON ((-118.61472 34.21952, -118.61039 34.2...\n4       POLYGON ((-118.25416 33.93882, -118.25413 33.9...\n                              ...                        \n4575    POLYGON ((-118.50373 34.42608, -118.5005 34.42...\n4576    POLYGON ((-118.20731 33.90754, -118.20641 33.9...\n4577    POLYGON ((-119.22134 34.1813, -119.21727 34.18...\n4578    POLYGON ((-116.51068 33.80502, -116.51069 33.8...\n4579    POLYGON ((-118.41378 34.1794, -118.4116 34.179...\nName: geometry, Length: 4580, dtype: geometry\n\n\n\n\nCode\ngdf.plot()"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#projections",
    "href": "studio/week03/studio3_geopandas.html#projections",
    "title": "GeoPandas",
    "section": "Projections",
    "text": "Projections\n\n\nCode\ngdf.crs\n\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\nCode\ngdf1 = gdf.to_crs(3857)\n\n\n\n\nCode\ngdf1.crs\n\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\nCode\ngdf1.plot()\n\n\n\n\n\n\n\n\n\n\n\nCode\ngdf.median_home_value\n\n\n0       647272.659176\n1       400842.977528\n2       416741.666667\n3       406178.838951\n4       251438.857678\n            ...      \n4575    291838.951311\n4576    273871.254682\n4577    293254.588015\n4578    255794.662921\n4579    581717.790262\nName: median_home_value, Length: 4580, dtype: float64\n\n\n\n\nCode\ngdf.plot(column='median_home_value')\n\n\n\n\n\n\n\n\n\n\n\nCode\ngdf.plot(column='median_home_value', legend=True)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngdf.plot(column='median_home_value', legend=True,\n        scheme='quantiles', k=10)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngdf.plot(column='p_hispanic_persons', legend=True,\n        scheme='quantiles', k=10)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngdf.explore(column='p_hispanic_persons', tooltip=['geoid', 'p_hispanic_persons'])\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\ngdf.head()\n\n\n\n\n\n\n\n\n\ngeoid\nn_asian_under_15\nn_black_under_15\nn_hispanic_under_15\nn_native_under_15\nn_white_under_15\nn_persons_under_18\nn_asian_over_60\nn_black_over_60\nn_hispanic_over_60\n...\nyear\nn_total_housing_units_sample\np_nonhisp_white_persons\np_white_over_60\np_black_over_60\np_hispanic_over_60\np_native_over_60\np_asian_over_60\np_disabled\ngeometry\n\n\n\n\n0\n06037128702\n58.0\n0.0\n223.0\n0.0\n475.0\n986.0\nNaN\nNaN\nNaN\n...\n2010\n2903.0\n64.726214\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.4487 34.16485, -118.43997 34.16...\n\n\n1\n06037131600\n83.0\n62.0\n777.0\n0.0\n135.0\n1355.0\nNaN\nNaN\nNaN\n...\n2010\n1487.0\n28.679979\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.56229 34.22033, -118.55792 34.2...\n\n\n2\n06037134104\n287.0\n17.0\n816.0\n0.0\n61.0\n1323.0\nNaN\nNaN\nNaN\n...\n2010\n1388.0\n14.846188\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.57976 34.21558, -118.57539 34.2...\n\n\n3\n06037134304\n90.0\n24.0\n298.0\n0.0\n89.0\n520.0\nNaN\nNaN\nNaN\n...\n2010\n928.0\n33.378933\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.61472 34.21952, -118.61039 34.2...\n\n\n4\n06037242000\n0.0\n229.0\n681.0\n0.0\n0.0\n1164.0\nNaN\nNaN\nNaN\n...\n2010\n1054.0\n0.058565\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nPOLYGON ((-118.25416 33.93882, -118.25413 33.9...\n\n\n\n\n5 rows × 194 columns\n\n\n\n\n\nCode\ncounty = gdf.geoid.str[:5]\n\n\n\n\nCode\ncounty\n\n\n0       06037\n1       06037\n2       06037\n3       06037\n4       06037\n        ...  \n4575    06037\n4576    06037\n4577    06111\n4578    06065\n4579    06037\nName: geoid, Length: 4580, dtype: object\n\n\n\n\nCode\ngdf['county'] = county"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#which-county-has-the-most-tracts",
    "href": "studio/week03/studio3_geopandas.html#which-county-has-the-most-tracts",
    "title": "GeoPandas",
    "section": "Which county has the most tracts?",
    "text": "Which county has the most tracts?\n\n\nCode\ngdf.groupby(by='county').count()\n\n\n\n\n\n\n\n\n\ngeoid\nn_asian_under_15\nn_black_under_15\nn_hispanic_under_15\nn_native_under_15\nn_white_under_15\nn_persons_under_18\nn_asian_over_60\nn_black_over_60\nn_hispanic_over_60\n...\nyear\nn_total_housing_units_sample\np_nonhisp_white_persons\np_white_over_60\np_black_over_60\np_hispanic_over_60\np_native_over_60\np_asian_over_60\np_disabled\ngeometry\n\n\ncounty\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n06025\n31\n31\n31\n31\n31\n31\n31\n0\n0\n0\n...\n31\n31\n31\n0\n0\n0\n0\n0\n0\n31\n\n\n06037\n2344\n2344\n2344\n2344\n2344\n2344\n2344\n0\n0\n0\n...\n2344\n2344\n2328\n0\n0\n0\n0\n0\n0\n2344\n\n\n06059\n582\n582\n582\n582\n582\n582\n582\n0\n0\n0\n...\n582\n582\n582\n0\n0\n0\n0\n0\n0\n582\n\n\n06065\n453\n453\n453\n453\n453\n453\n453\n0\n0\n0\n...\n453\n453\n452\n0\n0\n0\n0\n0\n0\n453\n\n\n06071\n369\n369\n369\n369\n369\n369\n369\n0\n0\n0\n...\n369\n369\n368\n0\n0\n0\n0\n0\n0\n369\n\n\n06073\n627\n627\n627\n627\n627\n627\n627\n0\n0\n0\n...\n627\n627\n627\n0\n0\n0\n0\n0\n0\n627\n\n\n06111\n174\n174\n174\n174\n174\n174\n174\n0\n0\n0\n...\n174\n174\n173\n0\n0\n0\n0\n0\n0\n174\n\n\n\n\n7 rows × 194 columns"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#which-county-has-the-largest-tract-in-area",
    "href": "studio/week03/studio3_geopandas.html#which-county-has-the-largest-tract-in-area",
    "title": "GeoPandas",
    "section": "Which county has the largest tract in area?",
    "text": "Which county has the largest tract in area?\n\n\nCode\ngdf['area'] = gdf1.area\n\n\n\n\nCode\ngdf[['area', 'county']].sort_values(by='area', ascending=False)\n\n\n\n\n\n\n\n\n\narea\ncounty\n\n\n\n\n489\n2.700979e+10\n06071\n\n\n437\n1.430813e+10\n06065\n\n\n908\n1.073840e+10\n06071\n\n\n4303\n8.553053e+09\n06025\n\n\n1661\n5.345018e+09\n06071\n\n\n...\n...\n...\n\n\n715\n1.237570e+05\n06037\n\n\n3562\n1.161974e+05\n06037\n\n\n4062\n9.984444e+04\n06037\n\n\n1669\n4.045569e+03\n06037\n\n\n3673\n2.537546e-01\n06111\n\n\n\n\n4580 rows × 2 columns\n\n\n\n\n\nCode\ngdf.columns.values\n\n\narray(['geoid', 'n_asian_under_15', 'n_black_under_15',\n       'n_hispanic_under_15', 'n_native_under_15', 'n_white_under_15',\n       'n_persons_under_18', 'n_asian_over_60', 'n_black_over_60',\n       'n_hispanic_over_60', 'n_native_over_60', 'n_persons_over_60',\n       'n_white_over_60', 'n_asian_over_65', 'n_black_over_65',\n       'n_hispanic_over_65', 'n_native_over_65', 'n_white_over_65',\n       'n_persons_over_75', 'n_persons_over_15', 'n_civilians_over_16',\n       'n_civilians_over_18', 'n_persons_over_25', 'n_age_5_older',\n       'n_asian_age_distribution', 'n_black_age_distribution',\n       'n_hispanic_age_distribution', 'n_native_age_distribution',\n       'n_white_age_distribution', 'n_asian_persons', 'n_black_persons',\n       'n_chinese_persons', 'n_labor_force', 'n_civilians_16_64',\n       'n_edu_college_greater', 'n_cuban_pop',\n       'n_poverty_determined_asian', 'n_poverty_determined_black',\n       'n_total_pop_sample', 'n_female_over_16',\n       'n_poverty_determined_families', 'n_poverty_determined_hispanic',\n       'n_disabled', 'n_housing_units_multiunit_structures_denom',\n       'n_poverty_determined_native', 'n_poverty_determined_persons',\n       'n_poverty_determined_white', 'n_employed_over_16',\n       'n_total_families', 'n_foreign_born_pop',\n       'n_female_headed_families', 'n_filipino_persons',\n       'n_female_labor_force', 'n_german_pop', 'n_german_born_pop',\n       'n_household_recent_move', 'n_structures_30_old',\n       'n_hawaiian_persons', 'n_total_households', 'n_asian_households',\n       'n_black_households', 'n_hispanic_households',\n       'n_white_households', 'median_household_income',\n       'median_income_asianhh', 'median_income_blackhh',\n       'median_income_hispanichh', 'median_income_whitehh',\n       'n_hispanic_persons', 'n_edu_hs_less', 'n_total_housing_units',\n       'per_capita_income', 'n_asian_indian_persons', 'n_irish_pop',\n       'n_irish_born_pop', 'n_italian_pop', 'n_italian_born_pop',\n       'n_japanese_persons', 'n_korean_persons', 'n_limited_english',\n       'n_employed_manufacturing', 'n_married', 'n_mexican_pop',\n       'median_home_value', 'median_contract_rent',\n       'n_housing_units_multiunit_structures', 'n_recent_immigrant_pop',\n       'n_poverty_over_65', 'n_poverty_asian', 'n_naturalized_pop',\n       'n_poverty_black', 'n_poverty_families_children',\n       'n_nonhisp_black_persons', 'n_poverty_hispanic',\n       'n_nonhisp_white_persons', 'n_poverty_native', 'n_poverty_persons',\n       'n_native_persons', 'n_poverty_white', 'n_occupied_housing_units',\n       'n_other_language', 'n_owner_occupied_housing_units',\n       'p_recent_immigrant_pop', 'p_household_recent_move',\n       'p_asian_under_15', 'p_black_under_15', 'p_hispanic_under_15',\n       'p_native_under_15', 'p_white_under_15', 'p_persons_under_18',\n       'p_structures_30_old', 'p_persons_over_60', 'p_asian_over_65',\n       'p_black_over_65', 'p_hispanic_over_65', 'p_native_over_65',\n       'p_poverty_rate_over_65', 'p_white_over_65', 'p_persons_over_75',\n       'p_poverty_rate_asian', 'p_asian_persons', 'p_poverty_rate_black',\n       'p_chinese_persons', 'p_edu_college_greater', 'p_cuban_pop',\n       'p_foreign_born_pop', 'p_female_headed_families',\n       'p_filipino_persons', 'p_female_labor_force',\n       'p_poverty_rate_children', 'p_german_pop', 'p_german_born_pop',\n       'p_hawaiian_persons', 'p_hispanic_persons',\n       'p_poverty_rate_hispanic', 'p_edu_hs_less',\n       'p_asian_indian_persons', 'p_irish_pop', 'p_irish_born_pop',\n       'p_italian_pop', 'p_italian_born_pop', 'p_japanese_persons',\n       'p_korean_persons', 'p_limited_english',\n       'p_employed_manufacturing', 'p_married', 'p_mexican_pop',\n       'p_housing_units_multiunit_structures', 'p_poverty_rate_native',\n       'p_naturalized_pop', 'p_nonhisp_black_persons', 'p_black_persons',\n       'p_native_persons', 'p_other_language', 'n_total_pop',\n       'p_owner_occupied_units', 'p_poverty_rate', 'p_puerto_rican_pop',\n       'p_employed_professional', 'n_puerto_rican_pop',\n       'n_employed_professional', 'p_russian_pop', 'p_russian_born_pop',\n       'p_scandanavian_pop', 'p_scandanavian_born_pop',\n       'p_employed_self_employed', 'p_unemployment_rate',\n       'p_vacant_housing_units', 'p_veterans', 'p_vietnamese_persons',\n       'p_widowed_divorced', 'p_poverty_rate_white',\n       'n_renter_occupied_housing_units', 'n_russian_pop',\n       'n_russian_born_pop', 'n_scandaniavian_pop',\n       'n_scandaniavian__born_pop', 'n_employed_self_employed',\n       'n_unemployed_persons', 'n_vacant_housing_units', 'n_veterans',\n       'n_vietnamese_persons', 'n_widowed_divorced', 'n_white_persons',\n       'year', 'n_total_housing_units_sample', 'p_nonhisp_white_persons',\n       'p_white_over_60', 'p_black_over_60', 'p_hispanic_over_60',\n       'p_native_over_60', 'p_asian_over_60', 'p_disabled', 'geometry',\n       'county', 'area'], dtype=object)\n\n\n\n\nCode\ngdf.n_total_pop_sample\n\n\n0      NaN\n1      NaN\n2      NaN\n3      NaN\n4      NaN\n        ..\n4575   NaN\n4576   NaN\n4577   NaN\n4578   NaN\n4579   NaN\nName: n_total_pop_sample, Length: 4580, dtype: float64"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#geopandas-1",
    "href": "studio/week03/studio3_geopandas.html#geopandas-1",
    "title": "GeoPandas",
    "section": "Geopandas",
    "text": "Geopandas\n\nGeoSeries\nGeoDataFrame\nCounty variable\narea/crs/project\npopulation density ## Studio\nReport number of tracts by county\nMedian population tract population density by county\nPopulation density by county\n\ntwo group bys and division\nlater show them dissove"
  },
  {
    "objectID": "studio/week01/intro.html",
    "href": "studio/week01/intro.html",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "",
    "text": "In this Session we introduce the computational environment for the course."
  },
  {
    "objectID": "studio/week01/intro.html#logging-on-to-jupyter-hub",
    "href": "studio/week01/intro.html#logging-on-to-jupyter-hub",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Logging on to Jupyter Hub",
    "text": "Logging on to Jupyter Hub\nEach registered student is given an account on our course Jupyter Hub installation.\nIf you are on campus, and using a campus IP, go to http://130.191.118.182/hub/login\n\n\n\nlogon\n\n\nYour Username is the prefix of your SDSU email (the part before the @).\nFor the Password, you set that the first time you log on. It can be anything you choose, but you must remember it.\nIf you are off-campus, you must first connect to the university’s Virtual Private Network."
  },
  {
    "objectID": "studio/week01/intro.html#interface",
    "href": "studio/week01/intro.html#interface",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Interface",
    "text": "Interface\nWe will be exploring the components of the Jupyter Lab Interface.\n\nMain work area\nleft sidebar\nmenu bar\nfile browser\n\n\n\n\nlogon\n\n\n\nMain work area\nThe main work area arranges activities and documents into panels of tabs.\nDocuments can be notebooks, text files, while activities can be terminals or code consoles.\nIt currently has a single tab entitled Launcher which contains a set of, well, launchers.\n\n\nLeft sidebar\nThe left sidebar contains a file browser (next to the main work area). The thin panel to the left of the file browser has three icons for:\n\ncommand pallet\ntable of contents\nextension manager"
  },
  {
    "objectID": "studio/week01/intro.html#notebooks",
    "href": "studio/week01/intro.html#notebooks",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Notebooks",
    "text": "Notebooks\nLet’s open our first document.\nDouble-click the Square icon under Notebook in the Launcher tab.\nThis will result in:\n\n\n\nnotebook\n\n\nNow, the main work area has a single tab with the title Untitled.ipynb. This is our first jupyter notebook.\nThe extension ipynb tells us so.\nWe also see that the filename is showing up in the file browser.\nIt is good practice to give your notebooks (and files) meaningful names. To do so you can right click on the tab or in the file browser and give it a new name introduction.ipynb.\n\n\n\nnotebook renamed"
  },
  {
    "objectID": "studio/week01/intro.html#cell-types",
    "href": "studio/week01/intro.html#cell-types",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Cell Types",
    "text": "Cell Types\nA notebook is composed of cells. Currently, our notebook as a single cell.\nCells can be of different types. There are three possible types:\n\nCode\nMarkdown\nRaw\n\nWhat happens with the contents of a cell depends upon its type. We can have cells of different types in the same notebook - in other words, all the cells in a notebook do not have to be of the same type. This opens up rich possibilities for creating computational documents.\n\nCode\nThe type of a cell is indicated in the dropdown of the tabs icon bar. Our current cell is of type Code.\nA code cell should contain, well, code. By this we mean, a set of statements that the kernel for our language can understand. Think of the kernel as a machine that is going to take our code and convert it into some type of result or action.\nIn our case, the kernel is Python. This is indicated in the upper right portion of the notebook tab.\nLet’s enter some code in our code cell:\n\nEnter 3**2\nShift-return\n\n\n\n\nRunning a code cell\n\n\nWhen we used the key-chord Shift-return (while holding the shift key down also hit return) from inside the code cell, this took the contents of the cell 3**2 and passed it off to the Python interpreter. Since this was legit Python code, we got a result of 9 in an output cell.\nThen the interface gives us a new empty code cell, so we can continue if we wish.\nBut, instead of continuing, let’s say we wanted a different calculation. Put the cursor back in the first code cell and change this to 10 * 3**2 and rerun the cell.\n\n\n\nRe-running a code cell\n\n\nAgain, this is legit Python code so we get a new result. The other things that have changed are the numbers on the left of the cells. Now we have a [2] in front of the code cell and its output cell. This indicates that we have run 2 code cells in this session.\nThe current cell is indicated by the blue vertical bar. This is where we would enter new code as we progress.\nLet’s progress.\nIn the current cell, enter x = 10 * 3**2 and run the cell.\n\n\n\nRunning a code cell with an assignment\n\n\nWe don’t get an output cell in this case. This is because our code is an assignment statement. This means we assign the value of the statement on the right of the = into the variable x on the left side.\nTo see the value of x, enter x in the next code cell and run the cell:\n\n\n\nRunning a code cell with an output\n\n\nWith this, we have the basics of entering Python code and running it. Let’s turn our attention to the next type of cell: Markdown.\n\n\nMarkdown\nMarkdown is a markup language invented by John Gruber to make it easier for humans to write web pages.\nLet’s change the type of the current cell. There are two ways to do this.\nThe first way is to click on the cell type dropdown (currently set to Code) and select Markdown. This results in:\n\n\n\nChanging to Markdown\n\n\nWe still have the blue indicator to the left of the current cell. But we no longer of the [ ]: next to the cell.\nTo enter some Markdown, put the cursor in the cell and enter:\nThis next word will be **bold**.\n\n\n\nEditing Markdown\n\n\nThen run the Markdown cell with Shift-return:\n\n\n\n“Running” Markdown\n\n\nThis is a bit different from what we saw when we ran a code cell. In the case of a Markdown cell, what happens is that when we “run” the cell, the contents of the cell gets handed off to a different kernel, one that knows the Markdown markup. The kernel then translate from the markdown input and returns actual html that gets rendered in the same cell.\nWe can change our cell by double-clicking in it. Let’s add some more Markdown by changing the cell contents to:\n## Markdown Cells\n\nHere we are demonstrating `Markdown`.\n\nThe next word will be in **bold**.\n\nThe next word will be in *italics*.\n\n### Lists\n\nWe can do unordered lists:\n\n- dog\n- cat\n- monkey\n\nAs well as ordered lists\n\n1. dogs\n1. monkey\n1. cat\n\n\n\nMore Markdown\n\n\nOnce we have entered this, “run” the cell with Shift-return:\n\n\n\nMore Rendered Markdown\n\n\nBefore we do more with Markdown, let’s learn a bit about our last cell type Raw.\n\n\nRaw\nTo see the utility of the Raw cell type, double-click into the Markdown cell. In the cell, copy all the contents of the cell (click and drag with the mouse, then Control-C (Linux/Windows) Command-C (Mac) ).\nMove the cursor into the next cell and paste (Control-V (Linux/Windows), Command-V (Mac)).\nThen, in this last cell change the cell type to Raw so your screen should look like:\n\n\n\nRaw Cell Type\n\n\nNext, jump up to the Markdown cell, and run that cell to render it. Then, render the Raw cell:\n\n\n\nRaw Cell As Reference\n\n\nThis shows us that we can use Raw cells to display the syntax used to get a rendered cell. This can be helpful to document how things were done."
  },
  {
    "objectID": "studio/week01/intro.html#cell-modes",
    "href": "studio/week01/intro.html#cell-modes",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Cell Modes",
    "text": "Cell Modes\nIn addition to having different cell types, cells have two modes.\n\nCommand Mode\nEdit Mode\n\nThese are mutually exclusive modes - only one is active. In other words, you a cell is either in command mode or edit mode.\n\nCommand Mode (Running Cells)\nIn command mode we can, not suprsingly, run cells. We already know how to do this. Make the cell active (by moving the cursor to the cell), then use Ctrl-return.\nHow do we know we are in command mode? A couple of ways.\nIf you are in a code cell, if the cell does not have a blue border, you are in command mode:\n\n\n\nCode cell in Command mode\n\n\nIf the code cell has a blue border you are in edit mode:\n\n\n\nCode cell in Edit mode\n\n\nIf you are in edit mode and want to switch to command mode, use the Esc key.\nIf you are in command mode and want to switch to edit mode, simply click in the cell to start editing.\nIn addition to letting us run cells, command mode also allows us to manipulate cells. The two sets of most common manipulations we do in command mode are:\n\nCut and paste cells (move)\nSplit and merge cells\n\nTo demonstrate the first, recall the figure that had the Raw cell below the Markdown cell. It might be more helpful to have the Raw cell before (above) the Markdown cell.\nTo do this.\nFrom the empty code cell:\n\nEnter command mode (Esc)\nHit the k key. This moves the cursor up into the raw cell.\nHit the x key. This will cut the current cell.\nMove up two cells by repeating k k\nPaste the cut cell with v\n\nYour notebook should now look something like:\n\n\n\nCode cell in Edit mode\n\n\nTo demonstrate splitting cells, let’s say we want to break our Markdown cell into two separate Markdown cells such that the Lists subsection is in its own cell.\nTo do this,\n\nMake the Markdown cell active by moving down one with j.\nOnce the Markdown cell is active, get into edit mode (click into the cell).\nMove the cursor to the empty ilne before Lists.\nCtrl-Shift-- (That’s the Ctrl key held down, with the Shift key followed by -).\n\nThe result should be:\n\n\n\nSpliltting a cell\n\n\nTo merge cells together.\n\nEnter command mode\nShift-k to select the current cell and the cell above it.\nShift-m to merge the two cells.\n\n\n\n\nMerging two cells\n\n\n\n\nEdit Mode\nLet’s create an empty cell and edit it. Assume we want to add a new cell above the current cell. This is done with a.\n\n\n\nCreating a new cell above the current cell\n\n\nLet’s make this a Markdown cell, using the second approach I hinted at above.\n\nEnter command mode\nm\n\nNote that it is lower-case m here. Now we can enter Markdown by clicking in the new cell and filling it in with whatever we want. For example:\n### Using Raw and Markdown cells\nThe cell below will be the rendered markdown. The cell above is the raw markdown in a raw cell for reference\nRendering the cell should give:\n\n\n\nRendered new cell\n\n\nAs our notebooks grow, it would be nice to be able to jump around without endlessly scrolling. Remember the table of contents that lives in the Left sidebar? This can come in handy when you have a long Markdown document and can use the TOC to jump around quickly.\nTo see this work, let’s first go to the top of the notebook by scrolling up. Then, 1. Add a new cell above the current cell. 2. Make it a Markdown Cell 3. Enter ## Python code cells 4. Render the cell\nAfter rendering, the cell, click the table of contents icon in the left sidebar:\n\n\n\nTable of Contents\n\n\nYou can now click on the entries in the table of contents to jump to that section/subsection in the notebook."
  },
  {
    "objectID": "studio/week01/intro.html#saving-and-exporting",
    "href": "studio/week01/intro.html#saving-and-exporting",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Saving and Exporting",
    "text": "Saving and Exporting\nIt is good practice to save your notebook as you go. Use Ctrl-s to do so or Command-s (mac).\nIf there are any unsaved changes, the little black dot in the notebook tab will be visible:\n\n\n\nUnsaved changes\n\n\nAfter saving your notebook, it will live on the course server, so you can come back to it later (see logging off below). Sometimes, you will need to export or download a copy of your notebook to hand in for credit. To do this:\n\nMake sure the notebook you want to save is the active tab in the main work area\nClick on the file browser icon in the left side bar.\nFrom the Menu bar: File-Save and Export Notebook As-pdf\n\nThis should create a pdf file on your local computer that you can hand in.\nIf you get an error that looks like:\n\n\n\nSaving error\n\n\nThis is due to having the Raw cell in the notebook. To fix it, simply delete the Raw cell and try to export again. We won’t be using Raw cells in the assignments so this won’t be an issue moving forward."
  },
  {
    "objectID": "studio/week01/meet.html",
    "href": "studio/week01/meet.html",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "",
    "text": "This handout provides instructions on how to use Google Meet for small group work, including creating a meeting, sharing screens (with sound off), and using the chat feature to collaborate on in-class studios."
  },
  {
    "objectID": "studio/week01/meet.html#purpose",
    "href": "studio/week01/meet.html#purpose",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "",
    "text": "This handout provides instructions on how to use Google Meet for small group work, including creating a meeting, sharing screens (with sound off), and using the chat feature to collaborate on in-class studios."
  },
  {
    "objectID": "studio/week01/meet.html#find-your-team",
    "href": "studio/week01/meet.html#find-your-team",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Find Your Team",
    "text": "Find Your Team\nTeams are randomly constructed. To find your team:\n\nVisit the link for the team assignments for Studio 1.\nThe first person listed is the group leader. If the first person is not present, the first person next on the list who is present is the group leader for the studio."
  },
  {
    "objectID": "studio/week01/meet.html#getting-started-with-google-meet",
    "href": "studio/week01/meet.html#getting-started-with-google-meet",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Getting Started with Google Meet",
    "text": "Getting Started with Google Meet\n\nGroup Leader\n\nThe group leader will be responsible for creating the Google Meet session.\n\nCreating a Google Meet Session\n\nThe group leader should sign in to their Google account.\nUsing the Team Meeting link at the bottom of the Studio 1 Team listing, the Group Leader should start the meeting..\n\nJoining the Google Meet Session\n\nEach group member should click the link provided by the group leader to join the session.\nAllow Google Meet to access your microphone and camera if prompted.\nMute your microphone by clicking the microphone icon at the bottom of the screen to reduce background noise."
  },
  {
    "objectID": "studio/week01/meet.html#sharing-your-screen",
    "href": "studio/week01/meet.html#sharing-your-screen",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Sharing Your Screen",
    "text": "Sharing Your Screen\nScreen sharing helps all group members see the same content, making collaboration easier.\n\nHow to Share Your Screen\n\nOnce in the Google Meet, click on the “Present Now” button at the bottom right of the screen.\nSelect “Your Entire Screen” or “A Window,” depending on what you want to share.\nClick “Share” to start sharing your screen.\n\nKeeping Your Microphone Off\n\nKeep your microphone muted while sharing your screen to avoid feedback or echo. Use the chat for communication or unmute only when necessary."
  },
  {
    "objectID": "studio/week01/meet.html#using-the-chat-feature",
    "href": "studio/week01/meet.html#using-the-chat-feature",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Using the Chat Feature",
    "text": "Using the Chat Feature\nThe chat feature is useful for collaboration without speaking out loud.\n\nOpen the Chat\n\nClick on the chat icon (speech bubble) in the top right corner of the screen to open the chat window.\n\nCommunicate Effectively\n\nUse the chat to ask questions, share links, and discuss the studio.\nKeep your messages clear and concise to avoid misunderstandings."
  },
  {
    "objectID": "studio/week01/meet.html#best-practices-for-google-meet-collaboration",
    "href": "studio/week01/meet.html#best-practices-for-google-meet-collaboration",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Best Practices for Google Meet Collaboration",
    "text": "Best Practices for Google Meet Collaboration\n\nStay Muted When Not Speaking: We will be in person, so no need to use your microphone in class.\nUse the Chat to Communicate: Share your thoughts and questions in the chat to maintain a smooth flow of discussion.\nKeep Your Camera On: This helps the group stay engaged and allows for better non-verbal communication.\nBe Respectful: Listen to others, avoid interrupting, and provide constructive feedback.\nEnsure Only One Person Shares at a Time: This helps avoid confusion and keeps the focus on the task at hand."
  },
  {
    "objectID": "studio/week01/meet.html#troubleshooting-tips",
    "href": "studio/week01/meet.html#troubleshooting-tips",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Troubleshooting Tips",
    "text": "Troubleshooting Tips\n\nAudio Issues: If others cannot hear you, check that your microphone is not muted and that Google Meet is using the correct microphone in the settings.\nScreen Sharing Problems: Ensure that your browser has permission to share your screen.\nConnectivity Issues: If you experience lag or get disconnected, try refreshing your browser or checking your internet connection."
  },
  {
    "objectID": "studio/week01/meet.html#wrapping-up",
    "href": "studio/week01/meet.html#wrapping-up",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nAt the end of the studio, the group leader should summarize the group’s discussion and findings. The leader will hand in the summary on Canvas.\nFor additional assistance, refer to the Google Meet Help Center or contact your instructor.\nHappy collaborating!"
  },
  {
    "objectID": "studio/meet.html",
    "href": "studio/meet.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "studio/meet.html#overview",
    "href": "studio/meet.html#overview",
    "title": "",
    "section": "Overview",
    "text": "Overview\nIn this activity, you’ll work in small groups to collaborate on a task. To facilitate your work, each group will create a Google Meet meeting where you can share your screens and discuss the activity in real-time."
  },
  {
    "objectID": "studio/meet.html#steps-to-create-a-google-meet-meeting",
    "href": "studio/meet.html#steps-to-create-a-google-meet-meeting",
    "title": "",
    "section": "Steps to Create a Google Meet Meeting",
    "text": "Steps to Create a Google Meet Meeting\n\n1. Choose a Group Leader\n\nSelect one person in your group to create the Google Meet meeting. This person will be responsible for sharing the meeting link with the rest of the group.\n\n\n\n2. Create the Google Meet Meeting\n\nThe group leader should follow these steps:\n\nOpen Google Meet:\n\nGo to Google Meet in your web browser.\n\nStart a New Meeting:\n\nClick on the New meeting button.\nSelect Start an instant meeting.\n\nCopy the Meeting Link:\n\nOnce the meeting is created, a window will pop up with the meeting link.\nClick on Copy meeting link to copy the URL to your clipboard.\n\n\n\n\n\n3. Share the Meeting Link with Your Group\n\nThe group leader should share the copied meeting link with the rest of the group members. This can be done via:\n\nClass communication platform (chat)\nDirect message or text\n\n\n\n\n4. Join the Google Meet Meeting\n\nEach group member should click on the link provided by the group leader to join the meeting.\n\n\n\n5. Share Your Screen\n\nTo share your screen during the meeting:\n\nClick on the Present Now button:\n\nThis button is located at the bottom of the Google Meet window.\n\nChoose What to Share:\n\nYou can select to share your entire screen, a specific window, or a specific browser tab.\n\nClick on Share:\n\nOnce you’ve selected what to share, click Share to start presenting to the group.\n\n\n\n\n\n6. Collaborate on the Activity\n\nUse the screen sharing feature to work together on the assigned activity. Discuss, brainstorm, and contribute as a team.\n\n\n\n7. Wrap Up\n\nWhen your group has completed the activity, you can leave the Google Meet meeting by clicking the Leave call button."
  },
  {
    "objectID": "studio/meet.html#troubleshooting-tips",
    "href": "studio/meet.html#troubleshooting-tips",
    "title": "",
    "section": "Troubleshooting Tips",
    "text": "Troubleshooting Tips\n\nAudio Issues: If you’re having trouble hearing others, make sure your microphone and speakers are properly connected and not muted.\nScreen Sharing Not Working: Ensure that you have granted the necessary permissions for screen sharing in your browser.\nInternet Connection: If your connection is unstable, try moving closer to your Wi-Fi router or switching to a wired connection if possible."
  },
  {
    "objectID": "studio/meet.html#additional-resources",
    "href": "studio/meet.html#additional-resources",
    "title": "",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nGoogle Meet Help Center\n\nGood luck with your activity, and make the most of your collaborative time!"
  },
  {
    "objectID": "lectures/week03/lecture.html#syllabus",
    "href": "lectures/week03/lecture.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus"
  },
  {
    "objectID": "lectures/week03/lecture.html#spatial-data-analysis",
    "href": "lectures/week03/lecture.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture"
  },
  {
    "objectID": "lectures/week03/studio.html",
    "href": "lectures/week03/studio.html",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2\n\n\n\n\n[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week03/studio.html#objectives",
    "href": "lectures/week03/studio.html#objectives",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "lectures/week03/studio.html#instructions",
    "href": "lectures/week03/studio.html#instructions",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week01/lecture.html#syllabus",
    "href": "lectures/week01/lecture.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus"
  },
  {
    "objectID": "lectures/week01/lecture.html#spatial-data-analysis",
    "href": "lectures/week01/lecture.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture"
  },
  {
    "objectID": "lectures/week01/studio.html",
    "href": "lectures/week01/studio.html",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2\n\n\n\n\n[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week01/studio.html#objectives",
    "href": "lectures/week01/studio.html#objectives",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "lectures/week01/studio.html#instructions",
    "href": "lectures/week01/studio.html#instructions",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "[Studio module instructions go here…]"
  },
  {
    "objectID": "assignments/python_course.html#definition-of-spatial-data-analysis",
    "href": "assignments/python_course.html#definition-of-spatial-data-analysis",
    "title": "Python Primer",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "assignments/python_course.html#importance-of-spatial-data-analysis",
    "href": "assignments/python_course.html#importance-of-spatial-data-analysis",
    "title": "Python Primer",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "assignments/python_course.html#historical-context",
    "href": "assignments/python_course.html#historical-context",
    "title": "Python Primer",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "assignments/python_course.html#vector-data",
    "href": "assignments/python_course.html#vector-data",
    "title": "Python Primer",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "assignments/python_course.html#vector-data-1",
    "href": "assignments/python_course.html#vector-data-1",
    "title": "Python Primer",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "assignments/python_course.html#raster-data",
    "href": "assignments/python_course.html#raster-data",
    "title": "Python Primer",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "assignments/python_course.html#attribute-data",
    "href": "assignments/python_course.html#attribute-data",
    "title": "Python Primer",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "assignments/python_course.html#attribute-data-1",
    "href": "assignments/python_course.html#attribute-data-1",
    "title": "Python Primer",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "assignments/python_course.html#temporal-spatial-data",
    "href": "assignments/python_course.html#temporal-spatial-data",
    "title": "Python Primer",
    "section": "Temporal-Spatial Data",
    "text": "Temporal-Spatial Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "assignments/python_course.html#remote-sensing",
    "href": "assignments/python_course.html#remote-sensing",
    "title": "Python Primer",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "assignments/python_course.html#geographic-information-systems-gis",
    "href": "assignments/python_course.html#geographic-information-systems-gis",
    "title": "Python Primer",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "assignments/python_course.html#global-positioning-system-gps",
    "href": "assignments/python_course.html#global-positioning-system-gps",
    "title": "Python Primer",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "assignments/python_course.html#crowdsourced-data",
    "href": "assignments/python_course.html#crowdsourced-data",
    "title": "Python Primer",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "assignments/python_course.html#spatial-autocorrelation",
    "href": "assignments/python_course.html#spatial-autocorrelation",
    "title": "Python Primer",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "assignments/python_course.html#spatial-scale-and-resolution",
    "href": "assignments/python_course.html#spatial-scale-and-resolution",
    "title": "Python Primer",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "assignments/python_course.html#modifiable-areal-unit-problem-maup",
    "href": "assignments/python_course.html#modifiable-areal-unit-problem-maup",
    "title": "Python Primer",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "assignments/python_course.html#modifiable-areal-unit-problem-maup-1",
    "href": "assignments/python_course.html#modifiable-areal-unit-problem-maup-1",
    "title": "Python Primer",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "assignments/python_course.html#spatial-interpolation",
    "href": "assignments/python_course.html#spatial-interpolation",
    "title": "Python Primer",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "assignments/python_course.html#spatial-interpolation-1",
    "href": "assignments/python_course.html#spatial-interpolation-1",
    "title": "Python Primer",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "assignments/python_course.html#public-health",
    "href": "assignments/python_course.html#public-health",
    "title": "Python Primer",
    "section": "Public Health",
    "text": "Public Health\n\nTracking disease outbreaks, identifying health disparities."
  },
  {
    "objectID": "assignments/python_course.html#environmental-management",
    "href": "assignments/python_course.html#environmental-management",
    "title": "Python Primer",
    "section": "Environmental Management",
    "text": "Environmental Management\n\nMonitoring deforestation, analyzing pollution patterns."
  },
  {
    "objectID": "assignments/python_course.html#urban-planning",
    "href": "assignments/python_course.html#urban-planning",
    "title": "Python Primer",
    "section": "Urban Planning",
    "text": "Urban Planning\n\nInfrastructure development, zoning, transportation networks."
  },
  {
    "objectID": "assignments/python_course.html#emergency-response",
    "href": "assignments/python_course.html#emergency-response",
    "title": "Python Primer",
    "section": "Emergency Response",
    "text": "Emergency Response\n\nDisaster management, evacuation planning, resource allocation."
  },
  {
    "objectID": "assignments/python_course.html#conclusion-and-qa-3-minutes",
    "href": "assignments/python_course.html#conclusion-and-qa-3-minutes",
    "title": "Python Primer",
    "section": "Conclusion and Q&A (3 minutes)",
    "text": "Conclusion and Q&A (3 minutes)"
  },
  {
    "objectID": "assignments/python_course.html#recap-of-key-points",
    "href": "assignments/python_course.html#recap-of-key-points",
    "title": "Python Primer",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nOverview of spatial data types, key concepts, and applications."
  },
  {
    "objectID": "assignments/python_course.html#importance-of-spatial-data-analysis-1",
    "href": "assignments/python_course.html#importance-of-spatial-data-analysis-1",
    "title": "Python Primer",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nEmphasis on its growing relevance in various fields."
  },
  {
    "objectID": "assignments/python_course.html#open-floor-for-questions",
    "href": "assignments/python_course.html#open-floor-for-questions",
    "title": "Python Primer",
    "section": "Open Floor for Questions",
    "text": "Open Floor for Questions\n\nEncourage students to ask questions or discuss topics of interest."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Geography 385 Spatial Data Analysis is an introduction to exploratory spatial data analysis taught by Professor Sergio Rey at San Diego State University."
  }
]
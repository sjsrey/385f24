[
  {
    "objectID": "syllabus.html#class-meetings",
    "href": "syllabus.html#class-meetings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Class Meetings",
    "text": "Class Meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nLSN 111\nMon & Wed 3:30 - 4:45pm"
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Instructor",
    "text": "Instructor\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\nSergio Rey\nMon 9:00 - 10:00 (by appointment)\nPSFA 361G"
  },
  {
    "objectID": "syllabus.html#introduction",
    "href": "syllabus.html#introduction",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Introduction",
    "text": "Introduction\nWelcome to GEOG 385: Spatial Data Analysis!\nThe purpose of this course is to introduce you to methods of spatial data analysis. The focus is on both the conceptual and applied aspects of spatial statistical methods. We will place particular emphasis on the computational aspects of Exploratory Spatial Data Analysis (ESDA) methods for diﬀerent types of spatial data including point processes, lattice data, geostatistical data, network data, and spatial interaction. Throughout the course you will gain valuable hands-on experience with several specialized software packages for spatial data analysis. The overriding goal of the course is for you to acquire familiarity with the fundamental methodological and operational issues in the statistical analysis of geographic information and the ability to extend these methods in your own research.\nThe course takes an explicitly computational thinking approach to its pedagogy. Students are introduced to computational concepts and tools that are increasingly important to research that engages with geospatial data. By adopting these tools, students acquire a deeper engagement with, and mastery of, the substantive concepts. Put differently, students will learn to code. But this is a means to the end goal: students will code to learn spatial data analysis.\nIn the scope of a 15-week semester course we can only introduce a handful of the key concepts and methods relevant to the field of spatial data analysis. As such, the course is not intended as an exhaustive treatment. Instead, the goal is that students will acquire an understanding of the more common and useful methods and practices, and use the course as an entry point for further engagement with the field."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGEOG 101 or GEOG 102\nSTAT 250 or comparable course in statistics.\n\nAll students are required to complete the prerequisite assessment quiz before 2024-08-28 3:30pm."
  },
  {
    "objectID": "syllabus.html#computational-learning",
    "href": "syllabus.html#computational-learning",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Computational Learning",
    "text": "Computational Learning\nWe will be using open source geospatial software throughout the course together with Jupyter Notebooks, and Python as our scripting language.\nAll software for the course will be made available through JupyterHub, a web-based framework. Students wishing to install these materials on their own machines will be given instructions to do so, but this is not required."
  },
  {
    "objectID": "syllabus.html#readings",
    "href": "syllabus.html#readings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Readings",
    "text": "Readings\nAll required readings are available through the links listed below. Assigned readings should be completed before the date listed in the schedule (see below). Readings are a critical part of the discussions we will hold in class, and therefore being prepared for class means having completed the readings and thought about the content. It will be difficult to do well in this course without having completed the readings.\n\n\n\nAbbrevation\nSource\n\n\n\n\nGDA\nTenkanen, H., V. Heikinheimo, D. Whipp (2023) Python for Geographic Data Analysis. CRC Press.\n\n\nGDS\nRey, S.J., D. Arribas-Bel, L.J. Wolf (2023) Geographic Data Science with Python. CRC Press."
  },
  {
    "objectID": "syllabus.html#schedule-planned",
    "href": "syllabus.html#schedule-planned",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Schedule (Planned)",
    "text": "Schedule (Planned)\n\n\n\nWeek\nDate\nTopic\nReading\nDue\n\n\n\n\n1\n8-26\nIntroduction\n\nPrerequisite Quiz\n\n\n\n8-28\nJupyter\n\n\n\n\n2\n9-02\nLabor Day (Holiday)\n\n\n\n\n\n9-04\nPandas\nGDA 3\n\n\n\n3\n9-09\nSpatial Data Analysis\nGDS 1\n\n\n\n\n9-11\nGeopandas\nGDA 6\n\n\n\n4\n9-16\nArea Unit Data\nGDS 3\n\n\n\n\n9-18\nGeoprocessing: Area Units\nGDA 6\n\n\n\n5\n9-23\nVisualizing Area Unit Data\nGDS 5\nPython Primer\n\n\n\n9-25\nChoropleth Mapping\n\n\n\n\n6\n9-30\nSpatial Weights\nGDS 4\nTopic Approval\n\n\n\n10-02\nNeighbor Relations\n\nPeer Evaluation 1\n\n\n7\n10-07\nGlobal Spatial Autocorrelation\nGDS 6\n\n\n\n\n10-09\nTesting for Clustering\n\n\n\n\n8\n10-14\nLocal Spatial Autocorrelation\nGDS 7\nProject Proposal\n\n\n\n10-16\nCluster Detection\n\n\n\n\n9\n10-21\nClustering Area Unit Data\nGDS 10\n\n\n\n\n10-23\nRegion Building\n\nPeer Evaluation 2\n\n\n10\n10-28\nPoint Pattern Data\nGDS 8.1\n\n\n\n\n10-30\nGeoprocessing: Points\n\n\n\n\n11\n11-04\nCentrography\nGDS8.2\nData Visualization\n\n\n\n11-06\nDescribing Point Patterns\n\nPeer Evaluation 3\n\n\n12\n11-11\nVeteran’s Day (Holiday)\n\n\n\n\n\n11-13\nPoint Process Simulation\nGDS 8.3\n\n\n\n13\n11-18\nNearest Neighbor Statistics\n\nData Analysis\n\n\n\n11-20\nTesting for Randomness\n\nPeer Evaluation 4\n\n\n14\n11-25\nDistance Based Statistics\n\n\n\n\n\n11-27\nThanksgiving (Holiday)\n\n\n\n\n15\n12-02\nClustering Point Pattern Data\n\nNarrative\n\n\n\n12-04\nDBScan\n\n\n\n\n16\n12-09\nIntegrating Point and Area Data\n\n\n\n\n\n12-11\nGeoprocessing: Synthesis\n\nComputational Notebook\n\n\n17\n12-18\nFinal Presentations (1-3pm)"
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Grading",
    "text": "Grading\nGEOG 385 uses specification grading in evaluating student work and in determining your final course grade. Your course grade will be based on the quality and quantity of the work that you submit that is evaluated to be of an acceptable level of quality. The acceptable level of quality demonstrates competency in the concepts and methods covered in the course.\nThere is a two-step process for determination of your final course grade at the end of the quarter:\n\nUsing your quizzes and exercises, your base grade is determined.\nUsing your final exam results, determine if your base grade includes a \"plus\", \"minus\", or level drop to form the course grade.\n\n\nBase Grade\nFor Step 1, the base grade is determined using the following specification:\n\n\n\nLevel\nThresholds\n\n\n\n\nA-\nAll the B- Thresholds\n\n\n\nPass 11 or more reading quizzes\n\n\n\nParticipate in 12 or more studios\n\n\n\nComplete 4 peer evaluations\n\n\n\nPresentation of Computational Essay\n\n\nB-\nAll the C- Thresholds\n\n\n\nPass 9 or more reading quizzes\n\n\n\nParticipate in 8 or more studios\n\n\n\nComplete 3 peer evaluations\n\n\n\nComputational Essay\n\n\nC-\nAll the D- Thresholds\n\n\n\nPass 6 or more reading quizzes\n\n\n\nParticipate in 6 or more studios\n\n\n\nComplete 2 peer evaluations\n\n\nD-\nPass 4 or more reading quizzes\n\n\n\nParticipate in 4 or more studios\n\n\n\nComplete 1 peer evaluation\n\n\nF\nFailing to clear all the D- Thresholds\n\n\n\n\n\nFinal Grade\nFor Step 2, your final course grade is determined as follows:\nIf your base grade is not an A-:\n\n2 tokens can increment a B(C,D)- to a B(CD)\n3 tokens can increment a B(C,D)- to a B(CD)+\n\nIf your base grade is an A-:\n\n2 tokens increments an A- to an A\n3 tokens increments an A- to an A and earns a recommendation certificate\n\n\n\n\n\n\n\nNote\n\n\n\nNote that SDSU grading policy does not allow A+ grades."
  },
  {
    "objectID": "syllabus.html#quizzes",
    "href": "syllabus.html#quizzes",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Quizzes",
    "text": "Quizzes\nStarting in week three, there will be a quiz due before a session that pertains to the background reading that is required before our work in class. Quizzes are graded on a pass/fail basis."
  },
  {
    "objectID": "syllabus.html#studio-participation",
    "href": "syllabus.html#studio-participation",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Studio Participation",
    "text": "Studio Participation\nEach Wednesday, we will focus on hands-on exercises that explore the material from lecture. Each student will be assigned to a small group that works together to carry out a set of spatial data analysis tasks. At the end of the session each group will submit a single notebook demonstrating their work.\nEach notebook is graded using a CRN rubric that classifies work with marks of C (\"Demonstrates Competence\"), R (\"Needs Revision\"), or N (\"Not assessable\"):\nOf each notebook the following questions will be asked: Does the work demonstrate that the student understands the concepts? Does the work demonstrate competence and meet the expectations outlined in the exercise?\nIf the answer is \"yes\" to both of the questions, the group passes the hurdle for that studio.\nIf the initial submission does not clear the hurdle, then a second question is asked: Is there evidence of partial understanding of the concepts? If the answer to this question is \"Yes\" the group can exchange one token (from each student) to attempt a revision of their work. If the answer is \"No\", the group does not clear the hurdle for this exercise and will not have the opportunity to revise their work.\nFor our studio sessions on Wednesdays, it is essential that you bring your own device, such as a laptop or tablet. These sessions will involve hands-on activities that require access to software and online resources. Having your own device will allow you to fully participate and engage with the exercises. Please ensure your device is charged and ready to use at the start of each studio session. If you have any concerns about this requirement, please reach out to me in advance so we can make necessary arrangements."
  },
  {
    "objectID": "syllabus.html#computational-essay",
    "href": "syllabus.html#computational-essay",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Computational Essay",
    "text": "Computational Essay\nEach student will have the opportunity to write a computational essay using Jupyter notebooks to apply the methods of ESDA to a topic of their choice, approved by the instructor. The essay should demonstrate your ability to analyze spatial data, identify patterns, and interpret the results using ESDA techniques.\n\nInstructions\n\n1. Topic Selection\nSelect a topic of interest that involves spatial data. The topic should be relevant to your field of study or personal interest. Ensure that the data is accessible and suitable for spatial analysis. Submit your topic for approval by the instructor by September 30. If you are unsure about a topic, speak to the professor.\n\n\n2. Data Acquisition\nIdentify and acquire spatial data related to your chosen topic. This may include data from public repositories, government databases, or other reliable sources.\n\n\n3. ESDA Techniques\nApply appropriate ESDA methods such as spatial autocorrelation, clustering, and visualization techniques to explore your data. Use libraries like PySAL, GeoPandas, or others as needed.\n\n\n4. Analysis and Interpretation\nDocument your analysis in a Jupyter notebook. Include clear explanations of the methods used, the rationale behind your choices, and a discussion of your findings. Visualizations should be integrated into the narrative to support your analysis.\n\n\n5. Submission\nSubmit your Jupyter notebook along with a brief (500-word) reflection on what you learned from the analysis and how ESDA techniques enhanced your understanding of the topic. At submission you can indicate whether you wish to present your computational essay during the final period.\n\n\n\n\n\n\nImportant\n\n\n\nYou must demonstrate competency on each of the stages above to have the computational essay count towards your base grade.\n\n\n\n\n\nDeadline\nSubmit your completed essay by December 12, Midnight."
  },
  {
    "objectID": "syllabus.html#final-exam-activity",
    "href": "syllabus.html#final-exam-activity",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Final Exam Activity",
    "text": "Final Exam Activity\nOur final exam activity is scheduled for December 18 from 1-3pm. Students who applied to submit their computational essay will present during this period."
  },
  {
    "objectID": "syllabus.html#sec-tokens",
    "href": "syllabus.html#sec-tokens",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Tokens",
    "text": "Tokens\nEach student is provided with three tokens at the beginning of the semester.\n\nUsing Tokens\n\nCredit for a reading quiz that was failed (1 token).\nObtaining a one-day extension for a milestone prior to due date (1 token).\nHanding in a milestone activity one day late without permission (2 tokens).\nRevising a milestone that was submitted on-time but evaluated as \"Needing Revision\" (1 token).\nRevising a studio exercise that needs revision (1 token).\nRequesting a make-up date for the presentation by 2024-12-01 17:00 (3 tokens)\nMissing a studio session (3 tokens).\nAny tokens remaining after determination of the base grade will be used to determine the final course grade (see above).\n\nTo use a token you must complete a request using the token spending form.\n\n\nEarning Tokens\nAdditional tokens can be earned in several ways:\n\nSubmitting topics for discussion in lectures in our board\nAttending an in-person office hour to discuss a proposed question/topic\nAttending a geography colloquium (write a paragraph description)\nCompleting the python primer (3 tokens)\nIdentifying and reporting any errors in the course materials (1 token)"
  },
  {
    "objectID": "syllabus.html#policies",
    "href": "syllabus.html#policies",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Policies",
    "text": "Policies\n\nAccommodations\nIf you are a student with a disability and are in need of accommodations for this class, please contact Student Ability Success Center at (619) 594-6473 as soon as possible. Please know accommodations are not retroactive, and I cannot provide accommodations based upon disability until I have received an accommodation letter from Student Ability Success Center.\n\n\nPrivacy and Intellectual Property\nStudent Privacy and Intellectual Property: The Family Educational Rights and Privacy Act (FERPA) mandates the protection of student information, including contact information, grades, and graded assignments. I will use Canvas to communicate with you, and I will not post grades or leave graded assignments in public places. Students will be notified at the time of an assignment if copies of student work will be retained beyond the end of the semester or used as examples for future students or the wider public. Students maintain intellectual property rights to work products they create as part of this course unless they are formally notified otherwise.\n\n\nAcademic Integrity\nThe SDSU student academic integrity policy lists violations in detail. These violations fall into eight broad areas that include but are not limited to: cheating, fabrication, plagiarism, facilitating academic misconduct, unauthorized collaboration, interference or sabotage, non-compliance with research regulations and retaliation. For more information about the SDSU student academic integrity policy, please see the following: https://sacd.sdsu.edu/student-rights/academic-dishonesty.\n\n\nCode of Conduct\nAs course instructor, I am dedicated to providing a harassment-free learning experience for all students, regardless of gender, sexual orientation, disability, physical appearance, body size, race, religion, or choice of operating system. All course participants are expected to show respect and courtesy to other students throughout the semester. As a learning community we do not tolerate harassment of participants in any form.\n\nAll communication should be appropriate for a professional audience including people of many different backgrounds. Sexual language and imagery are not appropriate in this course.\nBe kind to others. Do not insult or put down other students. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are not appropriate for this course.\nStudents violating these rules may be asked to leave the course, and their violations will be reported to the SDSU administration.\n\nThis code of conduct is an adaptation of the SciPy 2018 Code of Conduct."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week01/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week01/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#eda-approach",
    "href": "lectures/week01/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week01/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#historical-context",
    "href": "lectures/week01/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#snow-map",
    "href": "lectures/week01/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#snow-map-1",
    "href": "lectures/week01/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week01/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#vector-data",
    "href": "lectures/week01/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#vector-data-1",
    "href": "lectures/week01/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#raster-data",
    "href": "lectures/week01/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#raster-data-1",
    "href": "lectures/week01/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#attribute-data",
    "href": "lectures/week01/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#attribute-data-1",
    "href": "lectures/week01/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week01/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week01/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#remote-sensing",
    "href": "lectures/week01/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week01/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week01/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week01/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week01/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week01/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week01/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week01/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week01/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week01/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#questions",
    "href": "lectures/week01/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#references",
    "href": "lectures/week01/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "lectures/week01/lecture.html#syllabus",
    "href": "lectures/week01/lecture.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus"
  },
  {
    "objectID": "lectures/week01/lecture.html#spatial-data-analysis",
    "href": "lectures/week01/lecture.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture"
  },
  {
    "objectID": "lectures/week07/global.html#toblers-first-law-of-geography",
    "href": "lectures/week07/global.html#toblers-first-law-of-geography",
    "title": "Global Spatial Autocorrelation",
    "section": "Tobler’s First Law of Geography",
    "text": "Tobler’s First Law of Geography\n\nEverything is related to everything else, but near things are more related than distant things.\n\n\nWaldo Tobler",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#tfl-blessing-or-curse",
    "href": "lectures/week07/global.html#tfl-blessing-or-curse",
    "title": "Global Spatial Autocorrelation",
    "section": "TFL: Blessing or Curse?",
    "text": "TFL: Blessing or Curse?",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#sources-of-spatial-variation",
    "href": "lectures/week07/global.html#sources-of-spatial-variation",
    "title": "Global Spatial Autocorrelation",
    "section": "Sources of Spatial Variation",
    "text": "Sources of Spatial Variation\n\nCompositional Influences\n\nDisease rates may reflect differences in age structure\nEconomic growth rates may reflect differences in industrial composition\n\nContextual Influences\n\nDisease rates may be due to exposure to pollutants\nEconomic growth may be due to differences in local labor markets/institutions",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#contextual-effects",
    "href": "lectures/week07/global.html#contextual-effects",
    "title": "Global Spatial Autocorrelation",
    "section": "Contextual Effects",
    "text": "Contextual Effects\n\nSpillovers\n\nhousing values\nretail price behavior\npolicy copy-catting\n\nContagion\n\ninfectious disease spread\npeer influences/networks\nneighborhoods provide role models",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#objectives-of-areal-data-analysis",
    "href": "lectures/week07/global.html#objectives-of-areal-data-analysis",
    "title": "Global Spatial Autocorrelation",
    "section": "Objectives of Areal Data Analysis",
    "text": "Objectives of Areal Data Analysis\n\nInfer whether there are a spatial trend or pattern in the attribute values recorded over the sub-regions\nFirst order variation: Trend in the mean\nSecond order variation: Spatial dependence",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#trend-in-the-mean",
    "href": "lectures/week07/global.html#trend-in-the-mean",
    "title": "Global Spatial Autocorrelation",
    "section": "Trend in the mean",
    "text": "Trend in the mean\n\nfrom geosnap import DataStore\nimport geopandas as gpd\n\ndatasets = DataStore()\n\nfrom geosnap.io import get_acs\nca = get_acs(datasets, state_fips=['06'], level='tract', years=[2016])\nsd = ca[ca.geoid.str.startswith('06073')]\nsd['lat'] = sd.geometry.centroid.y\nsd.plot('lat', scheme='quantiles', k=10, legend=True,\n        legend_kwds={'bbox_to_anchor': (1.3,1)});",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#second-order-variation",
    "href": "lectures/week07/global.html#second-order-variation",
    "title": "Global Spatial Autocorrelation",
    "section": "Second order variation",
    "text": "Second order variation\n\nsd['p_poverty_rate'] = sd.p_poverty_rate.fillna(0)\nsd.plot(column='p_poverty_rate', scheme='quantiles', k=10, legend=True,\n        legend_kwds={'bbox_to_anchor': (1.3,1)});",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#spatial-dependence",
    "href": "lectures/week07/global.html#spatial-dependence",
    "title": "Global Spatial Autocorrelation",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\nCategorizing\n\nType: Substantive versus nuisance\nDirection: Positive versus negative\n\nIssues\n\nTime versus space\nInference",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#substantive-spatial-dependence",
    "href": "lectures/week07/global.html#substantive-spatial-dependence",
    "title": "Global Spatial Autocorrelation",
    "section": "Substantive Spatial Dependence",
    "text": "Substantive Spatial Dependence\nProcess Based\n\nPart of the process under study\nLeaving it out\n\nIncomplete understanding\nBiased inferences",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#nuisance-spatial-dependence",
    "href": "lectures/week07/global.html#nuisance-spatial-dependence",
    "title": "Global Spatial Autocorrelation",
    "section": "Nuisance Spatial Dependence",
    "text": "Nuisance Spatial Dependence\nNot Process Based\n\nArtifact of data collection\nProcess boundaries not matching data boundaries\nScattering across pixels\nGIS induced",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#boundary",
    "href": "lectures/week07/global.html#boundary",
    "title": "Global Spatial Autocorrelation",
    "section": "Boundary",
    "text": "Boundary",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#boundary-mismatch",
    "href": "lectures/week07/global.html#boundary-mismatch",
    "title": "Global Spatial Autocorrelation",
    "section": "Boundary Mismatch",
    "text": "Boundary Mismatch\n\n\nEven if \\(A\\) and \\(B\\) are independent\n\\(A'\\) and \\(B'\\) will be dependent",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#nusiance-vs.-substantive-dependence",
    "href": "lectures/week07/global.html#nusiance-vs.-substantive-dependence",
    "title": "Global Spatial Autocorrelation",
    "section": "Nusiance vs. Substantive Dependence",
    "text": "Nusiance vs. Substantive Dependence\nIssues\n\nNot always easy to differentiate from substantive\nDifferent implications for each type\nSpecification strategies (Econometrics)\nBoth can be operating jointly",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#space-versus-time",
    "href": "lectures/week07/global.html#space-versus-time",
    "title": "Global Spatial Autocorrelation",
    "section": "Space versus Time",
    "text": "Space versus Time\nTemporal Dependence\n\nPast influences the future\nRecursive\nOne dimension",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#space-versus-time-1",
    "href": "lectures/week07/global.html#space-versus-time-1",
    "title": "Global Spatial Autocorrelation",
    "section": "Space versus Time",
    "text": "Space versus Time\nSpatial Dependence\n\nMulti-directional\nSimultaneous",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#hypotheses",
    "href": "lectures/week07/global.html#hypotheses",
    "title": "Global Spatial Autocorrelation",
    "section": "Hypotheses",
    "text": "Hypotheses\n\nNull Hypothesis (\\(H_o\\))\nAlternative Hypothesis (\\(H_a\\))",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#null-hypothesis-h_o",
    "href": "lectures/week07/global.html#null-hypothesis-h_o",
    "title": "Global Spatial Autocorrelation",
    "section": "Null Hypothesis (\\(H_o\\))",
    "text": "Null Hypothesis (\\(H_o\\))\n\nobserved spatial pattern of values is equally likely as any other spatial pattern\nvalues at one location do no depend on values at other (neighboring) locations\nunder spatial randomness, the location of values may be altered without affecting the information content of the data",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#alternative-hypothesis-h_a",
    "href": "lectures/week07/global.html#alternative-hypothesis-h_a",
    "title": "Global Spatial Autocorrelation",
    "section": "Alternative Hypothesis (\\(H_a\\))",
    "text": "Alternative Hypothesis (\\(H_a\\))\n\nthere is spatial autocorrelation in the data, indicating that the values of the variable are not randomly distributed over space, but instead exhibit some for of spatial dependence.\np-value = probability of getting such a pattern from a spatially random process\np-value != probability the process is random",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#forms-of-spatial-autocorrelation",
    "href": "lectures/week07/global.html#forms-of-spatial-autocorrelation",
    "title": "Global Spatial Autocorrelation",
    "section": "Forms of Spatial Autocorrelation",
    "text": "Forms of Spatial Autocorrelation",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#positive-spatial-autocorrelation",
    "href": "lectures/week07/global.html#positive-spatial-autocorrelation",
    "title": "Global Spatial Autocorrelation",
    "section": "Positive Spatial Autocorrelation",
    "text": "Positive Spatial Autocorrelation",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#positive-spatial-autocorrelation-1",
    "href": "lectures/week07/global.html#positive-spatial-autocorrelation-1",
    "title": "Global Spatial Autocorrelation",
    "section": "Positive Spatial Autocorrelation",
    "text": "Positive Spatial Autocorrelation\n\nClustering: like values tend to be in similar locations\n\nneighbor similarity\nmore alike than would be expected under spatial randomness\n\nCompatible with diffusion\n\nbut not necessarily caused by diffusion",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#negative-spatial-autocorrelation",
    "href": "lectures/week07/global.html#negative-spatial-autocorrelation",
    "title": "Global Spatial Autocorrelation",
    "section": "Negative Spatial Autocorrelation",
    "text": "Negative Spatial Autocorrelation",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#negative-spatial-autocorrelation-1",
    "href": "lectures/week07/global.html#negative-spatial-autocorrelation-1",
    "title": "Global Spatial Autocorrelation",
    "section": "Negative Spatial Autocorrelation",
    "text": "Negative Spatial Autocorrelation\n\nAnti-clustering\n\nneighbor dissimilarity\nmore dissimilar than they would be under spatial randomness\n\nCompatible with competition\n\nbut not necessarily caused by competition",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#spatial-autcorrelation-statistic",
    "href": "lectures/week07/global.html#spatial-autcorrelation-statistic",
    "title": "Global Spatial Autocorrelation",
    "section": "Spatial Autcorrelation Statistic",
    "text": "Spatial Autcorrelation Statistic\nStructure\n\nFormal test of match between value similarity and locational similarity\nStatistic summarizes both aspects\nSignificance\n\nhow likely is it (p-value) that the computed statistic would take this (extreme) value in a spatially random pattern",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#binary-variable",
    "href": "lectures/week07/global.html#binary-variable",
    "title": "Global Spatial Autocorrelation",
    "section": "Binary Variable",
    "text": "Binary Variable\n\nhigh_poverty = sd.p_poverty_rate &gt; sd.p_poverty_rate.median()\nsd['high_poverty'] = high_poverty * 1\nsd.plot(column='high_poverty', categorical=True, legend=True,\n        edgecolor='k')",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#explore",
    "href": "lectures/week07/global.html#explore",
    "title": "Global Spatial Autocorrelation",
    "section": "Explore",
    "text": "Explore\n\nsd.explore(column='p_poverty_rate', legend=True,\n           tooltip=['high_poverty', 'p_poverty_rate', 'geoid'])\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#spatial-joins",
    "href": "lectures/week07/global.html#spatial-joins",
    "title": "Global Spatial Autocorrelation",
    "section": "Spatial Joins",
    "text": "Spatial Joins\n\nfrom esda.join_counts import Join_Counts\nfrom libpysal.weights import Queen\nw = Queen.from_dataframe(sd)",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#joins",
    "href": "lectures/week07/global.html#joins",
    "title": "Global Spatial Autocorrelation",
    "section": "Joins",
    "text": "Joins\n\nw.s0 \n\nnp.float64(4018.0)\n\n\n\\[w.s0 = \\sum_i \\sum_j w_{i,j}\\]\n\nNumber of non-zero values in \\(w\\)\n2x the number of joins",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#neighbors",
    "href": "lectures/week07/global.html#neighbors",
    "title": "Global Spatial Autocorrelation",
    "section": "Neighbors",
    "text": "Neighbors\n\nimport numpy as np\nsd['neighbors'] = np.array(list(w.cardinalities.values()))\n\nsd.explore(column='p_poverty_rate', legend=True, \n           tooltip=['high_poverty', 'p_poverty_rate', 'geoid', 'neighbors']) \n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#spatial-lag",
    "href": "lectures/week07/global.html#spatial-lag",
    "title": "Global Spatial Autocorrelation",
    "section": "Spatial Lag",
    "text": "Spatial Lag\n\\(L_i = \\sum_{j} w_{i,j} B_j\\)\n\nthe spatial lag is the number of B neighbors\nif the focal unit is B, then it involved in as many BB joins as it has B neighbors\nif the focal unit is W(hite), it is involved in 0 BB joins",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#spatial-lag-1",
    "href": "lectures/week07/global.html#spatial-lag-1",
    "title": "Global Spatial Autocorrelation",
    "section": "Spatial Lag",
    "text": "Spatial Lag\n\nfrom libpysal.weights import lag_spatial\nsd['BNeighbors'] = lag_spatial(w, sd.high_poverty)\nsd.explore(column='p_poverty_rate', legend=True, \n           tooltip=['high_poverty', 'p_poverty_rate', 'geoid',\n                    'neighbors', 'BNeighbors']) \n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#join-counts-1",
    "href": "lectures/week07/global.html#join-counts-1",
    "title": "Global Spatial Autocorrelation",
    "section": "Join Counts",
    "text": "Join Counts\n\nfrom esda.join_counts import Join_Counts\nfrom libpysal.weights import Queen\nimport numpy as np\nnp.random.seed(12345)\nw = Queen.from_dataframe(sd)\njc = Join_Counts(sd.high_poverty, w)\njc.bb, jc.bw, jc.ww\n\n(np.float64(660.0), np.float64(667.0), np.float64(682.0))\n\n\n\\(BB =\\frac{1}{2} \\sum_i \\sum_j w_{i,j} B_i B_j = \\frac{1}{2} \\sum_i B_i L_i\\)",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#join-counts-inference",
    "href": "lectures/week07/global.html#join-counts-inference",
    "title": "Global Spatial Autocorrelation",
    "section": "Join Counts Inference",
    "text": "Join Counts Inference\n\njc.p_sim_bb, jc.mean_bb, jc.bb\n\n(np.float64(0.001), np.float64(502.2142142142142), np.float64(660.0))",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#morans-i-1",
    "href": "lectures/week07/global.html#morans-i-1",
    "title": "Global Spatial Autocorrelation",
    "section": "Moran’s I",
    "text": "Moran’s I\n\\[\nI = \\dfrac{n}{\\sum_i\\sum_j w_{ij}} \\dfrac{\\sum_i\\sum_j w_{i,j} \\, z_i \\, z_j}{\\sum_i z_i^2}\n\\]\n\n\\(z_i = y_i - \\bar{y}\\)\n\\(\\sum_i \\sum_j w_{i,j}z_i z_j = \\sum_i z_i \\sum_j w_{i,j} z_j = \\sum_i z_i l_i\\)",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#morans-i-2",
    "href": "lectures/week07/global.html#morans-i-2",
    "title": "Global Spatial Autocorrelation",
    "section": "Moran’s I",
    "text": "Moran’s I\n\nfrom esda.moran import Moran\nfrom libpysal.weights import Queen\nnp.random.seed(12345)\nmc = Moran(sd.p_poverty_rate, w, transformation='r')\nmc.I, mc.EI, mc.p_norm, mc.p_sim\n\n(np.float64(0.5345296697872074),\n -0.001594896331738437,\n np.float64(1.1152317274459047e-123),\n np.float64(0.001))",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#recap-of-key-points",
    "href": "lectures/week07/global.html#recap-of-key-points",
    "title": "Global Spatial Autocorrelation",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nSpatial Autocorrelation\nJoin Counts\nMoran’s I",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/global.html#questions",
    "href": "lectures/week07/global.html#questions",
    "title": "Global Spatial Autocorrelation",
    "section": "Questions",
    "text": "Questions",
    "crumbs": [
      "Home",
      "10-07 Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#imports",
    "href": "lectures/week06/spatial_weights.html#imports",
    "title": "Spatial Weights",
    "section": "Imports",
    "text": "Imports\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\n\n\nimport libpysal \nfrom libpysal.weights import Queen, Rook, KNN, Kernel, DistanceBand\nimport numpy as np\nimport geopandas\nimport pandas\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n\nfrom splot.libpysal import plot_spatial_weights\n\nThere are functions to construct weights directly from a file path.",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#weight-types",
    "href": "lectures/week06/spatial_weights.html#weight-types",
    "title": "Spatial Weights",
    "section": "Weight Types",
    "text": "Weight Types\n\nContiguity\nDistance Based Weights",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#contiguity-weights-1",
    "href": "lectures/week06/spatial_weights.html#contiguity-weights-1",
    "title": "Spatial Weights",
    "section": "Contiguity Weights",
    "text": "Contiguity Weights\n\nAlternative Definitions\nQueen\nRook\nBishop",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#queen-weights",
    "href": "lectures/week06/spatial_weights.html#queen-weights",
    "title": "Spatial Weights",
    "section": "Queen Weights",
    "text": "Queen Weights\nA commonly-used type of weight is a queen contigutiy weight, which reflects adjacency relationships as a binary indicator variable denoting whether or not a polygon shares an edge or a vertex with another polygon. These weights are symmetric, in that when polygon \\(A\\) neighbors polygon \\(B\\), both \\(w_{AB} = 1\\) and \\(w_{BA} = 1\\).",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#constructing-queen-weights",
    "href": "lectures/week06/spatial_weights.html#constructing-queen-weights",
    "title": "Spatial Weights",
    "section": "Constructing Queen Weights",
    "text": "Constructing Queen Weights\nTo construct queen weights from a shapefile, we will use geopandas to read the file into a GeoDataFrame, and then use libpysal to construct the weights:\n\npath = \"~/data/scag_region.parquet\"\ndf = geopandas.read_parquet(path)\ndf = df.to_crs(26911)  #UTM zone 11N\nqW = Queen.from_dataframe(df)\nqW\n\n&lt;libpysal.weights.contiguity.Queen at 0x795c71799450&gt;",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#weight-attributes",
    "href": "lectures/week06/spatial_weights.html#weight-attributes",
    "title": "Spatial Weights",
    "section": "Weight Attributes",
    "text": "Weight Attributes\nAll weights objects have a few traits that you can use to work with the weights object, as well as to get information about the weights object.\nTo get the neighbors & weights around an observation, use the observation’s index on the weights object, like a dictionary:\n\nqW[155] #neighbors & weights of the 156th observation (0-index remember)\n\n{4528: 1.0, 547: 1.0, 2133: 1.0, 2744: 1.0}",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#weights-matrix",
    "href": "lectures/week06/spatial_weights.html#weights-matrix",
    "title": "Spatial Weights",
    "section": "Weights Matrix",
    "text": "Weights Matrix\nA full, dense matrix describing all of the pairwise relationships is constructed using the .full method, or when libpysal.weights.full is called on a weights object:\n\nWmatrix, ids = qW.full()\n#Wmatrix, ids = libpysal.weights.full(qW)\n\n\nWmatrix\n\narray([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#number-of-neighbors",
    "href": "lectures/week06/spatial_weights.html#number-of-neighbors",
    "title": "Spatial Weights",
    "section": "Number of Neighbors",
    "text": "Number of Neighbors\n\nn_neighbors = Wmatrix.sum(axis=1) # how many neighbors each region has\n\n\nn_neighbors[155]\n\nnp.float64(4.0)\n\n\n\nqW.cardinalities[155]\n\n4\n\n\nNote that this matrix is binary, in that its elements are either zero or one, since an observation is either a neighbor or it is not a neighbor.",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#standardization",
    "href": "lectures/week06/spatial_weights.html#standardization",
    "title": "Spatial Weights",
    "section": "Standardization",
    "text": "Standardization\nHowever, many common use cases of spatial weights require that the matrix is row-standardized. This is done simply in PySAL using the .transform attribute\n\nqW.transform = 'r'\n\n('WARNING: ', 4285, ' is an island (no neighbors)')\n\n\nNow, if we build a new full matrix, its rows should sum to one:\n\nWmatrix, ids = qW.full()\n\n\nWmatrix.sum(axis=1) #numpy axes are 0:column, 1:row, 2:facet, into higher dimensions\n\narray([1., 1., 1., ..., 1., 1., 1.])",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#sparse-weights",
    "href": "lectures/week06/spatial_weights.html#sparse-weights",
    "title": "Spatial Weights",
    "section": "Sparse Weights",
    "text": "Sparse Weights\nSince weight matrices are typically very sparse, there is also a sparse weights matrix constructor:\n\nqW.sparse\n\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 29374 stored elements and shape (4580, 4580)&gt;\n\n\n\nqW.pct_nonzero #Percentage of nonzero neighbor counts\n\n0.14003356152628668",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#neighbors",
    "href": "lectures/week06/spatial_weights.html#neighbors",
    "title": "Spatial Weights",
    "section": "Neighbors",
    "text": "Neighbors\nLet’s look at the neighborhoods of the 101th observation\n\nqW.neighbors[100]\n\n[789, 790, 1991, 3676, 791]\n\n\n\nlen(qW.neighbors[100])\n\n5",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#plotting",
    "href": "lectures/week06/spatial_weights.html#plotting",
    "title": "Spatial Weights",
    "section": "Plotting",
    "text": "Plotting\n\nplot_spatial_weights(qW, df)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#connectivity-histogram",
    "href": "lectures/week06/spatial_weights.html#connectivity-histogram",
    "title": "Spatial Weights",
    "section": "Connectivity Histogram",
    "text": "Connectivity Histogram\n\npandas.Series(qW.cardinalities).plot.hist(bins=9)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#cardinalities",
    "href": "lectures/week06/spatial_weights.html#cardinalities",
    "title": "Spatial Weights",
    "section": "Cardinalities",
    "text": "Cardinalities\n\nqW.cardinalities.values()\n\ndict_values([9, 9, 4, 7, 7, 5, 5, 6, 5, 8, 9, 8, 4, 3, 5, 5, 6, 6, 4, 5, 5, 6, 7, 9, 6, 4, 7, 8, 7, 5, 7, 2, 6, 6, 8, 3, 7, 7, 5, 8, 6, 5, 5, 4, 6, 6, 7, 7, 4, 6, 7, 4, 5, 6, 13, 6, 7, 6, 8, 6, 6, 6, 2, 6, 6, 8, 6, 7, 7, 6, 3, 5, 6, 6, 3, 7, 6, 5, 5, 5, 8, 8, 6, 8, 9, 7, 7, 6, 7, 5, 5, 7, 7, 6, 5, 7, 8, 8, 4, 7, 5, 4, 4, 6, 9, 6, 6, 7, 4, 8, 6, 6, 5, 6, 6, 6, 6, 7, 6, 8, 6, 6, 6, 8, 6, 6, 5, 8, 4, 5, 7, 5, 5, 5, 5, 5, 2, 4, 4, 7, 6, 8, 6, 9, 4, 6, 7, 5, 5, 6, 6, 4, 8, 9, 7, 4, 8, 4, 6, 5, 5, 4, 5, 6, 7, 8, 4, 6, 5, 6, 6, 6, 4, 6, 7, 6, 5, 6, 7, 6, 7, 7, 7, 7, 3, 10, 6, 6, 7, 7, 5, 6, 7, 8, 6, 5, 9, 7, 9, 6, 6, 4, 6, 6, 5, 7, 7, 7, 6, 4, 7, 8, 7, 5, 6, 6, 4, 6, 6, 5, 9, 7, 5, 7, 4, 7, 7, 3, 6, 7, 5, 5, 6, 6, 5, 4, 6, 5, 5, 6, 5, 10, 4, 3, 6, 1, 8, 6, 4, 5, 5, 7, 6, 4, 7, 4, 5, 6, 6, 5, 10, 3, 5, 5, 9, 5, 7, 5, 5, 7, 5, 8, 4, 6, 5, 7, 7, 7, 5, 6, 7, 5, 3, 7, 5, 4, 6, 3, 5, 6, 5, 5, 5, 4, 4, 7, 7, 5, 5, 5, 7, 9, 6, 4, 4, 5, 7, 4, 4, 7, 4, 6, 6, 4, 8, 6, 7, 5, 8, 6, 7, 6, 8, 8, 4, 5, 7, 6, 3, 5, 5, 4, 6, 6, 7, 5, 5, 5, 3, 5, 7, 6, 8, 5, 5, 5, 7, 6, 6, 7, 3, 4, 8, 4, 7, 4, 6, 6, 4, 4, 4, 5, 3, 5, 6, 4, 6, 7, 8, 5, 6, 6, 6, 7, 5, 8, 5, 3, 5, 5, 6, 4, 7, 7, 7, 4, 6, 5, 6, 9, 4, 7, 5, 5, 5, 7, 4, 7, 8, 7, 7, 6, 5, 5, 7, 5, 9, 5, 5, 6, 4, 8, 6, 4, 5, 5, 5, 7, 6, 6, 3, 6, 7, 5, 4, 5, 5, 7, 7, 5, 4, 6, 6, 6, 5, 5, 5, 17, 7, 6, 6, 14, 5, 5, 6, 6, 4, 11, 7, 6, 4, 6, 5, 7, 6, 6, 4, 7, 4, 6, 4, 7, 7, 6, 8, 5, 6, 8, 6, 5, 8, 8, 6, 4, 5, 5, 3, 6, 4, 6, 6, 6, 5, 6, 4, 4, 6, 7, 7, 8, 4, 5, 17, 7, 5, 6, 5, 7, 8, 6, 4, 7, 5, 7, 6, 4, 4, 5, 5, 4, 4, 4, 5, 3, 5, 4, 5, 3, 4, 5, 7, 7, 4, 7, 5, 4, 5, 12, 9, 9, 5, 4, 6, 7, 6, 6, 3, 8, 4, 8, 4, 6, 8, 4, 6, 5, 9, 6, 7, 4, 4, 8, 7, 4, 8, 5, 5, 7, 6, 5, 7, 4, 8, 6, 5, 8, 6, 6, 6, 6, 4, 5, 6, 8, 5, 8, 5, 8, 5, 8, 8, 6, 8, 7, 6, 7, 6, 5, 5, 7, 9, 3, 6, 8, 8, 7, 8, 5, 4, 6, 5, 6, 9, 7, 6, 7, 8, 3, 6, 6, 4, 7, 6, 5, 3, 5, 5, 8, 6, 8, 3, 8, 6, 8, 6, 6, 5, 8, 4, 8, 8, 7, 4, 5, 6, 6, 7, 7, 7, 5, 7, 4, 8, 6, 8, 8, 6, 4, 5, 7, 6, 6, 7, 5, 7, 8, 4, 6, 7, 6, 6, 8, 7, 7, 4, 4, 8, 7, 7, 8, 11, 6, 7, 6, 10, 5, 6, 6, 6, 4, 5, 5, 8, 7, 4, 7, 6, 8, 6, 7, 6, 7, 7, 6, 6, 5, 6, 6, 6, 5, 7, 9, 4, 5, 6, 6, 5, 6, 7, 5, 10, 5, 7, 4, 5, 4, 5, 5, 5, 6, 10, 6, 6, 6, 5, 6, 7, 4, 4, 6, 6, 8, 6, 7, 8, 8, 6, 3, 5, 6, 5, 7, 5, 5, 7, 8, 6, 7, 5, 5, 6, 6, 6, 5, 6, 6, 8, 5, 8, 4, 6, 8, 4, 5, 3, 5, 5, 8, 5, 8, 7, 8, 7, 6, 10, 5, 7, 4, 4, 3, 9, 4, 6, 5, 4, 7, 7, 6, 9, 4, 6, 5, 5, 7, 5, 5, 9, 5, 6, 6, 5, 6, 5, 7, 5, 8, 8, 6, 7, 5, 7, 5, 5, 7, 7, 4, 7, 8, 6, 8, 7, 5, 7, 10, 5, 4, 7, 5, 6, 7, 7, 5, 5, 4, 6, 5, 6, 6, 7, 5, 7, 7, 6, 6, 5, 6, 4, 4, 6, 5, 6, 5, 6, 6, 5, 4, 5, 9, 9, 4, 5, 8, 6, 8, 5, 7, 7, 6, 6, 4, 9, 8, 6, 10, 5, 7, 6, 3, 6, 6, 8, 7, 5, 7, 5, 6, 8, 5, 6, 5, 5, 7, 4, 5, 4, 4, 5, 4, 5, 7, 5, 7, 6, 5, 7, 7, 6, 7, 6, 7, 7, 6, 7, 4, 4, 6, 7, 4, 6, 7, 8, 6, 8, 8, 2, 7, 4, 9, 5, 7, 7, 4, 6, 6, 4, 5, 5, 5, 9, 6, 8, 6, 9, 9, 7, 7, 5, 7, 5, 5, 5, 5, 4, 7, 6, 5, 6, 9, 6, 4, 6, 5, 6, 7, 6, 6, 4, 5, 3, 7, 4, 5, 6, 10, 4, 7, 6, 4, 6, 6, 8, 5, 6, 6, 7, 6, 6, 4, 7, 6, 7, 8, 6, 6, 7, 9, 6, 6, 9, 6, 8, 3, 5, 7, 8, 9, 7, 5, 5, 7, 7, 7, 6, 5, 6, 7, 7, 3, 6, 6, 5, 9, 5, 8, 7, 5, 6, 5, 7, 7, 7, 6, 6, 8, 6, 5, 6, 7, 3, 6, 6, 8, 7, 6, 8, 5, 7, 6, 5, 6, 7, 4, 4, 7, 5, 20, 6, 5, 6, 6, 6, 7, 5, 6, 7, 5, 4, 5, 4, 9, 4, 7, 6, 8, 7, 5, 5, 5, 5, 7, 5, 6, 6, 5, 3, 5, 4, 6, 8, 6, 2, 7, 5, 5, 5, 6, 8, 7, 7, 7, 8, 7, 6, 5, 5, 6, 5, 6, 5, 7, 6, 7, 4, 6, 4, 5, 7, 5, 9, 6, 7, 7, 5, 10, 8, 5, 5, 5, 7, 6, 6, 7, 6, 7, 6, 5, 4, 5, 5, 6, 7, 10, 4, 4, 6, 6, 8, 7, 5, 6, 6, 9, 5, 5, 6, 6, 8, 5, 7, 6, 4, 9, 7, 5, 5, 6, 5, 16, 5, 4, 6, 4, 8, 8, 6, 6, 7, 7, 5, 10, 7, 6, 7, 6, 7, 5, 7, 5, 7, 6, 7, 6, 4, 8, 6, 7, 6, 6, 5, 4, 4, 5, 9, 4, 8, 8, 7, 6, 6, 11, 6, 4, 6, 6, 4, 7, 5, 6, 7, 5, 5, 3, 7, 5, 5, 3, 6, 6, 9, 5, 8, 8, 3, 6, 5, 5, 8, 5, 5, 7, 5, 9, 8, 9, 6, 6, 6, 7, 8, 8, 7, 6, 7, 9, 4, 8, 9, 9, 7, 7, 8, 6, 5, 6, 5, 5, 6, 5, 5, 8, 6, 7, 5, 7, 4, 7, 5, 10, 7, 8, 5, 6, 9, 9, 9, 10, 4, 5, 6, 9, 4, 5, 6, 6, 5, 6, 8, 9, 9, 9, 10, 7, 9, 5, 3, 6, 7, 7, 9, 7, 8, 9, 8, 7, 8, 6, 7, 6, 9, 9, 5, 8, 3, 3, 7, 5, 7, 9, 9, 8, 7, 7, 10, 6, 8, 7, 6, 8, 6, 8, 5, 5, 5, 4, 5, 7, 8, 9, 7, 3, 6, 4, 7, 7, 7, 6, 10, 6, 7, 8, 7, 10, 9, 7, 6, 8, 5, 7, 7, 6, 5, 5, 5, 7, 5, 6, 4, 5, 6, 4, 9, 7, 4, 6, 4, 9, 9, 6, 8, 5, 9, 6, 9, 6, 7, 7, 6, 5, 10, 10, 7, 7, 7, 7, 8, 6, 3, 7, 4, 5, 6, 4, 10, 9, 5, 8, 6, 9, 5, 7, 5, 7, 5, 8, 8, 9, 9, 13, 7, 7, 8, 6, 1, 7, 6, 5, 6, 7, 9, 5, 7, 6, 4, 4, 3, 7, 8, 6, 7, 8, 6, 4, 6, 9, 8, 6, 6, 6, 8, 7, 7, 5, 5, 2, 3, 7, 6, 6, 6, 8, 5, 5, 6, 4, 5, 7, 8, 6, 9, 4, 5, 5, 3, 5, 10, 5, 15, 4, 6, 9, 8, 8, 7, 5, 8, 7, 8, 9, 8, 7, 5, 6, 8, 4, 9, 6, 9, 6, 6, 6, 5, 7, 10, 11, 11, 6, 5, 6, 7, 4, 5, 11, 16, 5, 7, 9, 7, 6, 7, 7, 6, 5, 9, 6, 10, 7, 5, 7, 6, 5, 3, 8, 3, 11, 5, 5, 9, 9, 7, 6, 6, 8, 10, 6, 10, 4, 8, 7, 4, 7, 4, 5, 9, 4, 5, 9, 9, 6, 6, 8, 9, 9, 4, 7, 10, 16, 7, 11, 7, 11, 5, 8, 9, 5, 11, 7, 5, 7, 5, 5, 7, 8, 9, 5, 11, 11, 7, 8, 6, 5, 6, 5, 7, 9, 4, 7, 8, 7, 8, 4, 6, 7, 9, 9, 8, 6, 4, 7, 4, 6, 7, 6, 8, 6, 7, 4, 8, 5, 7, 7, 10, 7, 7, 6, 4, 6, 6, 13, 3, 8, 9, 6, 4, 6, 5, 6, 12, 5, 2, 6, 5, 7, 6, 7, 8, 5, 7, 4, 6, 7, 10, 3, 17, 10, 8, 6, 5, 7, 14, 1, 12, 8, 4, 4, 8, 8, 4, 8, 6, 8, 6, 5, 3, 8, 6, 7, 8, 6, 9, 8, 5, 11, 5, 3, 7, 5, 4, 5, 3, 7, 7, 6, 5, 8, 2, 5, 6, 11, 8, 6, 6, 7, 6, 7, 6, 6, 4, 4, 6, 9, 6, 9, 6, 5, 4, 3, 5, 8, 7, 10, 4, 6, 7, 4, 6, 6, 4, 6, 4, 8, 6, 10, 8, 5, 8, 6, 4, 6, 6, 5, 11, 4, 7, 8, 7, 6, 5, 5, 10, 16, 8, 5, 7, 9, 3, 7, 5, 3, 4, 8, 6, 6, 7, 6, 9, 7, 7, 6, 6, 11, 7, 7, 8, 6, 6, 7, 4, 7, 6, 3, 7, 7, 6, 8, 15, 7, 6, 4, 6, 9, 6, 6, 6, 10, 7, 8, 4, 9, 11, 6, 6, 6, 4, 11, 6, 5, 5, 5, 5, 7, 5, 5, 5, 4, 4, 8, 4, 6, 5, 7, 8, 6, 7, 5, 6, 7, 7, 6, 4, 10, 5, 6, 7, 5, 4, 7, 5, 6, 5, 7, 5, 5, 10, 6, 5, 5, 3, 7, 5, 6, 6, 6, 7, 5, 4, 7, 6, 11, 6, 8, 6, 9, 5, 14, 4, 5, 13, 8, 6, 7, 4, 7, 5, 9, 5, 8, 4, 7, 7, 8, 7, 4, 7, 5, 10, 8, 9, 5, 7, 6, 4, 7, 8, 8, 12, 7, 6, 8, 10, 5, 7, 6, 6, 6, 5, 5, 5, 6, 9, 5, 7, 4, 7, 8, 5, 7, 6, 5, 7, 7, 4, 4, 6, 7, 7, 6, 8, 6, 5, 4, 6, 5, 5, 4, 6, 6, 6, 7, 5, 4, 6, 3, 6, 7, 1, 7, 11, 4, 4, 12, 7, 6, 8, 5, 7, 8, 3, 6, 5, 5, 5, 9, 6, 9, 6, 5, 3, 7, 6, 8, 8, 9, 7, 5, 7, 6, 6, 5, 5, 10, 4, 8, 5, 8, 4, 5, 6, 5, 14, 8, 1, 5, 6, 7, 8, 10, 4, 7, 5, 9, 5, 5, 7, 4, 4, 7, 5, 8, 6, 9, 6, 8, 7, 4, 6, 4, 7, 5, 4, 6, 3, 7, 6, 6, 7, 11, 8, 6, 7, 8, 5, 7, 7, 9, 6, 5, 6, 6, 8, 6, 9, 7, 7, 7, 8, 5, 5, 5, 9, 6, 5, 4, 7, 7, 5, 7, 5, 5, 6, 8, 6, 5, 6, 4, 6, 6, 7, 7, 5, 6, 9, 6, 5, 6, 5, 8, 9, 7, 11, 7, 11, 15, 6, 7, 8, 3, 10, 8, 10, 8, 8, 4, 6, 5, 7, 6, 5, 6, 6, 7, 5, 9, 9, 9, 7, 11, 6, 6, 6, 5, 6, 6, 8, 6, 7, 5, 7, 8, 10, 10, 9, 7, 3, 9, 10, 7, 7, 6, 10, 6, 6, 7, 4, 7, 4, 5, 6, 6, 5, 5, 7, 8, 7, 4, 7, 7, 7, 7, 7, 7, 7, 6, 7, 6, 7, 7, 8, 7, 7, 5, 8, 10, 8, 7, 7, 6, 6, 8, 7, 6, 5, 6, 6, 9, 6, 2, 7, 7, 7, 7, 6, 7, 7, 4, 9, 12, 5, 5, 5, 5, 4, 9, 5, 7, 6, 7, 6, 4, 8, 7, 7, 7, 3, 5, 6, 5, 5, 7, 8, 6, 9, 4, 5, 6, 7, 5, 4, 6, 9, 5, 6, 10, 10, 6, 8, 5, 6, 4, 7, 8, 8, 5, 4, 9, 6, 4, 6, 5, 7, 5, 7, 6, 4, 10, 5, 6, 5, 5, 4, 6, 4, 6, 16, 8, 3, 7, 6, 5, 5, 5, 7, 7, 6, 9, 7, 6, 6, 6, 8, 3, 8, 4, 5, 5, 6, 6, 8, 9, 4, 7, 8, 7, 5, 6, 6, 6, 12, 4, 5, 6, 7, 7, 4, 8, 5, 7, 6, 7, 7, 9, 8, 7, 6, 7, 7, 6, 7, 5, 6, 3, 6, 5, 3, 6, 10, 7, 6, 6, 6, 6, 13, 10, 6, 8, 4, 6, 5, 7, 8, 6, 7, 5, 8, 7, 7, 8, 13, 5, 10, 7, 6, 7, 7, 6, 7, 7, 7, 8, 4, 9, 7, 4, 5, 4, 6, 8, 8, 6, 10, 3, 5, 10, 8, 6, 6, 11, 7, 6, 6, 5, 5, 8, 4, 6, 4, 13, 4, 11, 7, 5, 7, 6, 6, 7, 5, 5, 6, 5, 10, 5, 5, 8, 10, 10, 6, 6, 7, 6, 8, 5, 5, 2, 5, 5, 11, 6, 6, 8, 13, 2, 3, 5, 4, 6, 5, 4, 5, 5, 5, 11, 5, 8, 7, 8, 7, 5, 6, 5, 6, 10, 3, 9, 5, 4, 6, 6, 9, 8, 6, 9, 6, 7, 5, 6, 3, 6, 9, 8, 7, 7, 4, 5, 8, 5, 8, 8, 7, 6, 8, 14, 6, 4, 7, 3, 9, 5, 6, 5, 5, 6, 7, 3, 9, 9, 5, 6, 6, 4, 4, 9, 7, 5, 4, 5, 15, 8, 7, 9, 6, 6, 5, 7, 6, 8, 4, 4, 5, 5, 3, 5, 3, 4, 4, 4, 7, 12, 8, 9, 9, 6, 3, 6, 4, 7, 7, 9, 4, 6, 9, 5, 7, 5, 10, 5, 10, 6, 9, 4, 6, 8, 5, 8, 12, 10, 5, 7, 6, 7, 10, 7, 9, 6, 7, 5, 6, 6, 8, 6, 6, 8, 4, 6, 6, 9, 6, 6, 7, 4, 4, 3, 8, 10, 6, 6, 25, 8, 8, 5, 5, 4, 7, 7, 5, 7, 6, 7, 7, 6, 6, 5, 8, 6, 6, 7, 6, 8, 5, 4, 5, 8, 6, 12, 6, 7, 8, 4, 4, 7, 7, 9, 9, 14, 3, 10, 6, 6, 5, 7, 14, 5, 8, 4, 8, 8, 6, 6, 4, 6, 10, 14, 8, 5, 7, 6, 9, 5, 6, 7, 7, 5, 7, 5, 6, 9, 6, 6, 8, 7, 3, 6, 5, 9, 4, 4, 6, 13, 4, 6, 4, 5, 5, 7, 6, 7, 14, 3, 5, 11, 6, 7, 7, 7, 5, 5, 6, 14, 7, 7, 7, 5, 3, 4, 8, 4, 6, 8, 2, 6, 10, 5, 12, 8, 9, 6, 5, 13, 6, 8, 5, 2, 5, 1, 5, 6, 5, 5, 4, 9, 6, 7, 3, 8, 5, 6, 7, 6, 7, 8, 7, 3, 8, 6, 7, 5, 7, 7, 6, 5, 7, 11, 9, 6, 6, 3, 4, 9, 8, 8, 8, 6, 5, 6, 5, 7, 15, 8, 10, 9, 10, 6, 5, 7, 6, 10, 6, 5, 12, 5, 5, 8, 8, 9, 4, 7, 4, 4, 8, 15, 6, 4, 12, 6, 6, 4, 6, 6, 8, 4, 7, 8, 6, 6, 8, 4, 5, 9, 7, 6, 6, 7, 7, 6, 6, 7, 9, 6, 7, 6, 8, 5, 5, 5, 10, 8, 6, 6, 7, 5, 6, 6, 6, 8, 8, 7, 6, 8, 5, 6, 7, 7, 7, 4, 7, 6, 6, 4, 11, 4, 7, 6, 5, 9, 10, 8, 6, 7, 6, 7, 6, 6, 7, 4, 7, 7, 5, 7, 7, 6, 9, 6, 6, 6, 7, 8, 4, 5, 3, 7, 5, 6, 8, 6, 6, 6, 16, 6, 5, 15, 10, 6, 7, 9, 7, 7, 8, 5, 9, 6, 5, 5, 4, 9, 11, 6, 6, 6, 8, 5, 5, 6, 4, 5, 7, 8, 8, 5, 4, 3, 8, 5, 4, 4, 5, 5, 6, 5, 3, 10, 8, 5, 9, 9, 6, 5, 3, 5, 6, 7, 7, 8, 5, 8, 6, 6, 4, 5, 4, 5, 9, 9, 4, 7, 5, 6, 9, 7, 4, 8, 8, 7, 6, 10, 7, 8, 11, 5, 7, 5, 6, 7, 9, 8, 7, 7, 8, 10, 3, 4, 6, 7, 7, 5, 7, 6, 5, 6, 9, 10, 3, 7, 5, 7, 8, 9, 5, 6, 2, 9, 7, 7, 4, 6, 6, 9, 7, 9, 6, 6, 7, 6, 7, 6, 5, 7, 8, 8, 5, 6, 6, 8, 6, 6, 6, 8, 7, 8, 6, 6, 8, 5, 7, 8, 4, 6, 5, 7, 8, 7, 7, 9, 5, 1, 8, 7, 5, 5, 7, 8, 5, 8, 6, 6, 4, 6, 6, 6, 7, 5, 5, 4, 7, 7, 7, 7, 6, 7, 5, 6, 6, 7, 6, 5, 6, 7, 9, 6, 7, 7, 4, 7, 7, 5, 6, 8, 5, 7, 7, 7, 7, 6, 7, 6, 14, 6, 9, 9, 10, 5, 6, 7, 7, 9, 4, 8, 10, 4, 8, 6, 5, 5, 6, 6, 6, 7, 7, 6, 3, 5, 10, 8, 9, 6, 8, 1, 4, 6, 7, 5, 7, 8, 7, 7, 7, 6, 5, 7, 5, 4, 10, 7, 9, 5, 8, 10, 7, 5, 9, 6, 6, 7, 8, 7, 7, 6, 7, 5, 6, 5, 8, 9, 6, 6, 6, 10, 5, 6, 7, 6, 8, 6, 7, 7, 6, 9, 5, 8, 4, 5, 7, 6, 5, 4, 4, 7, 8, 5, 5, 7, 5, 8, 7, 9, 6, 10, 6, 8, 8, 6, 7, 6, 6, 7, 9, 6, 5, 5, 8, 6, 7, 10, 6, 4, 14, 3, 6, 6, 8, 8, 7, 9, 6, 6, 10, 6, 8, 7, 6, 8, 6, 4, 5, 5, 5, 8, 4, 4, 6, 4, 6, 11, 4, 5, 6, 4, 6, 7, 5, 5, 3, 5, 6, 6, 9, 8, 9, 6, 6, 6, 6, 6, 8, 7, 7, 6, 4, 6, 5, 8, 6, 6, 5, 7, 8, 5, 7, 7, 6, 7, 3, 7, 4, 6, 5, 6, 5, 6, 6, 7, 10, 6, 6, 9, 7, 14, 6, 5, 7, 9, 8, 8, 9, 5, 4, 9, 4, 6, 5, 6, 8, 7, 6, 5, 5, 6, 5, 6, 7, 6, 6, 7, 7, 7, 6, 7, 6, 7, 6, 11, 6, 7, 7, 5, 4, 7, 6, 9, 7, 3, 6, 8, 5, 6, 3, 6, 7, 6, 3, 7, 11, 5, 7, 6, 6, 5, 6, 5, 7, 6, 8, 8, 9, 6, 6, 6, 7, 7, 10, 7, 9, 7, 6, 9, 8, 7, 6, 6, 5, 7, 8, 5, 7, 6, 6, 6, 9, 7, 4, 8, 7, 8, 7, 6, 6, 10, 5, 8, 4, 8, 5, 6, 7, 7, 7, 8, 7, 6, 9, 6, 7, 5, 4, 5, 7, 7, 5, 7, 7, 6, 6, 5, 7, 6, 5, 7, 5, 6, 8, 8, 5, 5, 5, 10, 6, 5, 6, 4, 9, 5, 6, 9, 8, 8, 7, 6, 8, 10, 6, 11, 6, 5, 10, 6, 8, 8, 7, 6, 10, 5, 7, 9, 6, 4, 8, 9, 7, 6, 6, 6, 5, 10, 6, 9, 5, 7, 7, 8, 6, 7, 5, 7, 6, 4, 7, 6, 8, 8, 5, 7, 6, 4, 7, 4, 5, 8, 5, 5, 9, 8, 5, 8, 6, 4, 7, 5, 3, 6, 6, 4, 7, 3, 5, 4, 4, 7, 8, 8, 7, 10, 8, 6, 6, 7, 5, 6, 5, 7, 8, 4, 7, 9, 5, 7, 5, 5, 7, 7, 7, 5, 5, 5, 6, 9, 6, 6, 8, 7, 5, 5, 7, 6, 8, 6, 8, 10, 9, 7, 8, 5, 6, 6, 7, 6, 8, 7, 6, 8, 5, 7, 5, 6, 7, 6, 5, 8, 5, 7, 3, 7, 6, 7, 8, 8, 4, 6, 2, 8, 6, 6, 5, 7, 5, 8, 8, 9, 7, 7, 7, 8, 7, 8, 6, 5, 8, 11, 10, 7, 7, 4, 6, 8, 5, 4, 8, 3, 5, 6, 8, 9, 7, 4, 5, 8, 8, 5, 5, 6, 6, 6, 7, 9, 6, 6, 11, 4, 7, 5, 9, 9, 6, 8, 6, 6, 5, 5, 8, 7, 7, 5, 7, 6, 12, 7, 6, 7, 5, 1, 10, 5, 3, 7, 5, 5, 6, 6, 7, 8, 8, 7, 5, 3, 5, 7, 7, 8, 9, 4, 5, 8, 8, 6, 5, 7, 7, 6, 7, 5, 8, 11, 5, 5, 4, 5, 5, 1, 9, 6, 9, 9, 5, 6, 7, 7, 9, 6, 7, 7, 7, 5, 4, 5, 6, 6, 5, 6, 4, 6, 6, 5, 5, 3, 5, 7, 4, 6, 4, 8, 6, 6, 6, 6, 6, 7, 4, 3, 4, 12, 6, 6, 6, 6, 8, 6, 6, 7, 12, 8, 5, 11, 4, 6, 6, 5, 6, 7, 6, 5, 7, 7, 10, 6, 5, 7, 6, 5, 6, 6, 6, 6, 5, 10, 19, 7, 7, 8, 5, 6, 9, 6, 6, 12, 5, 4, 5, 3, 12, 4, 6, 4, 7, 4, 9, 4, 5, 3, 4, 7, 9, 6, 5, 7, 8, 5, 6, 5, 4, 8, 7, 5, 7, 5, 4, 7, 6, 4, 7, 5, 5, 7, 6, 7, 8, 11, 5, 5, 8, 3, 5, 4, 6, 6, 3, 7, 7, 5, 6, 9, 12, 7, 5, 5, 6, 9, 5, 7, 10, 6, 9, 5, 6, 6, 6, 7, 8, 6, 5, 7, 5, 7, 5, 5, 5, 8, 6, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 6, 10, 8, 7, 7, 5, 6, 6, 5, 12, 7, 8, 6, 6, 5, 8, 5, 5, 5, 5, 6, 5, 9, 10, 6, 6, 5, 4, 5, 4, 6, 6, 5, 7, 5, 7, 7, 4, 7, 5, 9, 6, 6, 4, 6, 6, 6, 5, 6, 6, 6, 6, 4, 8, 3, 5, 9, 7, 9, 6, 4, 12, 6, 7, 6, 7, 6, 8, 16, 7, 7, 5, 10, 7, 8, 6, 6, 7, 7, 11, 6, 11, 5, 6, 9, 5, 8, 6, 7, 5, 6, 7, 6, 8, 9, 7, 2, 10, 5, 7, 6, 7, 6, 6, 6, 6, 10, 4, 4, 6, 8, 6, 6, 9, 7, 6, 2, 6, 7, 5, 7, 5, 15, 8, 6, 8, 4, 6, 7, 7, 7, 8, 8, 7, 5, 5, 6, 5, 7, 7, 7, 5, 6, 9, 8, 9, 5, 6, 4, 6, 5, 5, 7, 5, 8, 5, 4, 5, 5, 7, 7, 7, 5, 6, 8, 9, 4, 6, 6, 11, 6, 8, 9, 6, 5, 6, 6, 8, 6, 5, 7, 6, 5, 7, 4, 9, 5, 4, 6, 6, 6, 3, 7, 6, 6, 5, 13, 7, 6, 8, 5, 7, 5, 5, 8, 7, 7, 7, 7, 6, 9, 10, 8, 9, 6, 6, 7, 10, 6, 7, 7, 6, 6, 6, 6, 5, 7, 7, 5, 6, 4, 6, 7, 9, 8, 4, 9, 5, 5, 6, 4, 7, 8, 9, 7, 2, 4, 7, 7, 7, 7, 7, 11, 8, 9, 6, 4, 6, 6, 5, 8, 7, 7, 6, 7, 8, 8, 8, 6, 6, 8, 9, 8, 9, 7, 7, 5, 7, 5, 9, 6, 4, 6, 7, 4, 9, 7, 4, 4, 5, 9, 10, 8, 10, 9, 5, 6, 6, 5, 7, 7, 6, 5, 6, 9, 8, 7, 4, 6, 6, 7, 4, 5, 7, 7, 5, 9, 6, 7, 6, 9, 9, 8, 7, 8, 5, 3, 4, 11, 14, 5, 5, 4, 3, 6, 6, 5, 6, 7, 6, 8, 8, 9, 7, 6, 2, 6, 6, 5, 5, 5, 3, 8, 8, 11, 7, 6, 7, 6, 6, 7, 8, 6, 7, 7, 6, 6, 8, 8, 5, 5, 16, 8, 6, 7, 9, 5, 8, 6, 5, 4, 7, 5, 6, 8, 7, 5, 6, 7, 6, 6, 7, 10, 7, 10, 9, 8, 7, 5, 8, 5, 8, 7, 7, 9, 9, 5, 7, 6, 6, 5, 7, 5, 6, 8, 7, 6, 6, 10, 6, 5, 5, 8, 5, 7, 5, 5, 7, 6, 6, 5, 6, 0, 6, 11, 5, 5, 9, 6, 5, 9, 5, 6, 6, 6, 6, 6, 7, 7, 11, 10, 4, 7, 5, 8, 8, 8, 5, 6, 6, 7, 8, 7, 8, 5, 5, 5, 6, 7, 7, 5, 8, 5, 5, 5, 10, 8, 5, 10, 5, 4, 5, 5, 6, 5, 9, 5, 4, 5, 7, 4, 4, 6, 15, 7, 6, 8, 7, 10, 7, 7, 5, 6, 7, 6, 6, 6, 8, 5, 6, 4, 2, 6, 5, 8, 8, 5, 6, 5, 7, 10, 7, 8, 7, 6, 8, 7, 11, 7, 6, 6, 8, 7, 10, 16, 6, 7, 6, 4, 5, 4, 4, 7, 8, 8, 5, 6, 4, 6, 3, 5, 9, 8, 4, 6, 4, 6, 3, 6, 9, 7, 8, 3, 14, 6, 8, 4, 7, 6, 5, 6, 4, 8, 5, 7, 7, 7, 7, 5, 5, 7, 5, 6, 6, 7, 7, 7, 7, 4, 11, 6, 7, 4, 3, 13, 5, 8, 9, 8, 6, 8, 7, 7, 6, 7, 8, 6, 6, 9, 5, 8, 6, 7, 11, 6, 5, 8, 7, 9, 5, 7, 5, 7, 8, 4, 4, 8, 5, 7, 5, 5, 6, 7, 9, 7, 6, 11, 8, 3, 5, 7, 11, 4, 6, 7, 7, 7, 6, 5, 5, 7, 5, 6, 6, 7, 6, 5, 7, 8, 6, 5, 7, 14, 10, 6, 7, 7, 5, 6, 11, 5, 6, 5, 10, 4, 3, 6, 5, 8, 6, 6, 6, 7, 7, 8, 5, 7, 6, 5, 8, 7, 9, 6, 5, 6, 8, 5, 7, 7, 7, 6, 7, 6, 8, 5, 7, 9, 8, 5, 7, 5, 8, 8, 9, 12, 7, 4, 7, 10, 8, 7, 7, 6, 6, 7, 6, 7])",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#rook-weights",
    "href": "lectures/week06/spatial_weights.html#rook-weights",
    "title": "Spatial Weights",
    "section": "Rook Weights",
    "text": "Rook Weights\nRook weights are another type of contiguity weight, but consider observations as neighboring only when they share an edge. The rook neighbors of an observation may be different than its queen neighbors, depending on how the observation and its nearby polygons are configured.\nWe can construct this in the same way as the queen weights:\n\nrW = Rook.from_dataframe(df)\n\n\nrW.neighbors[100]\n\n[789, 790, 1991, 791, 3676]\n\n\n\nlen(rW.neighbors[100])\n\n5",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#rook-graph",
    "href": "lectures/week06/spatial_weights.html#rook-graph",
    "title": "Spatial Weights",
    "section": "Rook Graph",
    "text": "Rook Graph\n\nplot_spatial_weights(rW, df)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#connectivity-histogram-1",
    "href": "lectures/week06/spatial_weights.html#connectivity-histogram-1",
    "title": "Spatial Weights",
    "section": "Connectivity Histogram",
    "text": "Connectivity Histogram\n\npandas.Series(rW.cardinalities).plot.hist(bins=9)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#bishop-weights",
    "href": "lectures/week06/spatial_weights.html#bishop-weights",
    "title": "Spatial Weights",
    "section": "Bishop Weights",
    "text": "Bishop Weights\nIn theory, a “Bishop” weighting scheme is one that arises when only polygons that share vertexes are considered to be neighboring. But, since Queen contiguigy requires either an edge or a vertex and Rook contiguity requires only shared edges, the following relationship is true:\n\\[ \\mathcal{Q} = \\mathcal{R} \\cup \\mathcal{B} \\]\nwhere \\(\\mathcal{Q}\\) is the set of neighbor pairs via queen contiguity, \\(\\mathcal{R}\\) is the set of neighbor pairs via Rook contiguity, and \\(\\mathcal{B}\\) via Bishop contiguity.",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#bishop-weights-1",
    "href": "lectures/week06/spatial_weights.html#bishop-weights-1",
    "title": "Spatial Weights",
    "section": "Bishop Weights",
    "text": "Bishop Weights\n\\[ \\mathcal{Q} \\setminus \\mathcal{R} = \\mathcal{B}\\]\nBishop weights entail all Queen neighbor pairs that are not also Rook neighbors.",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#bishop-weights-2",
    "href": "lectures/week06/spatial_weights.html#bishop-weights-2",
    "title": "Spatial Weights",
    "section": "Bishop Weights",
    "text": "Bishop Weights\nPySAL does not have a dedicated bishop weights constructor, but you can construct very easily using the w_difference function. This function is one of a family of tools to work with weights, all defined in libpysal.weights, that conduct these types of set operations between weight objects.\n\nbW = libpysal.weights.w_difference(qW, rW, constrained=False)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#bishop-graph",
    "href": "lectures/week06/spatial_weights.html#bishop-graph",
    "title": "Spatial Weights",
    "section": "Bishop Graph",
    "text": "Bishop Graph\n\nplot_spatial_weights(bW, df)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#connectivity",
    "href": "lectures/week06/spatial_weights.html#connectivity",
    "title": "Spatial Weights",
    "section": "Connectivity",
    "text": "Connectivity\n\nbW.histogram\n\n[(np.int64(0), np.int64(1624)),\n (np.int64(1), np.int64(1728)),\n (np.int64(2), np.int64(881)),\n (np.int64(3), np.int64(292)),\n (np.int64(4), np.int64(55))]\n\n\nThus, many tracts have no bishop neighbors. But, a few do.",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#bishop-connectivity-graph",
    "href": "lectures/week06/spatial_weights.html#bishop-connectivity-graph",
    "title": "Spatial Weights",
    "section": "Bishop Connectivity Graph",
    "text": "Bishop Connectivity Graph\n\nplot_spatial_weights(bW, df)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#distance",
    "href": "lectures/week06/spatial_weights.html#distance",
    "title": "Spatial Weights",
    "section": "Distance",
    "text": "Distance\nThere are many other kinds of weighting functions in PySAL. Another separate type use a continuous measure of distance to define neighborhoods.\n\ndf.crs\n\n&lt;Projected CRS: EPSG:26911&gt;\nName: NAD83 / UTM zone 11N\nAxis Info [cartesian]:\n- E[east]: Easting (metre)\n- N[north]: Northing (metre)\nArea of Use:\n- name: North America - between 120°W and 114°W - onshore and offshore. Canada - Alberta; British Columbia; Northwest Territories; Nunavut. United States (USA) - California; Idaho; Nevada, Oregon; Washington.\n- bounds: (-120.0, 30.88, -114.0, 83.5)\nCoordinate Operation:\n- name: UTM zone 11N\n- method: Transverse Mercator\nDatum: North American Datum 1983\n- Ellipsoid: GRS 1980\n- Prime Meridian: Greenwich",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#threshold-based-neighbors",
    "href": "lectures/week06/spatial_weights.html#threshold-based-neighbors",
    "title": "Spatial Weights",
    "section": "Threshold Based Neighbors",
    "text": "Threshold Based Neighbors\nOur coordinate system (UTM 11N) measures distance in meters, so that’s how we’ll define our neighbors\n\ndist_band = DistanceBand.from_dataframe(df, threshold=2000)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#plotting-threshold-neighbor-graph",
    "href": "lectures/week06/spatial_weights.html#plotting-threshold-neighbor-graph",
    "title": "Spatial Weights",
    "section": "Plotting Threshold Neighbor Graph",
    "text": "Plotting Threshold Neighbor Graph\n\nplot_spatial_weights(dist_band,df)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#knn-defined-weights",
    "href": "lectures/week06/spatial_weights.html#knn-defined-weights",
    "title": "Spatial Weights",
    "section": "knn defined weights",
    "text": "knn defined weights\n\nradius_mile = libpysal.cg.sphere.RADIUS_EARTH_MILES\nradius_mile\n\n3958.755865744055\n\n\n\ndf_latlong = df.to_crs(4326)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#wrong-way-to-define-knn",
    "href": "lectures/week06/spatial_weights.html#wrong-way-to-define-knn",
    "title": "Spatial Weights",
    "section": "Wrong Way to define KNN",
    "text": "Wrong Way to define KNN\n\nknn8_bad = KNN.from_dataframe(df_latlong, k=8) # ignore curvature of the earth",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#bad-knn",
    "href": "lectures/week06/spatial_weights.html#bad-knn",
    "title": "Spatial Weights",
    "section": "Bad KNN",
    "text": "Bad KNN\n\nknn8_bad.histogram\n\n[(np.int64(8), np.int64(4580))]",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#correct-way-to-define-knn",
    "href": "lectures/week06/spatial_weights.html#correct-way-to-define-knn",
    "title": "Spatial Weights",
    "section": "Correct Way to define KNN",
    "text": "Correct Way to define KNN\n\nknn8 = KNN.from_dataframe(df_latlong, k=8, radius=radius_mile)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#correct-knn",
    "href": "lectures/week06/spatial_weights.html#correct-knn",
    "title": "Spatial Weights",
    "section": "Correct KNN",
    "text": "Correct KNN\n\nknn8.histogram\n\n[(np.int64(8), np.int64(4580))]",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#comparison",
    "href": "lectures/week06/spatial_weights.html#comparison",
    "title": "Spatial Weights",
    "section": "Comparison",
    "text": "Comparison\n\nknn8_bad.neighbors[1487]\n\n[np.int64(501),\n np.int64(2296),\n np.int64(2960),\n np.int64(974),\n np.int64(167),\n np.int64(4496),\n np.int64(2295),\n np.int64(4422)]\n\n\n\nknn8.neighbors[1487]\n\n[np.int64(501),\n np.int64(2960),\n np.int64(2296),\n np.int64(974),\n np.int64(167),\n np.int64(4496),\n np.int64(2881),\n np.int64(2297)]\n\n\n\nset(knn8_bad.neighbors[1487]) == set(knn8.neighbors[1487])\n\nFalse",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#kernel-w",
    "href": "lectures/week06/spatial_weights.html#kernel-w",
    "title": "Spatial Weights",
    "section": "Kernel W",
    "text": "Kernel W\nKernel Weights are continuous distance-based weights that use kernel densities to define the neighbor relationship. Typically, they estimate a bandwidth, which is a parameter governing how far out observations should be considered neighboring. Then, using this bandwidth, they evaluate a continuous kernel function to provide a weight between 0 and 1.\nMany different choices of kernel functions are supported, and bandwidths can either be fixed (constant over all units) or adaptive in function of unit density.\nFor example, if we want to use adaptive bandwidths for the map and weight according to a gaussian kernel:",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#adaptive-gaussian-kernel-weights",
    "href": "lectures/week06/spatial_weights.html#adaptive-gaussian-kernel-weights",
    "title": "Spatial Weights",
    "section": "Adaptive gaussian kernel weights",
    "text": "Adaptive gaussian kernel weights\nbandwidth = the distance to the kth nearest neighbor for each observation\nbandwith is changing across observations\n\nkernelWa = Kernel.from_dataframe(df, k=10, fixed=False, function='gaussian')",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#kernel-weights",
    "href": "lectures/week06/spatial_weights.html#kernel-weights",
    "title": "Spatial Weights",
    "section": "Kernel Weights",
    "text": "Kernel Weights\n\nplot_spatial_weights(kernelWa, df)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#kernel-weights-continuous",
    "href": "lectures/week06/spatial_weights.html#kernel-weights-continuous",
    "title": "Spatial Weights",
    "section": "Kernel Weights (Continuous)",
    "text": "Kernel Weights (Continuous)\n\nkernelWa.weights[0]\n\n[0.3989422804014327,\n 0.350004537433577,\n 0.31104924482806384,\n 0.30853347366341066,\n 0.2992343856666809,\n 0.281132887806544,\n 0.2737643355852085,\n 0.26431336729422755,\n 0.26173661400901954,\n 0.2613974031586016,\n 0.2419707487162134]",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#adaptive-bandwidths",
    "href": "lectures/week06/spatial_weights.html#adaptive-bandwidths",
    "title": "Spatial Weights",
    "section": "Adaptive bandwidths",
    "text": "Adaptive bandwidths\n\nkernelWa.bandwidth\n\narray([[1687.98315102],\n       [1997.79763417],\n       [1803.36975814],\n       ...,\n       [2468.39053934],\n       [3480.80242265],\n       [1749.83295263]])",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#adaptive-bandwidths-1",
    "href": "lectures/week06/spatial_weights.html#adaptive-bandwidths-1",
    "title": "Spatial Weights",
    "section": "Adaptive bandwidths",
    "text": "Adaptive bandwidths\n\ndf.assign(bw=kernelWa.bandwidth.flatten()).plot('bw', cmap='Reds')",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#block-weights",
    "href": "lectures/week06/spatial_weights.html#block-weights",
    "title": "Spatial Weights",
    "section": "Block Weights",
    "text": "Block Weights\n\nw,s,e,n = df.total_bounds\n\n\nmx = (w+e)/2\nmy = (n+s)/2\n\n\nimport shapely\ncentroids = df.geometry.centroid\nlon = centroids.apply(lambda p: p.x).values\nlat = centroids.apply(lambda p: p.y).values",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#regions",
    "href": "lectures/week06/spatial_weights.html#regions",
    "title": "Spatial Weights",
    "section": "Regions",
    "text": "Regions\n\nnorth = lat &gt; my\nsouth = lat &lt;= my\neast = lon &gt; mx\nwest = lon &lt;= mx\n\n\nnw = west * north * 2\nne = east * north * 1\nsw = west * south * 3\nse = east * south *4\nquad = nw + ne + sw + se\n\n\nquad\n\narray([3, 2, 2, ..., 2, 4, 2])",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#regions-1",
    "href": "lectures/week06/spatial_weights.html#regions-1",
    "title": "Spatial Weights",
    "section": "Regions",
    "text": "Regions\n\ndf['quad'] = quad\ndf.plot(column=\"quad\", categorical=True)",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#block-weights-1",
    "href": "lectures/week06/spatial_weights.html#block-weights-1",
    "title": "Spatial Weights",
    "section": "Block Weights",
    "text": "Block Weights\n\nblockW = libpysal.weights.block_weights(df[\"quad\"])\n\n\nblockW.n\n\n4580\n\n\n\nblockW.pct_nonzero\n\n65.53761369920483",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#connectivity-1",
    "href": "lectures/week06/spatial_weights.html#connectivity-1",
    "title": "Spatial Weights",
    "section": "Connectivity",
    "text": "Connectivity\n\npandas.Series(blockW.cardinalities).plot.hist()",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#region-membership",
    "href": "lectures/week06/spatial_weights.html#region-membership",
    "title": "Spatial Weights",
    "section": "Region Membership",
    "text": "Region Membership\n\ndf.groupby(by='quad').count()\n\n\n\n\n\n\n\n\ngeoid\nn_asian_under_15\nn_black_under_15\nn_hispanic_under_15\nn_native_under_15\nn_white_under_15\nn_persons_under_18\nn_asian_over_60\nn_black_over_60\nn_hispanic_over_60\n...\nyear\nn_total_housing_units_sample\np_nonhisp_white_persons\np_white_over_60\np_black_over_60\np_hispanic_over_60\np_native_over_60\np_asian_over_60\np_disabled\ngeometry\n\n\nquad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n15\n15\n15\n15\n15\n15\n15\n0\n0\n0\n...\n15\n15\n15\n0\n0\n0\n0\n0\n0\n15\n\n\n2\n761\n761\n761\n761\n761\n761\n761\n0\n0\n0\n...\n761\n761\n755\n0\n0\n0\n0\n0\n0\n761\n\n\n3\n3625\n3625\n3625\n3625\n3625\n3625\n3625\n0\n0\n0\n...\n3625\n3625\n3612\n0\n0\n0\n0\n0\n0\n3625\n\n\n4\n179\n179\n179\n179\n179\n179\n179\n0\n0\n0\n...\n179\n179\n179\n0\n0\n0\n0\n0\n0\n179\n\n\n\n\n4 rows × 194 columns",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#recap-of-key-points",
    "href": "lectures/week06/spatial_weights.html#recap-of-key-points",
    "title": "Spatial Weights",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nSpatial Weights\nContiguity Weights\nDistance Based Weights",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week06/spatial_weights.html#questions",
    "href": "lectures/week06/spatial_weights.html#questions",
    "title": "Spatial Weights",
    "section": "Questions",
    "text": "Questions",
    "crumbs": [
      "Home",
      "09-30 Spatial Weights"
    ]
  },
  {
    "objectID": "lectures/week04/0221_area_1.html",
    "href": "lectures/week04/0221_area_1.html",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nimport geopandas\nimport libpysal\n\n\n\n\nCode\nsouth = libpysal.examples.load_example('South')\n\n\n\n\nCode\nlibpysal.examples.explain('South')\n\n\n\n        \n        \n\n\n\n\n\n\nCode\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))\n\n\n\n\n\n\n\nCode\nsouth_gdf.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf.crs\n\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\n\n\n\nCode\nax = south_gdf.plot()\nax.set_axis_off();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf.shape\n\n\n(1412, 70)\n\n\n\n\nCode\nsouth_gdf.geometry\n\n\n0       POLYGON ((-80.62805 40.39816, -80.60204 40.480...\n1       POLYGON ((-80.52625 40.16245, -80.5876 40.1750...\n2       POLYGON ((-80.52517 40.02275, -80.73843 40.035...\n3       POLYGON ((-80.52447 39.72113, -80.83248 39.718...\n4       POLYGON ((-75.7727 39.38301, -75.79144 39.7237...\n                              ...                        \n1407    POLYGON ((-79.14433 36.54606, -79.21706 36.549...\n1408    POLYGON ((-79.43775 37.61596, -79.45834 37.603...\n1409    POLYGON ((-80.12475 37.1251, -80.14045 37.1283...\n1410    POLYGON ((-76.39569 37.10771, -76.4027 37.0905...\n1411    POLYGON ((-77.53178 38.56506, -77.72094 38.840...\nName: geometry, Length: 1412, dtype: geometry\n\n\n\n\nCode\nsouth_gdf.columns\n\n\nIndex(['NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'STFIPS',\n       'COFIPS', 'FIPSNO', 'SOUTH', 'HR60', 'HR70', 'HR80', 'HR90', 'HC60',\n       'HC70', 'HC80', 'HC90', 'PO60', 'PO70', 'PO80', 'PO90', 'RD60', 'RD70',\n       'RD80', 'RD90', 'PS60', 'PS70', 'PS80', 'PS90', 'UE60', 'UE70', 'UE80',\n       'UE90', 'DV60', 'DV70', 'DV80', 'DV90', 'MA60', 'MA70', 'MA80', 'MA90',\n       'POL60', 'POL70', 'POL80', 'POL90', 'DNL60', 'DNL70', 'DNL80', 'DNL90',\n       'MFIL59', 'MFIL69', 'MFIL79', 'MFIL89', 'FP59', 'FP69', 'FP79', 'FP89',\n       'BLK60', 'BLK70', 'BLK80', 'BLK90', 'GI59', 'GI69', 'GI79', 'GI89',\n       'FH60', 'FH70', 'FH80', 'FH90', 'geometry'],\n      dtype='object')\n\n\n\n\nCode\nsouth_gdf.explore(column='HR60')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nsouth_gdf.HR60.describe()\n\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64\n\n\n\n\nCode\nax = south_gdf.plot(column='HR60')\nax.set_axis_off();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf.STATE_NAME.unique().shape\n\n\n(17,)\n\n\n\n\n\n\n\nCode\nsouth_gdf.shape[0]\n\n\n1412\n\n\n\n\n\n\n\nCode\nsouth_gdf.groupby(by='STATE_NAME').count()\n\n\n\n\n\n\n\n\n\nNAME\nSTATE_FIPS\nCNTY_FIPS\nFIPS\nSTFIPS\nCOFIPS\nFIPSNO\nSOUTH\nHR60\nHR70\n...\nBLK90\nGI59\nGI69\nGI79\nGI89\nFH60\nFH70\nFH80\nFH90\ngeometry\n\n\nSTATE_NAME\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nArkansas\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n...\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n\n\nDelaware\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n...\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n\n\nDistrict of Columbia\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\nFlorida\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nGeorgia\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n...\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n\n\nKentucky\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n...\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n\n\nLouisiana\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n...\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n\n\nMaryland\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n...\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n\n\nMississippi\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n...\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n\n\nNorth Carolina\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n...\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n\n\nOklahoma\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n...\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n\n\nSouth Carolina\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n...\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n\n\nTennessee\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n...\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n\n\nTexas\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n...\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n\n\nVirginia\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n...\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n\n\nWest Virginia\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n...\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n\n\n\n\n17 rows × 69 columns\n\n\n\n\n\n\n\n\nCode\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').median()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n9.623977\n\n\nArkansas\n4.704111\n\n\nDelaware\n4.228385\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n9.970306\n\n\nGeorgia\n9.300076\n\n\nKentucky\n5.235436\n\n\nLouisiana\n6.840286\n\n\nMaryland\n5.335208\n\n\nMississippi\n8.919274\n\n\nNorth Carolina\n7.633043\n\n\nOklahoma\n4.269126\n\n\nSouth Carolina\n7.509437\n\n\nTennessee\n4.877751\n\n\nTexas\n4.326215\n\n\nVirginia\n6.672004\n\n\nWest Virginia\n2.623226\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').max()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n24.903499\n\n\nArkansas\n21.154427\n\n\nDelaware\n7.286472\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n40.744262\n\n\nGeorgia\n53.304904\n\n\nKentucky\n37.250885\n\n\nLouisiana\n18.243736\n\n\nMaryland\n14.327234\n\n\nMississippi\n24.833923\n\n\nNorth Carolina\n25.660127\n\n\nOklahoma\n17.088175\n\n\nSouth Carolina\n23.345940\n\n\nTennessee\n20.894275\n\n\nTexas\n92.936803\n\n\nVirginia\n23.575639\n\n\nWest Virginia\n11.482375\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n4.742337\n\n\nArkansas\n4.574625\n\n\nDelaware\n1.815562\n\n\nDistrict of Columbia\nNaN\n\n\nFlorida\n7.990692\n\n\nGeorgia\n7.906488\n\n\nKentucky\n6.354316\n\n\nLouisiana\n4.189146\n\n\nMaryland\n4.064360\n\n\nMississippi\n4.972698\n\n\nNorth Carolina\n4.596952\n\n\nOklahoma\n4.231132\n\n\nSouth Carolina\n4.018644\n\n\nTennessee\n4.354979\n\n\nTexas\n8.223844\n\n\nVirginia\n4.826707\n\n\nWest Virginia\n2.773659\n\n\n\n\n\n\n\n\n\nCode\nsgdf = south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\nCode\ncv = sgdf / south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').mean() * 100\n\n\n\n\nCode\ncv.sort_values(by='HR60', ascending=False)\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nTexas\n144.992919\n\n\nKentucky\n96.815524\n\n\nWest Virginia\n93.234007\n\n\nArkansas\n81.223752\n\n\nOklahoma\n81.114430\n\n\nTennessee\n75.426226\n\n\nGeorgia\n73.774440\n\n\nMaryland\n71.898559\n\n\nFlorida\n68.252692\n\n\nVirginia\n66.924041\n\n\nLouisiana\n59.994571\n\n\nMississippi\n57.457024\n\n\nNorth Carolina\n57.013871\n\n\nAlabama\n49.070812\n\n\nSouth Carolina\n48.083524\n\n\nDelaware\n34.966796\n\n\nDistrict of Columbia\nNaN"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#loading",
    "href": "lectures/week04/0221_area_1.html#loading",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#plotting-geometries",
    "href": "lectures/week04/0221_area_1.html#plotting-geometries",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.plot()"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#checking-crs",
    "href": "lectures/week04/0221_area_1.html#checking-crs",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.crs\n\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#turning-off-axis",
    "href": "lectures/week04/0221_area_1.html#turning-off-axis",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nax = south_gdf.plot()\nax.set_axis_off();"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#inspecting-the-geodataframe",
    "href": "lectures/week04/0221_area_1.html#inspecting-the-geodataframe",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.shape\n\n\n(1412, 70)\n\n\n\n\nCode\nsouth_gdf.geometry\n\n\n0       POLYGON ((-80.62805 40.39816, -80.60204 40.480...\n1       POLYGON ((-80.52625 40.16245, -80.5876 40.1750...\n2       POLYGON ((-80.52517 40.02275, -80.73843 40.035...\n3       POLYGON ((-80.52447 39.72113, -80.83248 39.718...\n4       POLYGON ((-75.7727 39.38301, -75.79144 39.7237...\n                              ...                        \n1407    POLYGON ((-79.14433 36.54606, -79.21706 36.549...\n1408    POLYGON ((-79.43775 37.61596, -79.45834 37.603...\n1409    POLYGON ((-80.12475 37.1251, -80.14045 37.1283...\n1410    POLYGON ((-76.39569 37.10771, -76.4027 37.0905...\n1411    POLYGON ((-77.53178 38.56506, -77.72094 38.840...\nName: geometry, Length: 1412, dtype: geometry\n\n\n\n\nCode\nsouth_gdf.columns\n\n\nIndex(['NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'STFIPS',\n       'COFIPS', 'FIPSNO', 'SOUTH', 'HR60', 'HR70', 'HR80', 'HR90', 'HC60',\n       'HC70', 'HC80', 'HC90', 'PO60', 'PO70', 'PO80', 'PO90', 'RD60', 'RD70',\n       'RD80', 'RD90', 'PS60', 'PS70', 'PS80', 'PS90', 'UE60', 'UE70', 'UE80',\n       'UE90', 'DV60', 'DV70', 'DV80', 'DV90', 'MA60', 'MA70', 'MA80', 'MA90',\n       'POL60', 'POL70', 'POL80', 'POL90', 'DNL60', 'DNL70', 'DNL80', 'DNL90',\n       'MFIL59', 'MFIL69', 'MFIL79', 'MFIL89', 'FP59', 'FP69', 'FP79', 'FP89',\n       'BLK60', 'BLK70', 'BLK80', 'BLK90', 'GI59', 'GI69', 'GI79', 'GI89',\n       'FH60', 'FH70', 'FH80', 'FH90', 'geometry'],\n      dtype='object')\n\n\n\n\nCode\nsouth_gdf.explore(column='HR60')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nsouth_gdf.HR60.describe()\n\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64\n\n\n\n\nCode\nax = south_gdf.plot(column='HR60')\nax.set_axis_off();"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#how-many-states-are-there-in-this-dataset",
    "href": "lectures/week04/0221_area_1.html#how-many-states-are-there-in-this-dataset",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.STATE_NAME.unique().shape\n\n\n(17,)"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#how-many-counties",
    "href": "lectures/week04/0221_area_1.html#how-many-counties",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.shape[0]\n\n\n1412"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#how-many-counties-in-each-state",
    "href": "lectures/week04/0221_area_1.html#how-many-counties-in-each-state",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.groupby(by='STATE_NAME').count()\n\n\n\n\n\n\n\n\n\nNAME\nSTATE_FIPS\nCNTY_FIPS\nFIPS\nSTFIPS\nCOFIPS\nFIPSNO\nSOUTH\nHR60\nHR70\n...\nBLK90\nGI59\nGI69\nGI79\nGI89\nFH60\nFH70\nFH80\nFH90\ngeometry\n\n\nSTATE_NAME\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nArkansas\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n...\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n\n\nDelaware\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n...\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n\n\nDistrict of Columbia\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\nFlorida\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nGeorgia\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n...\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n\n\nKentucky\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n...\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n\n\nLouisiana\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n...\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n\n\nMaryland\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n...\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n\n\nMississippi\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n...\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n\n\nNorth Carolina\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n...\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n\n\nOklahoma\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n...\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n\n\nSouth Carolina\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n...\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n\n\nTennessee\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n...\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n\n\nTexas\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n...\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n\n\nVirginia\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n...\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n\n\nWest Virginia\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n...\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n\n\n\n\n17 rows × 69 columns"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#which-county-had-the-highest-median-homicide-rate-in-1960",
    "href": "lectures/week04/0221_area_1.html#which-county-had-the-highest-median-homicide-rate-in-1960",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').median()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n9.623977\n\n\nArkansas\n4.704111\n\n\nDelaware\n4.228385\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n9.970306\n\n\nGeorgia\n9.300076\n\n\nKentucky\n5.235436\n\n\nLouisiana\n6.840286\n\n\nMaryland\n5.335208\n\n\nMississippi\n8.919274\n\n\nNorth Carolina\n7.633043\n\n\nOklahoma\n4.269126\n\n\nSouth Carolina\n7.509437\n\n\nTennessee\n4.877751\n\n\nTexas\n4.326215\n\n\nVirginia\n6.672004\n\n\nWest Virginia\n2.623226"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#which-county-had-the-highest-maximum-homicide-rate-in-1960",
    "href": "lectures/week04/0221_area_1.html#which-county-had-the-highest-maximum-homicide-rate-in-1960",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').max()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n24.903499\n\n\nArkansas\n21.154427\n\n\nDelaware\n7.286472\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n40.744262\n\n\nGeorgia\n53.304904\n\n\nKentucky\n37.250885\n\n\nLouisiana\n18.243736\n\n\nMaryland\n14.327234\n\n\nMississippi\n24.833923\n\n\nNorth Carolina\n25.660127\n\n\nOklahoma\n17.088175\n\n\nSouth Carolina\n23.345940\n\n\nTennessee\n20.894275\n\n\nTexas\n92.936803\n\n\nVirginia\n23.575639\n\n\nWest Virginia\n11.482375"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#intra-state-dispersion",
    "href": "lectures/week04/0221_area_1.html#intra-state-dispersion",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n4.742337\n\n\nArkansas\n4.574625\n\n\nDelaware\n1.815562\n\n\nDistrict of Columbia\nNaN\n\n\nFlorida\n7.990692\n\n\nGeorgia\n7.906488\n\n\nKentucky\n6.354316\n\n\nLouisiana\n4.189146\n\n\nMaryland\n4.064360\n\n\nMississippi\n4.972698\n\n\nNorth Carolina\n4.596952\n\n\nOklahoma\n4.231132\n\n\nSouth Carolina\n4.018644\n\n\nTennessee\n4.354979\n\n\nTexas\n8.223844\n\n\nVirginia\n4.826707\n\n\nWest Virginia\n2.773659\n\n\n\n\n\n\n\n\n\nCode\nsgdf = south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\nCode\ncv = sgdf / south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').mean() * 100\n\n\n\n\nCode\ncv.sort_values(by='HR60', ascending=False)\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nTexas\n144.992919\n\n\nKentucky\n96.815524\n\n\nWest Virginia\n93.234007\n\n\nArkansas\n81.223752\n\n\nOklahoma\n81.114430\n\n\nTennessee\n75.426226\n\n\nGeorgia\n73.774440\n\n\nMaryland\n71.898559\n\n\nFlorida\n68.252692\n\n\nVirginia\n66.924041\n\n\nLouisiana\n59.994571\n\n\nMississippi\n57.457024\n\n\nNorth Carolina\n57.013871\n\n\nAlabama\n49.070812\n\n\nSouth Carolina\n48.083524\n\n\nDelaware\n34.966796\n\n\nDistrict of Columbia\nNaN"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week04/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week04/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#eda-approach",
    "href": "lectures/week04/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week04/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#historical-context",
    "href": "lectures/week04/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#snow-map",
    "href": "lectures/week04/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#snow-map-1",
    "href": "lectures/week04/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week04/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#vector-data",
    "href": "lectures/week04/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#vector-data-1",
    "href": "lectures/week04/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#raster-data",
    "href": "lectures/week04/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#raster-data-1",
    "href": "lectures/week04/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#attribute-data",
    "href": "lectures/week04/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#attribute-data-1",
    "href": "lectures/week04/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week04/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week04/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#remote-sensing",
    "href": "lectures/week04/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week04/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week04/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week04/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week04/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week04/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week04/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week04/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week04/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week04/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#questions",
    "href": "lectures/week04/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#references",
    "href": "lectures/week04/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "lectures/week03/studio.html",
    "href": "lectures/week03/studio.html",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2\n\n\n\n\n[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week03/studio.html#objectives",
    "href": "lectures/week03/studio.html#objectives",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "lectures/week03/studio.html#instructions",
    "href": "lectures/week03/studio.html#instructions",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week03/index.html",
    "href": "lectures/week03/index.html",
    "title": "Week 3 Lecture: Spatial Data Analysis",
    "section": "",
    "text": "lecture",
    "crumbs": [
      "Home",
      "09-09 Spatial Data Analysis"
    ]
  },
  {
    "objectID": "lectures/week03/index.html#spatial-data-analysis",
    "href": "lectures/week03/index.html#spatial-data-analysis",
    "title": "Week 3 Lecture: Spatial Data Analysis",
    "section": "",
    "text": "lecture",
    "crumbs": [
      "Home",
      "09-09 Spatial Data Analysis"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#what-is-clustering",
    "href": "lectures/week09/regionalization.html#what-is-clustering",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "What is Clustering?",
    "text": "What is Clustering?\n\nDefinition: Grouping observations based on multivariate similarity.\nPurpose: Simplify complex, multidimensional data into clusters.\nApplications:\n\nGeodemographic clusters in San Diego Census tracts.\nSocioeconomic analysis using clustering.",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#how-clustering-works",
    "href": "lectures/week09/regionalization.html#how-clustering-works",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "How Clustering Works",
    "text": "How Clustering Works\n\nUnsupervised Learning: No labels, groups based on similarity.\nMultivariate Processes: Clusters represent similarities in many variables.\nProfile Creation: Simplifies the interpretation of complex data.",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#example-socioeconomic-clustering",
    "href": "lectures/week09/regionalization.html#example-socioeconomic-clustering",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Example: Socioeconomic clustering",
    "text": "Example: Socioeconomic clustering\n\nimport pandas as pd\nimport geopandas as gpd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\n# Example dataset (San Diego tracts)\ndata = gpd.read_file('~/data/385/sandiego_tracts.gpkg')\n\n# Select clustering variables\ncluster_variables = [\"median_house_value\", \"pct_white\", \"pct_rented\", \"pct_hh_female\", \"pct_bachelor\", \"median_no_rooms\", \"income_gini\", \"median_age\", \"tt_work\"]\ndata.plot('median_house_value')",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#data-preparation-scaling",
    "href": "lectures/week09/regionalization.html#data-preparation-scaling",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Data Preparation: Scaling",
    "text": "Data Preparation: Scaling\n\ndata[cluster_variables[0:3]].head()\n\n\n\n\n\n\n\n\nmedian_house_value\npct_white\npct_rented\n\n\n\n\n0\n732900.000000\n0.916988\n0.373913\n\n\n1\n473800.000000\n0.790558\n0.205144\n\n\n2\n930600.000000\n0.880250\n0.279029\n\n\n3\n478500.000000\n0.800598\n0.196512\n\n\n4\n515570.896382\n0.753799\n0.949887",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#data-preparation-scaling-1",
    "href": "lectures/week09/regionalization.html#data-preparation-scaling-1",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Data Preparation: Scaling",
    "text": "Data Preparation: Scaling\n\n# Scale the data\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(data[cluster_variables])\nscaled_data[0:5, 0:3]\n\narray([[ 8.12429126e-01,  1.23188973e+00, -2.41143211e-01],\n       [-1.56149785e-01,  4.51803106e-01, -9.86504682e-01],\n       [ 1.55147988e+00,  1.00521260e+00, -6.60192373e-01],\n       [-1.38580040e-01,  5.13751652e-01, -1.02462658e+00],\n       [-2.17594415e-16,  2.25001983e-01,  2.30262050e+00]])",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#kmeans",
    "href": "lectures/week09/regionalization.html#kmeans",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "KMeans",
    "text": "KMeans\n\n# Run KMeans\nkmeans = KMeans(n_clusters=5, random_state=0)\ndata['kmeans_cluster'] = kmeans.fit_predict(scaled_data)\n\n# Visualize clusters\ndata.plot(column='kmeans_cluster', categorical=True, legend=True)",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#wards-hierarchical-clustering",
    "href": "lectures/week09/regionalization.html#wards-hierarchical-clustering",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Ward’s Hierarchical Clustering",
    "text": "Ward’s Hierarchical Clustering\n\nDefinition: Agglomerative clustering method.\nSteps:\n\nStart with each observation as its own cluster.\nMerge clusters based on proximity.\nCreate a hierarchy of clustering solutions.\n\nApplication: Socioeconomic clusters of San Diego.",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#example-wards-method",
    "href": "lectures/week09/regionalization.html#example-wards-method",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Example: Ward’s Method",
    "text": "Example: Ward’s Method\n\nfrom sklearn.cluster import AgglomerativeClustering\n\n# Perform Ward's hierarchical clustering\nward = AgglomerativeClustering(n_clusters=5, linkage=\"ward\")\ndata['ward_cluster'] = ward.fit_predict(scaled_data)\n\n# Visualize Ward clusters\ndata.plot(column='ward_cluster', categorical=True, legend=True)",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#section",
    "href": "lectures/week09/regionalization.html#section",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nZ = linkage(scaled_data, method='ward')\nplt.figure(figsize=(8, 5))\nplt.title(\"Dendrogram for Ward's Hierarchical Clustering\")\ndendrogram(Z)\nplt.show()",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#cluster-profile-data-setup",
    "href": "lectures/week09/regionalization.html#cluster-profile-data-setup",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Cluster Profile: Data Setup",
    "text": "Cluster Profile: Data Setup\n\ntidy_db = data.set_index('ward_cluster')\ntidy_db = tidy_db[cluster_variables]\ntidy_db = tidy_db.stack()\ntidy_db = tidy_db.reset_index()\ntidy_db = tidy_db.rename(\n    columns={\"level_1\": \"Attribute\", 0: \"Values\"})\ntidy_db.head()\n\n\n\n\n\n\n\n\nward_cluster\nAttribute\nValues\n\n\n\n\n0\n1\nmedian_house_value\n732900.000000\n\n\n1\n1\npct_white\n0.916988\n\n\n2\n1\npct_rented\n0.373913\n\n\n3\n1\npct_hh_female\n0.052896\n\n\n4\n1\npct_bachelor\n0.000000",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#section-1",
    "href": "lectures/week09/regionalization.html#section-1",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "",
    "text": "import seaborn\nimport matplotlib.pyplot as plt\n\nseaborn.set(font_scale=1.5)\n# Setup the facets\nfacets = seaborn.FacetGrid(\n    data=tidy_db,\n    col=\"Attribute\",\n    hue=\"ward_cluster\",\n    sharey=False,\n    sharex=False,\n    aspect=2,\n    col_wrap=3,\n);\n# Build the plot from `sns.kdeplot`\n_ = facets.map(seaborn.kdeplot, \"Values\", shade=True).add_legend();\nfacets.savefig(\"facets.png\")\nplt.close()",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#cluster-profiles",
    "href": "lectures/week09/regionalization.html#cluster-profiles",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Cluster Profiles",
    "text": "Cluster Profiles",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#spatial-autocorrelation-and-clustering",
    "href": "lectures/week09/regionalization.html#spatial-autocorrelation-and-clustering",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Spatial Autocorrelation and Clustering",
    "text": "Spatial Autocorrelation and Clustering\n\nfrom esda.moran import Moran\nfrom libpysal.weights import Queen\n\n# Create spatial weights matrix\nw = Queen.from_dataframe(data)\n\n# Moran's I for a variable\nmi = Moran(data['median_house_value'], w)\nprint(mi.I, mi.p_sim)\n\n0.6466184001197568 0.001",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#what-is-regionalization",
    "href": "lectures/week09/regionalization.html#what-is-regionalization",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "What is Regionalization?",
    "text": "What is Regionalization?\n\nDefinition: Clustering with geographic constraints.\nImportance: Ensures clusters are both statistically and spatially coherent.",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#spatial-weights-in-regionalization",
    "href": "lectures/week09/regionalization.html#spatial-weights-in-regionalization",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Spatial Weights in Regionalization",
    "text": "Spatial Weights in Regionalization\n\nSpatial Weights Matrix: Defines connectivity (e.g., Queen contiguity, K-nearest neighbors).",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#example-spatially-constrained-clustering",
    "href": "lectures/week09/regionalization.html#example-spatially-constrained-clustering",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Example: Spatially Constrained Clustering",
    "text": "Example: Spatially Constrained Clustering\n\nfrom libpysal.weights import Queen\n\n# Use spatial weights to constrain clustering\nwq = Queen.from_dataframe(data)\nward_spatial = AgglomerativeClustering(n_clusters=5, linkage=\"ward\",\n                                       connectivity=wq.sparse)\ndata['ward_spatial_cluster'] = ward_spatial.fit_predict(scaled_data)\ndata.plot(column='ward_spatial_cluster', categorical=True, legend=True)",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#clusters-versus-regions-1",
    "href": "lectures/week09/regionalization.html#clusters-versus-regions-1",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Clusters versus Regions",
    "text": "Clusters versus Regions\n\nConnected Component: a subgraph in which any two vertices are connected to each other by paths.\nRegions: formed as connected components defined on the spatial adjacency graph\nMultivariate Clusters: may or may not be spatially connected components",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#connected-components",
    "href": "lectures/week09/regionalization.html#connected-components",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Connected Components",
    "text": "Connected Components",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#ward-cluster-graph",
    "href": "lectures/week09/regionalization.html#ward-cluster-graph",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Ward Cluster Graph",
    "text": "Ward Cluster Graph\n\nimport libpysal\ngc = libpysal.graph.Graph.build_block_contiguity(data.ward_cluster)\ngc.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n628\n\n\nNumber of edges:\n114490\n\n\nNumber of connected components:\n5\n\n\nNumber of isolates:\n0\n\n\nNumber of non-zero edges:\n114490\n\n\nPercentage of non-zero edges:\n29.03%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n114490\nGG:\n114490\n\n\nS1:\n228980\nG'G:\n114490\n\n\nS3:\n106484296\nG'G + GG:\n228980\n\n\n\n\n            \n                Graph indexed by: [0, 5, 9, 10, 13, ...]",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#spatial-ward-cluster-graph",
    "href": "lectures/week09/regionalization.html#spatial-ward-cluster-graph",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Spatial Ward Cluster Graph",
    "text": "Spatial Ward Cluster Graph\n\ngcs = libpysal.graph.Graph.build_block_contiguity(data.ward_spatial_cluster)\ngcs.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n628\n\n\nNumber of edges:\n142610\n\n\nNumber of connected components:\n5\n\n\nNumber of isolates:\n1\n\n\nNumber of non-zero edges:\n142610\n\n\nPercentage of non-zero edges:\n36.16%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n142610\nGG:\n142610\n\n\nS1:\n285220\nG'G:\n142610\n\n\nS3:\n144306296\nG'G + GG:\n285220\n\n\n\n\n            \n                Graph indexed by: [0, 1, 3, 7, 12, ...]",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#queen-graph",
    "href": "lectures/week09/regionalization.html#queen-graph",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Queen Graph",
    "text": "Queen Graph\n\nimport libpysal\ngq  = libpysal.graph.Graph.from_W(wq)\ngq.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n628\n\n\nNumber of edges:\n4016\n\n\nNumber of connected components:\n1\n\n\nNumber of isolates:\n0\n\n\nNumber of non-zero edges:\n4016\n\n\nPercentage of non-zero edges:\n1.02%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n4016\nGG:\n4016\n\n\nS1:\n8032\nG'G:\n4016\n\n\nS3:\n113728\nG'G + GG:\n8032\n\n\n\n\n            \n                Graph indexed by: [0, 1, 2, 3, 4, ...]",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#intersection-graph-queen-ward",
    "href": "lectures/week09/regionalization.html#intersection-graph-queen-ward",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Intersection Graph (Queen + Ward )",
    "text": "Intersection Graph (Queen + Ward )\n\nimport libpysal\ngcq_int = gq.intersection(gc)\ngcq_int.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n628\n\n\nNumber of edges:\n2208\n\n\nNumber of connected components:\n80\n\n\nNumber of isolates:\n33\n\n\nNumber of non-zero edges:\n2208\n\n\nPercentage of non-zero edges:\n0.57%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n2208\nGG:\n2208\n\n\nS1:\n4416\nG'G:\n2208\n\n\nS3:\n41312\nG'G + GG:\n4416\n\n\n\n\n            \n                Graph indexed by: [0, 1, 2, 3, 4, ...]",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#intersection-graph-queen-ward-spatial",
    "href": "lectures/week09/regionalization.html#intersection-graph-queen-ward-spatial",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Intersection Graph (Queen + Ward Spatial)",
    "text": "Intersection Graph (Queen + Ward Spatial)\n\nimport libpysal\ngcsq_int = gq.intersection(gcs)\ngcsq_int.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n628\n\n\nNumber of edges:\n3394\n\n\nNumber of connected components:\n5\n\n\nNumber of isolates:\n1\n\n\nNumber of non-zero edges:\n3394\n\n\nPercentage of non-zero edges:\n0.86%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n3394\nGG:\n3394\n\n\nS1:\n6788\nG'G:\n3394\n\n\nS3:\n83704\nG'G + GG:\n6788\n\n\n\n\n            \n                Graph indexed by: [0, 1, 2, 3, 4, ...]",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#section-2",
    "href": "lectures/week09/regionalization.html#section-2",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\n\nfig, axes = plt.subplots(1,2, figsize=(12,6))\ndata.plot(column='ward_cluster', categorical=True, ax=axes[0], linewidth=0.1)\naxes[0].set_title('Ward')\naxes[0].axis('off')\ndata.plot(column='ward_spatial_cluster', categorical=True, ax=axes[1], linewidth=0.1, legend=True,\n          legend_kwds={'bbox_to_anchor': (1.3, 1),\n                       'title': \"Cluster\"})\naxes[1].set_title('Ward Spatial')\naxes[1].axis('off')\nplt.tight_layout()",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#comparison",
    "href": "lectures/week09/regionalization.html#comparison",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Comparison",
    "text": "Comparison\n\n\n\nMethod\nClusters\nRegions\n\n\n\n\nWard\n5\n80\n\n\nSpatial Ward\n5\n5",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#recap-of-key-points",
    "href": "lectures/week09/regionalization.html#recap-of-key-points",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nMultivariate Clustering\nRegionalization\nClusters versus Regions",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "lectures/week09/regionalization.html#questions",
    "href": "lectures/week09/regionalization.html#questions",
    "title": "Clustering and Regionalization in Geographic Data Science",
    "section": "Questions",
    "text": "Questions",
    "crumbs": [
      "Home",
      "10-21 Clustering and Regionalization"
    ]
  },
  {
    "objectID": "studio/week01/meet.html",
    "href": "studio/week01/meet.html",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "",
    "text": "This handout provides instructions on how to use Google Meet for small group work, including creating a meeting, sharing screens (with sound off), and using the chat feature to collaborate on in-class studios."
  },
  {
    "objectID": "studio/week01/meet.html#purpose",
    "href": "studio/week01/meet.html#purpose",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "",
    "text": "This handout provides instructions on how to use Google Meet for small group work, including creating a meeting, sharing screens (with sound off), and using the chat feature to collaborate on in-class studios."
  },
  {
    "objectID": "studio/week01/meet.html#find-your-team",
    "href": "studio/week01/meet.html#find-your-team",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Find Your Team",
    "text": "Find Your Team\nTeams are randomly constructed. To find your team:\n\nVisit the link for the team assignments for Studio 1.\nThe first person listed is the group leader. If the first person is not present, the first person next on the list who is present is the group leader for the studio."
  },
  {
    "objectID": "studio/week01/meet.html#getting-started-with-google-meet",
    "href": "studio/week01/meet.html#getting-started-with-google-meet",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Getting Started with Google Meet",
    "text": "Getting Started with Google Meet\n\nGroup Leader\n\nThe group leader will be responsible for creating the Google Meet session.\n\nCreating a Google Meet Session\n\nThe group leader should sign in to their Google account.\nUsing the Team Meeting link at the bottom of the Studio 1 Team listing, the Group Leader should start the meeting..\n\nJoining the Google Meet Session\n\nEach group member should click the link provided by the group leader to join the session.\nAllow Google Meet to access your microphone and camera if prompted.\nMute your microphone by clicking the microphone icon at the bottom of the screen to reduce background noise."
  },
  {
    "objectID": "studio/week01/meet.html#sharing-your-screen",
    "href": "studio/week01/meet.html#sharing-your-screen",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Sharing Your Screen",
    "text": "Sharing Your Screen\nScreen sharing helps all group members see the same content, making collaboration easier.\n\nHow to Share Your Screen\n\nOnce in the Google Meet, click on the “Present Now” button at the bottom right of the screen.\nSelect “Your Entire Screen” or “A Window,” depending on what you want to share.\nClick “Share” to start sharing your screen.\n\nKeeping Your Microphone Off\n\nKeep your microphone muted while sharing your screen to avoid feedback or echo. Use the chat for communication or unmute only when necessary."
  },
  {
    "objectID": "studio/week01/meet.html#using-the-chat-feature",
    "href": "studio/week01/meet.html#using-the-chat-feature",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Using the Chat Feature",
    "text": "Using the Chat Feature\nThe chat feature is useful for collaboration without speaking out loud.\n\nOpen the Chat\n\nClick on the chat icon (speech bubble) in the top right corner of the screen to open the chat window.\n\nCommunicate Effectively\n\nUse the chat to ask questions, share links, and discuss the studio.\nKeep your messages clear and concise to avoid misunderstandings."
  },
  {
    "objectID": "studio/week01/meet.html#best-practices-for-google-meet-collaboration",
    "href": "studio/week01/meet.html#best-practices-for-google-meet-collaboration",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Best Practices for Google Meet Collaboration",
    "text": "Best Practices for Google Meet Collaboration\n\nStay Muted When Not Speaking: We will be in person, so no need to use your microphone in class.\nUse the Chat to Communicate: Share your thoughts and questions in the chat to maintain a smooth flow of discussion.\nKeep Your Camera On: This helps the group stay engaged and allows for better non-verbal communication.\nBe Respectful: Listen to others, avoid interrupting, and provide constructive feedback.\nEnsure Only One Person Shares at a Time: This helps avoid confusion and keeps the focus on the task at hand."
  },
  {
    "objectID": "studio/week01/meet.html#troubleshooting-tips",
    "href": "studio/week01/meet.html#troubleshooting-tips",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Troubleshooting Tips",
    "text": "Troubleshooting Tips\n\nAudio Issues: If others cannot hear you, check that your microphone is not muted and that Google Meet is using the correct microphone in the settings.\nScreen Sharing Problems: Ensure that your browser has permission to share your screen.\nConnectivity Issues: If you experience lag or get disconnected, try refreshing your browser or checking your internet connection."
  },
  {
    "objectID": "studio/week01/meet.html#wrapping-up",
    "href": "studio/week01/meet.html#wrapping-up",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nAt the end of the studio, the group leader should summarize the group’s discussion and findings. The leader will hand in the summary on Canvas.\nFor additional assistance, refer to the Google Meet Help Center or contact your instructor.\nHappy collaborating!"
  },
  {
    "objectID": "studio/week01/jupyter.html",
    "href": "studio/week01/jupyter.html",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "",
    "text": "In this exercise, you will practice basic operations in Jupyter notebooks, including writing and running Python code, working with Markdown cells, and performing simple data operations."
  },
  {
    "objectID": "studio/week01/jupyter.html#setting-up-the-notebook",
    "href": "studio/week01/jupyter.html#setting-up-the-notebook",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "1. Setting Up the Notebook",
    "text": "1. Setting Up the Notebook\n\nCreate a new notebook.\nRename it to GroupX.ipynb where X is your group number.\n\nAdd some structure at the top cells:\n# Group Exercise 1\n\nThis notebook is for practicing basic operations in Jupyter notebooks. It includes examples of using Python code and Markdown cells to document the work.\nAdd a subsection with the name Team and underneath the subsection add a bulleted list with the names of the team members.\nPut the leader’s name in bold.\nAdd a second subsection that contains a second bulleted list. Give the subsection the title Links In this list add a link to a site that each group member suggests as interesting to the class."
  },
  {
    "objectID": "studio/week01/jupyter.html#basic-code-operations",
    "href": "studio/week01/jupyter.html#basic-code-operations",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "2. Basic Code Operations",
    "text": "2. Basic Code Operations\nIn this section, you’ll write and run some simple Python code.\n# Task 1: Print a welcome message\nprint(\"Welcome to JupyterHub!\")\n# Task 2: Perform a simple arithmetic operation\n10 * 3\nprint(f'The value 10 * 3 is equal to {10 * 3}')\nRun these cells, and explore what happens as you change some of the values.\nCreate some new code cells that extend on these ideas."
  },
  {
    "objectID": "studio/week01/jupyter.html#working-with-data",
    "href": "studio/week01/jupyter.html#working-with-data",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "3. Working with Data",
    "text": "3. Working with Data\nIn this section, you’ll work with a small dataset.\n\nLoad and Display the Dataset\ndata = [100, 20, 90, 40, 50, 30, 10]\n\n# Display the dataset\ndata\n\n\nPerform a Basic Analysis\n# Task: Calculate the sum of the numbers in the dataset\nsum(data)\n# Task: Calculate the mean of the numbers in the dataset\nmean_value = sum(data) / len(data)\nmean_value\nHow would you sort the data using python? Show your answer in a code cell.\nAs a group, come up with an answer to the questions: Is the data skewed? If so, in what way? Add Markdown cells that describe your reasoning used to come up with your answers."
  },
  {
    "objectID": "studio/week01/jupyter.html#documenting-the-analysis",
    "href": "studio/week01/jupyter.html#documenting-the-analysis",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "4. Documenting the Analysis",
    "text": "4. Documenting the Analysis\nUse Markdown cells to document your code and results. For example:\n## Dataset Analysis\n\nWe loaded a dataset containing the numbers 10, 20, 30, 40, 50, 90, 100. Below is the sum and mean of these numbers.\n\nWith regard to skewness, we find ...."
  },
  {
    "objectID": "studio/week01/jupyter.html#final-touches-and-submission",
    "href": "studio/week01/jupyter.html#final-touches-and-submission",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "5. Final Touches and Submission",
    "text": "5. Final Touches and Submission\nReview your notebook as a group. Ensure that it is well-organized and the code is properly documented. Use the ability to move cells around to reorganize as needed.\nOnce done, save your notebook as a pdf.\nHave the group leader turn the pdf in on canvas."
  },
  {
    "objectID": "studio/project_proposal.html",
    "href": "studio/project_proposal.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "studio/project_proposal.html#submission-due-october-14-330-pm",
    "href": "studio/project_proposal.html#submission-due-october-14-330-pm",
    "title": "",
    "section": "Submission (Due: October 14, 3:30 PM)",
    "text": "Submission (Due: October 14, 3:30 PM)\nOn Canvas submit a pdf generated from a Markdown file."
  },
  {
    "objectID": "studio/week07/global~20241009-130607.html",
    "href": "studio/week07/global~20241009-130607.html",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 16, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week07/global~20241009-130607.html#instructions",
    "href": "studio/week07/global~20241009-130607.html#instructions",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 16, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week07/global~20241009-130607.html#input-files",
    "href": "studio/week07/global~20241009-130607.html#input-files",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "Input Files",
    "text": "Input Files\nIn this studio you will be analyzing the spatial patterns of homicide rates in the southern US Counties, from the South built-in dataset from libpysal."
  },
  {
    "objectID": "studio/week07/global~20241009-130607.html#join-count-analysis",
    "href": "studio/week07/global~20241009-130607.html#join-count-analysis",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "Join Count Analysis",
    "text": "Join Count Analysis\nFor each decade that the homicide rate is recorded complete the following:\n\nCreate a binary variable reporting high and low county homicide rates using the median rate as the threshold.\nCreate a binary map of the spatial distribution for each decade.\nDescribe the patterns you see across the decades.\nConstruct a queen contiguity matrix for the counties.\nCarry out a join counts analysis on the binary variable using the queen contiguity matrix for each decade.\nCreate a time series plot of the number of BB joins for each decade.\nProvide a narrative interpretation of your findings. Specify the null hypothesis for each decade, and state your decision whether to reject or fail to reject the null hypothesis."
  },
  {
    "objectID": "studio/week07/global~20241009-130607.html#morans-i-analysis",
    "href": "studio/week07/global~20241009-130607.html#morans-i-analysis",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "Moran’s I Analysis",
    "text": "Moran’s I Analysis\nFor each decade that the homicide rate is recorded complete the following:\n\nCreate a choropleth map of the spatial distribution of the county homicide rates for each decade.\nDescribe the patterns you see across the decades.\nCarry out a Moran’s I analysis on the original homicide variable using the queen contiguity matrix for each decade.\nCreate a time series plot of the value of the Moran’s I statistic.\nProvide a narrative interpretation of your findings. Specify the null hypothesis for each decade, and state your decision whether to reject or fail to reject the null hypothesis in each period."
  },
  {
    "objectID": "studio/week08/key.html",
    "href": "studio/week08/key.html",
    "title": "Maps",
    "section": "",
    "text": "Code\nimport libpysal\nimport esda\nimport geopandas as gpd\nCode\nsouth = libpysal.examples.load_example('South')\nCode\nsouth_gdf = gpd.read_file(south.get_path('south.shp'))\nCode\nsouth_gdf.columns\n\n\nIndex(['NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'STFIPS',\n       'COFIPS', 'FIPSNO', 'SOUTH', 'HR60', 'HR70', 'HR80', 'HR90', 'HC60',\n       'HC70', 'HC80', 'HC90', 'PO60', 'PO70', 'PO80', 'PO90', 'RD60', 'RD70',\n       'RD80', 'RD90', 'PS60', 'PS70', 'PS80', 'PS90', 'UE60', 'UE70', 'UE80',\n       'UE90', 'DV60', 'DV70', 'DV80', 'DV90', 'MA60', 'MA70', 'MA80', 'MA90',\n       'POL60', 'POL70', 'POL80', 'POL90', 'DNL60', 'DNL70', 'DNL80', 'DNL90',\n       'MFIL59', 'MFIL69', 'MFIL79', 'MFIL89', 'FP59', 'FP69', 'FP79', 'FP89',\n       'BLK60', 'BLK70', 'BLK80', 'BLK90', 'GI59', 'GI69', 'GI79', 'GI89',\n       'FH60', 'FH70', 'FH80', 'FH90', 'geometry'],\n      dtype='object')\nCode\nhrvars = [f\"HR{y}\" for y in [60, 70, 80, 90]]\nCode\nfor var in hrvars:\n    south_gdf.plot(var, scheme='quantiles', k=10)\nCode\nfor var in hrvars:\n    ax = south_gdf.plot(var, scheme='quantiles', k=10)\n    ax.set_axis_off()"
  },
  {
    "objectID": "studio/week08/key.html#local-moran",
    "href": "studio/week08/key.html#local-moran",
    "title": "Maps",
    "section": "Local Moran",
    "text": "Local Moran\n\n\nCode\nw = libpysal.weights.Queen.from_dataframe(south_gdf)\nw.transform = 'r'\n\n\n/tmp/ipykernel_2638681/159586177.py:1: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w = libpysal.weights.Queen.from_dataframe(south_gdf)\n\n\n\n\nCode\nfrom esda.moran import Moran_Local\nimport numpy\nfrom splot.esda import moran_scatterplot\nimport matplotlib.pyplot as plt\nfor var in hrvars:\n    numpy.random.seed(12345)\n    li = Moran_Local(south_gdf[var], w)\n    fig, ax = moran_scatterplot(li)\n    ax.set_xlabel(f'{var}')\n    ax.set_ylabel(f'Spatial Lag of {var}')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport numpy\nhrvars = [f\"HR{y}\" for y in [60, 70, 80, 90]]\nfor var in hrvars:\n    numpy.random.seed(12345)\n    li = Moran_Local(south_gdf[var], w)\n    fig, ax = moran_scatterplot(li, p=0.05)\n    ax.set_xlabel(f'{var}')\n    ax.set_ylabel(f'Spatial Lag of {var}')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom splot.esda import lisa_cluster\nfor var in hrvars:\n    numpy.random.seed(12345)\n    li = Moran_Local(south_gdf[var], w)\n    lisa_cluster(li, south_gdf, p=0.05, figsize=(9,9))\n    plt.show()\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom splot.esda import plot_local_autocorrelation\nfor var in hrvars:\n    numpy.random.seed(12345)\n    li = Moran_Local(south_gdf[var], w)\n    plot_local_autocorrelation(li, south_gdf, var)"
  },
  {
    "objectID": "studio/week08/key.html#persistent-hot-and-cold-spots",
    "href": "studio/week08/key.html#persistent-hot-and-cold-spots",
    "title": "Maps",
    "section": "Persistent Hot and Cold Spots",
    "text": "Persistent Hot and Cold Spots\n\n\nCode\nfor var in hrvars:\n    numpy.random.seed(12345)\n    li = Moran_Local(south_gdf[var], w)\n    hot_spot = (li.q==1) * (li.p_sim &lt; 0.05)\n    cold_spot = (li.q==3) * (li.p_sim &lt; 0.05)\n    south_gdf[f'hot_{var}'] = hot_spot\n    south_gdf[f'cold_{var}'] = cold_spot\n    \n\n\n\n\nCode\nsouth_gdf[['hot_HR60','hot_HR70', 'hot_HR80', 'hot_HR90']].sum()\n\n\nhot_HR60    142\nhot_HR70    141\nhot_HR80    139\nhot_HR90    127\ndtype: int64\n\n\n\n\nCode\ng = south_gdf\npersistent_hot = \n\n\n\n\nCode\ng.hot_HR60 * g.hot_HR70 * g.hot_HR80 * g.hot_HR90\n\n\n\n\nCode\nsouth_gdf['persistent_hot'] = persistent_hot\n\n\n\n\nCode\nsouth_gdf.plot('persistent_hot', categorical=True, legend=True,\n              legend_kwds=dict(bbox_to_anchor=(1.05, 1), loc='upper left'))\n\n\n\n\n\n\n\n\n\n\n\nCode\npersistent_cold = g.cold_HR60 * g.cold_HR70 * g.cold_HR80 * g.cold_HR90\nsouth_gdf['persistent_cold'] = persistent_cold\n\n\n\n\nCode\nsouth_gdf.plot('persistent_cold', categorical=True, legend=True,\n                legend_kwds=dict(bbox_to_anchor=(1.05, 1), loc='upper left'))"
  },
  {
    "objectID": "studio/week08/key.html#pooled-classification",
    "href": "studio/week08/key.html#pooled-classification",
    "title": "Maps",
    "section": "Pooled classification",
    "text": "Pooled classification\n\n\nCode\nimport mapclassify\n# Create pooled classification\npooled = mapclassify.Pooled(south_gdf[hrvars], classifier=\"Quantiles\", k=10)\n\n# Set up figure with four axis\nf, axs = plt.subplots(2, 2, figsize=(12, 12))\n# Flatten the array of axis so you can loop over\n# in one dimension\naxs = axs.flatten()\n# Loop over each year\nfor i, y in enumerate(hrvars):\n    south_gdf.plot(\n        y,  # Year to plot\n        scheme=\"UserDefined\",  # Use our own bins\n        classification_kwds={\n            \"bins\": pooled.global_classifier.bins\n        },  # Use global bins\n        legend=True,  # Add a legend\n        ax=axs[i],  # Plot on the corresponding axis\n        legend_kwds=dict(bbox_to_anchor=(1.05, 1), loc='upper left')\n    )\n    # Remove axis\n    axs[i].set_axis_off()\n    # Name the subplot with the name of the column\n    axs[i].set_title(y)\n# Tight layout to better use space\nplt.tight_layout()\n# Display figure\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport mapclassify\n# Create pooled classification\npooled = mapclassify.Pooled(south_gdf[hrvars], classifier=\"Quantiles\", k=10)\n\n# Set up figure with four axis\nf, axs = plt.subplots(2, 2, figsize=(12, 12))\n# Flatten the array of axis so you can loop over\n# in one dimension\naxs = axs.flatten()\n# Loop over each year\nlegend=False\nfor i, y in enumerate(hrvars):\n    if i==3:\n        legend=True\n    south_gdf.plot(\n        y,  # Year to plot\n        scheme=\"UserDefined\",  # Use our own bins\n        classification_kwds={\n            \"bins\": pooled.global_classifier.bins\n        },  # Use global bins\n        legend=legend,  # Add a legend\n        ax=axs[i],  # Plot on the corresponding axis\n        legend_kwds=dict(bbox_to_anchor=(1.05, 1), loc='upper left')\n    )\n    # Remove axis\n    axs[i].set_axis_off()\n    # Name the subplot with the name of the column\n    axs[i].set_title(y)\n# Tight layout to better use space\nplt.tight_layout()\n# Display figure\nplt.show()"
  },
  {
    "objectID": "studio/week06/peer1.html",
    "href": "studio/week06/peer1.html",
    "title": "Studio 06 Peer Evaluation 1",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 9, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-02 Studio 6: Peer Evaluation 1"
    ]
  },
  {
    "objectID": "studio/week06/peer1.html#instructions",
    "href": "studio/week06/peer1.html#instructions",
    "title": "Studio 06 Peer Evaluation 1",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 9, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-02 Studio 6: Peer Evaluation 1"
    ]
  },
  {
    "objectID": "studio/week06/peer1.html#scheduling",
    "href": "studio/week06/peer1.html#scheduling",
    "title": "Studio 06 Peer Evaluation 1",
    "section": "Scheduling",
    "text": "Scheduling\n\nDetermine which team members have an approved computational essay topic.\nSchedule 10 minutes for each of these topics",
    "crumbs": [
      "Home",
      "10-02 Studio 6: Peer Evaluation 1"
    ]
  },
  {
    "objectID": "studio/week06/peer1.html#minute-section",
    "href": "studio/week06/peer1.html#minute-section",
    "title": "Studio 06 Peer Evaluation 1",
    "section": "10 Minute Section",
    "text": "10 Minute Section\n\nTeam leader creates a new section of the notebook with the presenters name\nA student presents their topic (2 minutes)\nEach remaining member of the team provides feedback and questions to the student (8 minutes)\nTeam leader captures this feedback in the notebook",
    "crumbs": [
      "Home",
      "10-02 Studio 6: Peer Evaluation 1"
    ]
  },
  {
    "objectID": "studio/week06/peer1.html#potential-questions-to-askfeedback-prompts",
    "href": "studio/week06/peer1.html#potential-questions-to-askfeedback-prompts",
    "title": "Studio 06 Peer Evaluation 1",
    "section": "Potential Questions to Ask/Feedback Prompts",
    "text": "Potential Questions to Ask/Feedback Prompts\n\nIs the research question clearly stated?\nDoes the topic clearly involve spatial analysis?\nAre spatial relationships and geographic context central to the question?\nConsiderations for emphasizing or incorporating spatial aspects more effectively.\nAre the data sources identified?\nAre these data sources appropriate for the research question?\nSuggestions for alternative or additional data sources, if needed.\n\nAll team members, whether they are doing a computational essay or not, must participate in the peer evaluation process.",
    "crumbs": [
      "Home",
      "10-02 Studio 6: Peer Evaluation 1"
    ]
  },
  {
    "objectID": "studio/week02/studio.html",
    "href": "studio/week02/studio.html",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 11, 2024 3:30pm\nUsing the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/studio.html#instructions",
    "href": "studio/week02/studio.html#instructions",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 11, 2024 3:30pm\nUsing the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/studio.html#setup",
    "href": "studio/week02/studio.html#setup",
    "title": "Studio 02 Pandas",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\n\ndf = pd.read_csv(\"merged.csv\")"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "href": "studio/week02/studio.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital city with the largest population of all capital cities?",
    "text": "Which region has the capital city with the largest population of all capital cities?\n\n# your code here"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "href": "studio/week02/studio.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region contains the largest number of people living in its capital cities?",
    "text": "Which region contains the largest number of people living in its capital cities?\n\n# your code here"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "href": "studio/week02/studio.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital cities with the highest population density (median)?",
    "text": "Which region has the capital cities with the highest population density (median)?\n\n# your code here"
  },
  {
    "objectID": "studio/week02/key.html",
    "href": "studio/week02/key.html",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Using the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/key.html#instructions",
    "href": "studio/week02/key.html#instructions",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Using the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/key.html#setup",
    "href": "studio/week02/key.html#setup",
    "title": "Studio 02 Pandas",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\n\ndf = pd.read_csv(\"merged.csv\")"
  },
  {
    "objectID": "studio/week02/key.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "href": "studio/week02/key.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital city with the largest population of all capital cities?",
    "text": "Which region has the capital city with the largest population of all capital cities?\n\ndf[['region', 'CityPop', 'description']].sort_values(by='CityPop', ascending=False)\n\n\n\n\n\n\n\n\nregion\nCityPop\ndescription\n\n\n\n\n2\nSW\n1608139\nPhoenix\n\n\n42\nSW\n961855\nAustin\n\n\n34\nNE\n905748\nColumbus\n\n\n13\nSE\n887642\nIndianapolis\n\n\n5\nSW\n715522\nDenver\n\n\n41\nSE\n689447\nNashville\n\n\n35\nSW\n681054\nOklahoma City\n\n\n20\nNE\n675647\nBoston\n\n\n4\nSW\n524943\nSacramento\n\n\n10\nSE\n498715\nAtlanta&lt;br&gt;\n\n\n31\nSE\n467665\nRaleigh\n\n\n8\nSW\n350964\nHonolulu\n\n\n22\nNW\n311527\nSt. Paul\n\n\n26\nNW\n291082\nLincoln\n\n\n48\nNE\n269840\nMadison\n\n\n11\nNW\n235684\nBoise\n\n\n17\nSW\n227470\nBaton Rouge\n\n\n45\nSE\n226610\nRichmond\n\n\n14\nNW\n214133\nDes Moines\n\n\n3\nSW\n202591\nLittle Rock\n\n\n0\nSE\n200603\nMontgomery\n\n\n43\nNW\n199723\nSalt Lake City\n\n\n9\nSE\n196169\nTallahassee\n\n\n38\nNE\n190934\nProvidence\n\n\n36\nNW\n175535\nSalem\n\n\n23\nSW\n153701\nJackson\n\n\n39\nSE\n136632\nColumbia\n\n\n15\nSW\n126587\nTopeka\n\n\n6\nNE\n121054\nHartford&lt;br&gt;\n\n\n12\nNE\n114394\nSpringfield\n\n\n21\nNE\n112644\nLansing\n\n\n33\nNE\n99224\nAlbany\n\n\n29\nNE\n90871\nTrenton\n\n\n30\nSW\n87505\nSanta Fe\n\n\n32\nNW\n73622\nBismarck\n\n\n49\nNW\n65132\nCheyenne\n\n\n27\nSW\n58639\nCarson City\n\n\n46\nNW\n55605\nOlympia\n\n\n37\nNE\n50099\nHarrisburg\n\n\n47\nSE\n48864\nCharleston\n\n\n28\nNE\n43976\nConcord\n\n\n24\nSW\n43228\nJefferson City\n\n\n19\nSE\n40812\nAnnapolis\n\n\n7\nSE\n39403\nDover\n\n\n1\nNW\n32255\nJuneau\n\n\n25\nNW\n32091\nHelena\n\n\n16\nSE\n28602\nFrankfort\n\n\n18\nNE\n18899\nAugusta\n\n\n40\nNW\n14091\nPierre\n\n\n44\nNE\n8074\nMontpelier"
  },
  {
    "objectID": "studio/week02/key.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "href": "studio/week02/key.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region contains the largest number of people living in its capital cities?",
    "text": "Which region contains the largest number of people living in its capital cities?\n\ndf[['region', 'CityPop']].groupby(by='region').sum()\n\n\n\n\n\n\n\n\nCityPop\n\n\nregion\n\n\n\n\n\nNE\n2701404\n\n\nNW\n1700480\n\n\nSE\n3461164\n\n\nSW\n5742198"
  },
  {
    "objectID": "studio/week02/key.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "href": "studio/week02/key.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital cities with the highest population density (median)?",
    "text": "Which region has the capital cities with the highest population density (median)?\n\ndf['density'] = df.CityPop / df.area\ndf[['density', 'region']].groupby(by='region').median()\n\n\n\n\n\n\n\n\ndensity\n\n\nregion\n\n\n\n\n\nNE\n4306.932953\n\n\nNW\n2955.899130\n\n\nSE\n1997.773548\n\n\nSW\n2345.978552"
  },
  {
    "objectID": "studio/week04/studio.html",
    "href": "studio/week04/studio.html",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 25, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week04/studio.html#instructions",
    "href": "studio/week04/studio.html#instructions",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 25, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week04/studio.html#input-files",
    "href": "studio/week04/studio.html#input-files",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Input Files",
    "text": "Input Files\nNone. You will collect all data from geosnap"
  },
  {
    "objectID": "studio/week04/studio.html#reading-the-spatial-data-files",
    "href": "studio/week04/studio.html#reading-the-spatial-data-files",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Reading the spatial data files",
    "text": "Reading the spatial data files\nUse geosnap to collect 2017 environmental justice screening data for the San Francisco metropolitan region\n(hint: the MSA fips code for the Bay Area is 41860)\n\nfrom geosnap import DataStore\n\ndatasets = DataStore(\"/srv/data/geosnap\")\n\n# uncomment the following line and complete the code\n#bay_ejscreen = gio.get_ejscreen(datasets, msa_fips=\"????\", years=????)"
  },
  {
    "objectID": "studio/week04/studio.html#report-whether-the-current-coordinate-reference-system-is-currently-projected",
    "href": "studio/week04/studio.html#report-whether-the-current-coordinate-reference-system-is-currently-projected",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Report whether the current coordinate reference system is currently projected",
    "text": "Report whether the current coordinate reference system is currently projected\n\n#bay_ejscreen.????.is_projected"
  },
  {
    "objectID": "studio/week04/studio.html#convert-the-geodataframe-into-a-geographic-coordinate-system",
    "href": "studio/week04/studio.html#convert-the-geodataframe-into-a-geographic-coordinate-system",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Convert the GeoDataFrame into a geographic coordinate system",
    "text": "Convert the GeoDataFrame into a geographic coordinate system\nhint: a the standard GCS is 4326\n\n#bay_ejscreen = bay_ejscreen.to_crs(????)"
  },
  {
    "objectID": "studio/week04/studio.html#collect-highway-data-in-the-bay-area-from-open-street-map",
    "href": "studio/week04/studio.html#collect-highway-data-in-the-bay-area-from-open-street-map",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Collect highway data in the Bay Area from Open street map",
    "text": "Collect highway data in the Bay Area from Open street map\n(hint: first take the union of the Bay Area geometries)\n\n#bay_union = bay_ejscreen.???_all()\n\n#highways = ox.features_from_polygon(bay_union, tags={\"highway\": \"????\"})"
  },
  {
    "objectID": "studio/week04/studio.html#convert-the-bay-area-geodataframe-into-an-appropriate-coordinate-system",
    "href": "studio/week04/studio.html#convert-the-bay-area-geodataframe-into-an-appropriate-coordinate-system",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Convert the Bay Area GeoDataFrame into an appropriate coordinate system",
    "text": "Convert the Bay Area GeoDataFrame into an appropriate coordinate system\nhint: a reasonable coordinate system for the Bay Area is EPSG 6419\n\n#bay_ejscreen = bay_ejscreen.to_crs(????)"
  },
  {
    "objectID": "studio/week04/studio.html#select-the-bay-area-census-blockgroups-that-are-within-2000-meters-of-a-highway",
    "href": "studio/week04/studio.html#select-the-bay-area-census-blockgroups-that-are-within-2000-meters-of-a-highway",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Select the Bay Area Census Blockgroups that are within 2000 meters of a highway",
    "text": "Select the Bay Area Census Blockgroups that are within 2000 meters of a highway\nhint: first buffer the highway then take the intersection (ensure your geodataframes share a coordinate system before taking the intersection)"
  },
  {
    "objectID": "studio/week04/studio.html#what-is-the-median-of-the-variable-pm25-for-the-blockgroups-in-the-highway-zone",
    "href": "studio/week04/studio.html#what-is-the-median-of-the-variable-pm25-for-the-blockgroups-in-the-highway-zone",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "what is the median of the variable PM25 for the blockgroups in the highway zone?",
    "text": "what is the median of the variable PM25 for the blockgroups in the highway zone?"
  },
  {
    "objectID": "studio/week04/index.html",
    "href": "studio/week04/index.html",
    "title": "Week 4 Studio: geosnap",
    "section": "",
    "text": "This week we introduce geosnap:\n\nIntroduction to geosnap and geoprocessing\nStudio exercise",
    "crumbs": [
      "Home",
      "09-18 Studio 4: Geosnap and Geoprocessing"
    ]
  },
  {
    "objectID": "studio/week05/index.html",
    "href": "studio/week05/index.html",
    "title": "Week 5 Studio: Choropleth Mapping",
    "section": "",
    "text": "Choropleths\nStudio exercise",
    "crumbs": [
      "Home",
      "09-25 Studio 5: Choropleth Mapping "
    ]
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html",
    "href": "studio/week03/studio3_geopandas.html",
    "title": "GeoPandas",
    "section": "",
    "text": "Earlier in the course we had a figure to illustrate vector spatial data:\n\n\n\nVector GIS\n\n\nThis figure was built with the following code:\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon as MplPolygon\n\n# Data for streets (line strings)\nstreets = [\n    [(0, 0), (1, 2), (3, 3)],\n    [(3, 3), (5, 2), (7, 5)],\n    [(7, 5), (8, 8), (10, 10)],\n    [(1, 2), (2, 5), (4, 6)],\n]\n\n# Data for school catchments (polygons)\ncatchments = [\n    [(0.5, 0.5), (2, 1), (1.5, 3), (0.5, 2)],\n    [(3, 4), (5, 3.5), (6, 6), (4, 6.5)],\n    [(7, 7), (8.5, 7.5), (9, 9), (7.5, 9)],\n]\n\n# Adjusting the data for one school per catchment\nschools = [(1.2, 1.8), (4.7, 5.3), (8.2, 8.2)]\n\n# Plotting the GIS map with one school per catchment\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plotting the streets with one legend entry\nax.plot(*zip(*streets[0]), color='blue', linewidth=2, label=\"Streets\")\nfor street in streets[1:]:\n    street_x, street_y = zip(*street)\n    ax.plot(street_x, street_y, color='blue', linewidth=2)\n\n# Plotting the catchments with legend\nfor i, catchment in enumerate(catchments):\n    polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n    ax.add_patch(polygon)\n    if i == 0:\n        polygon.set_label(\"School Catchments\")\n\n# Plotting the schools (points) with one per catchment\nschool_x, school_y = zip(*schools)\nax.scatter(school_x, school_y, color='green', s=100, label=\"Schools\")\n\n# Set the legend and title\nax.legend()\nax.set_title('Vector GIS: Street Network, School Catchments, and Schools')\nax.set_xlim(-1, 11)\nax.set_ylim(-1, 11)\nax.set_aspect('equal')\n\n# Save the figure to a file\nplt.savefig(\"vector.png\", dpi=300)\n\n# Show the plot\nplt.show()\n\n/tmp/ipykernel_15976/1512531908.py:33: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n  polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n\n\n\n\n\n\n\n\n\nHere, we are faking it regarding a GIS, as matplotlib is a visualization library and doesn’t actually allow us to do any spatial analysis per se.\nFortunately, there are a number of Python packages that are designed to wrangle spatial data:\n\nshapely\nGeoPandas"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#geometries-for-vector-spatial-data",
    "href": "studio/week03/studio3_geopandas.html#geometries-for-vector-spatial-data",
    "title": "GeoPandas",
    "section": "",
    "text": "Earlier in the course we had a figure to illustrate vector spatial data:\n\n\n\nVector GIS\n\n\nThis figure was built with the following code:\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon as MplPolygon\n\n# Data for streets (line strings)\nstreets = [\n    [(0, 0), (1, 2), (3, 3)],\n    [(3, 3), (5, 2), (7, 5)],\n    [(7, 5), (8, 8), (10, 10)],\n    [(1, 2), (2, 5), (4, 6)],\n]\n\n# Data for school catchments (polygons)\ncatchments = [\n    [(0.5, 0.5), (2, 1), (1.5, 3), (0.5, 2)],\n    [(3, 4), (5, 3.5), (6, 6), (4, 6.5)],\n    [(7, 7), (8.5, 7.5), (9, 9), (7.5, 9)],\n]\n\n# Adjusting the data for one school per catchment\nschools = [(1.2, 1.8), (4.7, 5.3), (8.2, 8.2)]\n\n# Plotting the GIS map with one school per catchment\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plotting the streets with one legend entry\nax.plot(*zip(*streets[0]), color='blue', linewidth=2, label=\"Streets\")\nfor street in streets[1:]:\n    street_x, street_y = zip(*street)\n    ax.plot(street_x, street_y, color='blue', linewidth=2)\n\n# Plotting the catchments with legend\nfor i, catchment in enumerate(catchments):\n    polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n    ax.add_patch(polygon)\n    if i == 0:\n        polygon.set_label(\"School Catchments\")\n\n# Plotting the schools (points) with one per catchment\nschool_x, school_y = zip(*schools)\nax.scatter(school_x, school_y, color='green', s=100, label=\"Schools\")\n\n# Set the legend and title\nax.legend()\nax.set_title('Vector GIS: Street Network, School Catchments, and Schools')\nax.set_xlim(-1, 11)\nax.set_ylim(-1, 11)\nax.set_aspect('equal')\n\n# Save the figure to a file\nplt.savefig(\"vector.png\", dpi=300)\n\n# Show the plot\nplt.show()\n\n/tmp/ipykernel_15976/1512531908.py:33: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n  polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n\n\n\n\n\n\n\n\n\nHere, we are faking it regarding a GIS, as matplotlib is a visualization library and doesn’t actually allow us to do any spatial analysis per se.\nFortunately, there are a number of Python packages that are designed to wrangle spatial data:\n\nshapely\nGeoPandas"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#shapely",
    "href": "studio/week03/studio3_geopandas.html#shapely",
    "title": "GeoPandas",
    "section": "shapely",
    "text": "shapely\nShapely (Gillies et al. 2007--) is a Python package for the manipulation and analysis of planar geometric objects.\nWe can use shapely to build up our example, starting with its Point class:\n\nfrom shapely import Point\n\nThe Point class can be used to create instances for each of our schools, here using a python list comprehension:\n\nschool_points = [Point(school) for school in schools]\n\nThis results in a python list containing three shapely point objects:\n\nschool_points\n\n[&lt;POINT (1.2 1.8)&gt;, &lt;POINT (4.7 5.3)&gt;, &lt;POINT (8.2 8.2)&gt;]\n\n\nIf we ask for the first point, we get a rendered point.\n\nschool_points[0]\n\n\n\n\n\n\n\n\nAnd, if we unpack the list into individual points, we should see similar behavior.\n\nschool_0, school_1, school_2 = school_points\n\n\nschool_0\n\n\n\n\n\n\n\n\n\nschool_1\n\n\n\n\n\n\n\n\n\nschool_2\n\n\n\n\n\n\n\n\nJust like we did for points, we can rely on shapely for dealing with our catchments, but this time using the Polygon class:\n\nfrom shapely import Polygon\n\n\ncatchment_polygons = [Polygon(catchment) for catchment in catchments]\n\n\ncatchment_0, catchment_1, catchment_2 = catchment_polygons\n\n\ncatchment_0\n\n\n\n\n\n\n\n\n\ncatchment_1\n\n\n\n\n\n\n\n\n\ncatchment_2\n\n\n\n\n\n\n\n\nAnd, finally, we can model the road network using the LineString class:\n\nfrom shapely import LineString\n\n\nstreet_lines = [LineString(street) for street in streets]\n\n\nstreet_0, street_1, street_2, street_3 = street_lines\n\n\nstreet_0\n\n\n\n\n\n\n\n\n\nstreet_1\n\n\n\n\n\n\n\n\n\nstreet_2\n\n\n\n\n\n\n\n\n\nstreet_3\n\n\n\n\n\n\n\n\n\nshapely Geometry Types\n\nschool_0.geom_type\n\n'Point'\n\n\n\nschool_2.geom_type\n\n'Point'\n\n\nPoints are zero-dimensional geometries, and thus have 0 area and 0 length:\n\nschool_0.area\n\n0.0\n\n\n\nschool_0.length\n\n0.0\n\n\n\nlist(school_0.coords)\n\n[(1.2, 1.8)]\n\n\n\nlist(school_2.coords)\n\n[(8.2, 8.2)]\n\n\nLineStrings are one-dimensional geometric objects, having length but 0 area\n\nstreet_1.length\n\n5.841619252963779\n\n\n\nstreet_1.area\n\n0.0\n\n\nFinally, Polygons are two-dimensional geometric objects, having area:\n\ncatchment_1.area\n\n5.5\n\n\nas well as length:\n\ncatchment_1.length\n\n9.508270432752164\n\n\n\n\ngeometry methods and spatial predicates\nThe power of these geometries comes from the functions and abilities to evaluate spatial predicates. These give us the building blocks of GIS operations for vector spatial data:\nTo see this, we can call the distance method of school_0 to determine the distance separating it from school_2:\n\nschool_0.distance(school_2)\n\n9.4847245611035\n\n\nWe can also measure the difference between objects of different geometry types:\n\nstreet_1.geom_type\n\n'LineString'\n\n\n\nschool_0.distance(street_1)\n\n2.1633307652783933\n\n\n\ncatchment_0.geom_type\n\n'Polygon'\n\n\n\ncatchment_0.area\n\n2.375\n\n\n\nlist(catchment_0.exterior.coords)\n\n[(0.5, 0.5), (2.0, 1.0), (1.5, 3.0), (0.5, 2.0), (0.5, 0.5)]\n\n\n\ncatchment_0.bounds\n\n(0.5, 0.5, 2.0, 3.0)\n\n\n\nschool_0.distance(catchment_0)\n\n0.0\n\n\n\ncatchment_0.contains(school_0)\n\nTrue\n\n\n\ncatchment_0.contains(school_1)\n\nFalse\n\n\n\nschool_1.distance(catchment_0)\n\n3.9408120990476063\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll the area, distance, and other measurements done with shapely objects utilize Cartesian coordinates."
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#geopandas",
    "href": "studio/week03/studio3_geopandas.html#geopandas",
    "title": "GeoPandas",
    "section": "GeoPandas",
    "text": "GeoPandas\nGeoPandas (Jordahl et al. 2020) is a python package that makes working with geospatial data easier. It relies on shapely and other libraries to extend the datatypes used by Pandas to allow spatial operations on geometric types.\nThe two important classes in GeoPandas are:\n\nGeoSeries\nGeoDataFrame\n\nThese are spatial extensions of the Series and DataFrame classes from pandas.\n\nimport and aliasing\n\nimport geopandas as gpd\n\n\n\nGeoSeries\nA GeoSeries is essentially a pandas Series object designed to store shapely geometry types:\n\nstreets = gpd.GeoSeries(street_lines)\n\n\nstreets.plot()\n\n\n\n\n\n\n\n\n\ncatchments = gpd.GeoSeries(catchment_polygons)\n\n\ncatchments.plot()\n\n\n\n\n\n\n\n\n\nschools = gpd.GeoSeries(school_points)\n\n\nschools.plot()\n\n\n\n\n\n\n\n\n\ntype(schools)\n\ngeopandas.geoseries.GeoSeries\n\n\n\n\nGeoDataFrame\nA GeoDataFrame is similar to a pandas DataFrame but includes at least one GeoSeries and supports spatial operations on its data.\n\nschools_gdf = gpd.GeoDataFrame(geometry=schools)\n\n\nschools_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOINT (1.2 1.8)\n\n\n1\nPOINT (4.7 5.3)\n\n\n2\nPOINT (8.2 8.2)\n\n\n\n\n\n\n\n\ntype(schools_gdf)\n\ngeopandas.geodataframe.GeoDataFrame\n\n\n\nschools_gdf['students'] = [124, 94, 100]\n\n\nschools_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\nstudents\n\n\n\n\n0\nPOINT (1.2 1.8)\n124\n\n\n1\nPOINT (4.7 5.3)\n94\n\n\n2\nPOINT (8.2 8.2)\n100\n\n\n\n\n\n\n\n\nschools_gdf.plot()\n\n\n\n\n\n\n\n\n\nschools_gdf.plot(column='students')\n\n\n\n\n\n\n\n\n\nstreets_gdf = gpd.GeoDataFrame(geometry=streets)\n\n\nstreets_gdf.plot()\n\n\n\n\n\n\n\n\n\nstreets_gdf['length'] = streets_gdf.length\n\n\nstreets_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\nlength\n\n\n\n\n0\nLINESTRING (0 0, 1 2, 3 3)\n4.472136\n\n\n1\nLINESTRING (3 3, 5 2, 7 5)\n5.841619\n\n\n2\nLINESTRING (7 5, 8 8, 10 10)\n5.990705\n\n\n3\nLINESTRING (1 2, 2 5, 4 6)\n5.398346\n\n\n\n\n\n\n\n\nstreets_gdf.plot(column='length', legend=True)\n\n\n\n\n\n\n\n\n\ncatchments_gdf = gpd.GeoDataFrame(geometry=catchment_polygons)\n\n\ncatchments_gdf['area'] = catchments_gdf.area\ncatchments_gdf.plot(column='area', legend=True)\n\n\n\n\n\n\n\n\n\n\nThe geometry of a GeoDataFrame\nOne of the key differences between a GeoDataFrame and a pandas DataFrame is that the former will have a geometry column that holds a GeoSeries:\n\ncatchments_gdf.geometry\n\n0    POLYGON ((0.5 0.5, 2 1, 1.5 3, 0.5 2, 0.5 0.5))\n1            POLYGON ((3 4, 5 3.5, 6 6, 4 6.5, 3 4))\n2          POLYGON ((7 7, 8.5 7.5, 9 9, 7.5 9, 7 7))\nName: geometry, dtype: geometry\n\n\n\ncatchments_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\narea\n\n\n\n\n0\nPOLYGON ((0.5 0.5, 2 1, 1.5 3, 0.5 2, 0.5 0.5))\n2.375\n\n\n1\nPOLYGON ((3 4, 5 3.5, 6 6, 4 6.5, 3 4))\n5.500\n\n\n2\nPOLYGON ((7 7, 8.5 7.5, 9 9, 7.5 9, 7 7))\n2.500\n\n\n\n\n\n\n\nA GeoDataFrame can contained more than a single GeoSeries but only one can be operative as far as the geometry attribute is concerned. To see this, let’s add a second GeoSeries to the catchments GeoDataFrame:\n\ncatchments_gdf.centroid\n\n0    POINT (1.17544 1.60526)\n1              POINT (4.5 5)\n2    POINT (7.96667 8.13333)\ndtype: geometry\n\n\n\ncatchments_gdf['centroid_point'] = catchments_gdf.centroid\ncatchments_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\narea\ncentroid_point\n\n\n\n\n0\nPOLYGON ((0.5 0.5, 2 1, 1.5 3, 0.5 2, 0.5 0.5))\n2.375\nPOINT (1.17544 1.60526)\n\n\n1\nPOLYGON ((3 4, 5 3.5, 6 6, 4 6.5, 3 4))\n5.500\nPOINT (4.5 5)\n\n\n2\nPOLYGON ((7 7, 8.5 7.5, 9 9, 7.5 9, 7 7))\n2.500\nPOINT (7.96667 8.13333)\n\n\n\n\n\n\n\nNow we can set the geometry to be the centroid_point GeoSeries:\n\ncatchments_gdf.set_geometry('centroid_point', inplace=True)\ncatchments_gdf.plot()\n\n\n\n\n\n\n\n\nAnd we could return to the polygons with:\n\ncatchments_gdf.set_geometry('geometry', inplace=True)\ncatchments_gdf.plot()"
  },
  {
    "objectID": "studio/week03/index.html",
    "href": "studio/week03/index.html",
    "title": "Week 3 Studio: GeoPandas",
    "section": "",
    "text": "This week we introduce GeoPandas:\n\nIntroduction to GeoPandas\nStudio exercise",
    "crumbs": [
      "Home",
      "09-11 Studio 3: GeoPandas"
    ]
  },
  {
    "objectID": "assignments/python_course.html#definition-of-spatial-data-analysis",
    "href": "assignments/python_course.html#definition-of-spatial-data-analysis",
    "title": "Python Primer",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "assignments/python_course.html#importance-of-spatial-data-analysis",
    "href": "assignments/python_course.html#importance-of-spatial-data-analysis",
    "title": "Python Primer",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "assignments/python_course.html#historical-context",
    "href": "assignments/python_course.html#historical-context",
    "title": "Python Primer",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "assignments/python_course.html#vector-data",
    "href": "assignments/python_course.html#vector-data",
    "title": "Python Primer",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "assignments/python_course.html#vector-data-1",
    "href": "assignments/python_course.html#vector-data-1",
    "title": "Python Primer",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "assignments/python_course.html#raster-data",
    "href": "assignments/python_course.html#raster-data",
    "title": "Python Primer",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "assignments/python_course.html#attribute-data",
    "href": "assignments/python_course.html#attribute-data",
    "title": "Python Primer",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "assignments/python_course.html#attribute-data-1",
    "href": "assignments/python_course.html#attribute-data-1",
    "title": "Python Primer",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "assignments/python_course.html#temporal-spatial-data",
    "href": "assignments/python_course.html#temporal-spatial-data",
    "title": "Python Primer",
    "section": "Temporal-Spatial Data",
    "text": "Temporal-Spatial Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "assignments/python_course.html#remote-sensing",
    "href": "assignments/python_course.html#remote-sensing",
    "title": "Python Primer",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "assignments/python_course.html#geographic-information-systems-gis",
    "href": "assignments/python_course.html#geographic-information-systems-gis",
    "title": "Python Primer",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "assignments/python_course.html#global-positioning-system-gps",
    "href": "assignments/python_course.html#global-positioning-system-gps",
    "title": "Python Primer",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "assignments/python_course.html#crowdsourced-data",
    "href": "assignments/python_course.html#crowdsourced-data",
    "title": "Python Primer",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "assignments/python_course.html#spatial-autocorrelation",
    "href": "assignments/python_course.html#spatial-autocorrelation",
    "title": "Python Primer",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "assignments/python_course.html#spatial-scale-and-resolution",
    "href": "assignments/python_course.html#spatial-scale-and-resolution",
    "title": "Python Primer",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "assignments/python_course.html#modifiable-areal-unit-problem-maup",
    "href": "assignments/python_course.html#modifiable-areal-unit-problem-maup",
    "title": "Python Primer",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "assignments/python_course.html#modifiable-areal-unit-problem-maup-1",
    "href": "assignments/python_course.html#modifiable-areal-unit-problem-maup-1",
    "title": "Python Primer",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "assignments/python_course.html#spatial-interpolation",
    "href": "assignments/python_course.html#spatial-interpolation",
    "title": "Python Primer",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "assignments/python_course.html#spatial-interpolation-1",
    "href": "assignments/python_course.html#spatial-interpolation-1",
    "title": "Python Primer",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "assignments/python_course.html#public-health",
    "href": "assignments/python_course.html#public-health",
    "title": "Python Primer",
    "section": "Public Health",
    "text": "Public Health\n\nTracking disease outbreaks, identifying health disparities."
  },
  {
    "objectID": "assignments/python_course.html#environmental-management",
    "href": "assignments/python_course.html#environmental-management",
    "title": "Python Primer",
    "section": "Environmental Management",
    "text": "Environmental Management\n\nMonitoring deforestation, analyzing pollution patterns."
  },
  {
    "objectID": "assignments/python_course.html#urban-planning",
    "href": "assignments/python_course.html#urban-planning",
    "title": "Python Primer",
    "section": "Urban Planning",
    "text": "Urban Planning\n\nInfrastructure development, zoning, transportation networks."
  },
  {
    "objectID": "assignments/python_course.html#emergency-response",
    "href": "assignments/python_course.html#emergency-response",
    "title": "Python Primer",
    "section": "Emergency Response",
    "text": "Emergency Response\n\nDisaster management, evacuation planning, resource allocation."
  },
  {
    "objectID": "assignments/python_course.html#conclusion-and-qa-3-minutes",
    "href": "assignments/python_course.html#conclusion-and-qa-3-minutes",
    "title": "Python Primer",
    "section": "Conclusion and Q&A (3 minutes)",
    "text": "Conclusion and Q&A (3 minutes)"
  },
  {
    "objectID": "assignments/python_course.html#recap-of-key-points",
    "href": "assignments/python_course.html#recap-of-key-points",
    "title": "Python Primer",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nOverview of spatial data types, key concepts, and applications."
  },
  {
    "objectID": "assignments/python_course.html#importance-of-spatial-data-analysis-1",
    "href": "assignments/python_course.html#importance-of-spatial-data-analysis-1",
    "title": "Python Primer",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nEmphasis on its growing relevance in various fields."
  },
  {
    "objectID": "assignments/python_course.html#open-floor-for-questions",
    "href": "assignments/python_course.html#open-floor-for-questions",
    "title": "Python Primer",
    "section": "Open Floor for Questions",
    "text": "Open Floor for Questions\n\nEncourage students to ask questions or discuss topics of interest."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nGillies, Sean et al. 2007--. “Shapely: Manipulation and Analysis of Geometric Objects.” toblerity.org. https://github.com/Toblerity/Shapely.\n\n\nHarrower, Mark, and Cynthia A. Brewer. 2003. “ColorBrewer.org: An Online Tool for Selecting Colour Schemes for Maps.” The Cartographic Journal 40 (1): 27–37. https://doi.org/10.1179/000870403235002042.\n\n\nHunter, John D. 2007a. “Matplotlib: A 2D Graphics Environment.” Computing in Science & Engineering 9 (3): 90–95. https://doi.org/10.1109/MCSE.2007.55.\n\n\n———. 2007b. “Matplotlib: A 2D Graphics Environment.” Computing in Science & Engineering 9 (3): 90–95. https://doi.org/10.1109/MCSE.2007.55.\n\n\nJordahl, Kelsey, Joris Van den Bossche, Martin Fleischmann, Jacob Wasserman, James McBride, Jeffrey Gerard, Jeff Tratner, et al. 2020. “Geopandas/Geopandas: V0.8.1.” Zenodo. https://doi.org/10.5281/zenodo.3946761.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nLongley, Paul A, and James A Cheshire. 2017. “Geographical Information Systems.” In The Routledge Handbook of Mapping and Cartography, 251–58. Routledge.\n\n\nMcKinney, Wes. 2010. “Data Structures for Statistical Computing in Python.” In Proceedings of the 9th Python in Science Conference, edited by Stéfan van der Walt and Jarrod Millman, 56–61. https://doi.org/10.25080/Majora-92bf1922-00a .\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Home",
    "section": "",
    "text": "This course will take you through 15 weeks of engaging lectures and hands-on studios, designed to give you practical experience in Spatial Data Analysis .\nUse the sidebar to navigate through the weekly content.\n\n\nPlease refer to the course syllabus for detailed information on course structure, grading, and policies."
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Course Home",
    "section": "",
    "text": "Please refer to the course syllabus for detailed information on course structure, grading, and policies."
  },
  {
    "objectID": "studio/week09/peer2.html",
    "href": "studio/week09/peer2.html",
    "title": "Studio 09 Peer Evaluation 2",
    "section": "",
    "text": "DUE: Wednesday, October 30, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-23 Studio 9: Peer Evaluation 2"
    ]
  },
  {
    "objectID": "studio/week09/peer2.html#instructions",
    "href": "studio/week09/peer2.html#instructions",
    "title": "Studio 09 Peer Evaluation 2",
    "section": "",
    "text": "DUE: Wednesday, October 30, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-23 Studio 9: Peer Evaluation 2"
    ]
  },
  {
    "objectID": "studio/week09/peer2.html#scheduling",
    "href": "studio/week09/peer2.html#scheduling",
    "title": "Studio 09 Peer Evaluation 2",
    "section": "Scheduling",
    "text": "Scheduling\n\nDetermine which team members have an approved computational essay topic.\nSchedule 10 minutes for each of these topics",
    "crumbs": [
      "Home",
      "10-23 Studio 9: Peer Evaluation 2"
    ]
  },
  {
    "objectID": "studio/week09/peer2.html#minute-section",
    "href": "studio/week09/peer2.html#minute-section",
    "title": "Studio 09 Peer Evaluation 2",
    "section": "10 Minute Section",
    "text": "10 Minute Section\n\nTeam leader creates a new section of the notebook with the presenters name\nA student presents their topic (2 minutes)\n\nDiscuss topic idea\nDescribe how the project has incorporated feedback from Peer Evaluation 1\n\nEach remaining member of the team provides feedback and questions to the student (8 minutes)\nTeam leader captures this feedback in the notebook",
    "crumbs": [
      "Home",
      "10-23 Studio 9: Peer Evaluation 2"
    ]
  },
  {
    "objectID": "studio/week09/peer2.html#potential-questions-to-askfeedback-prompts",
    "href": "studio/week09/peer2.html#potential-questions-to-askfeedback-prompts",
    "title": "Studio 09 Peer Evaluation 2",
    "section": "Potential Questions to Ask/Feedback Prompts",
    "text": "Potential Questions to Ask/Feedback Prompts\n\nIs the research question clearly stated?\nDoes the topic clearly involve spatial analysis?\nAre spatial relationships and geographic context central to the question?\nConsiderations for emphasizing or incorporating spatial aspects more effectively.\nAre the data sources identified?\nAre these data sources appropriate for the research question?\nSuggestions for alternative or additional data sources, if needed.\n\nAll team members, whether they are doing a computational essay or not, must participate in the peer evaluation process.",
    "crumbs": [
      "Home",
      "10-23 Studio 9: Peer Evaluation 2"
    ]
  },
  {
    "objectID": "studio/week03/studio.html",
    "href": "studio/week03/studio.html",
    "title": "Studio 03 GeoPandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 18, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week03/studio.html#instructions",
    "href": "studio/week03/studio.html#instructions",
    "title": "Studio 03 GeoPandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 18, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week03/studio.html#input-files",
    "href": "studio/week03/studio.html#input-files",
    "title": "Studio 03 GeoPandas",
    "section": "Input Files",
    "text": "Input Files\nThe files you will read are:\n~/data/385/studio03/schools.geojson\n~/data/385/studio03/streets.geojson\n~/data/385/studio03/catchments.geojson"
  },
  {
    "objectID": "studio/week03/studio.html#reading-the-spatial-data-files",
    "href": "studio/week03/studio.html#reading-the-spatial-data-files",
    "title": "Studio 03 GeoPandas",
    "section": "Reading the spatial data files",
    "text": "Reading the spatial data files\nRead in each of three data files to create three geodataframes: schools, catchments, streets\n\nimport geopandas as gpd\n\n# uncomment the following line and complete the code\n# schools = gpd.read_file(\"???\")"
  },
  {
    "objectID": "studio/week03/studio.html#report-the-number-of-rows-in-each-geodataframe",
    "href": "studio/week03/studio.html#report-the-number-of-rows-in-each-geodataframe",
    "title": "Studio 03 GeoPandas",
    "section": "Report the number of rows in each GeoDataFrame",
    "text": "Report the number of rows in each GeoDataFrame"
  },
  {
    "objectID": "studio/week03/studio.html#determine-the-datatype-of-the-geoseries-for-each-geodataframe",
    "href": "studio/week03/studio.html#determine-the-datatype-of-the-geoseries-for-each-geodataframe",
    "title": "Studio 03 GeoPandas",
    "section": "Determine the datatype of the geoseries for each GeoDataFrame",
    "text": "Determine the datatype of the geoseries for each GeoDataFrame"
  },
  {
    "objectID": "studio/week03/studio.html#determine-the-student-density-in-each-catchment",
    "href": "studio/week03/studio.html#determine-the-student-density-in-each-catchment",
    "title": "Studio 03 GeoPandas",
    "section": "Determine the student density in each catchment",
    "text": "Determine the student density in each catchment\nAssuming that the catchment student populations are 140, 200, 75, create a new variable that is called sdensity that is defined as the ratio of the number of students per unit area of the catchment."
  },
  {
    "objectID": "studio/week03/studio.html#plot-the-sdensity-variable",
    "href": "studio/week03/studio.html#plot-the-sdensity-variable",
    "title": "Studio 03 GeoPandas",
    "section": "Plot the sdensity variable",
    "text": "Plot the sdensity variable"
  },
  {
    "objectID": "studio/week03/studio.html#plotting-multiple-layers",
    "href": "studio/week03/studio.html#plotting-multiple-layers",
    "title": "Studio 03 GeoPandas",
    "section": "Plotting multiple layers",
    "text": "Plotting multiple layers\nRead the guide on Control the order of multiple layers in a plot and plot the three layers together on one plot with the catchments below the streets and schools.\nEnsure that the different geometries are visually distinguishable."
  },
  {
    "objectID": "studio/week05/choro.html#imports",
    "href": "studio/week05/choro.html#imports",
    "title": "Visualization for Area Unit Data",
    "section": "Imports",
    "text": "Imports\n\nimport geopandas\nimport libpysal"
  },
  {
    "objectID": "studio/week05/choro.html#example",
    "href": "studio/week05/choro.html#example",
    "title": "Visualization for Area Unit Data",
    "section": "Example",
    "text": "Example\n\nsouth = libpysal.examples.load_example('South')"
  },
  {
    "objectID": "studio/week05/choro.html#inspecting-the-example",
    "href": "studio/week05/choro.html#inspecting-the-example",
    "title": "Visualization for Area Unit Data",
    "section": "Inspecting the example",
    "text": "Inspecting the example\n\nlibpysal.examples.explain('South')"
  },
  {
    "objectID": "studio/week05/choro.html#reading-the-shapefile",
    "href": "studio/week05/choro.html#reading-the-shapefile",
    "title": "Visualization for Area Unit Data",
    "section": "Reading the shapefile",
    "text": "Reading the shapefile\n\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))"
  },
  {
    "objectID": "studio/week05/choro.html#plotting-the-geometries",
    "href": "studio/week05/choro.html#plotting-the-geometries",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the Geometries",
    "text": "Plotting the Geometries\n\nsouth_gdf.plot()"
  },
  {
    "objectID": "studio/week05/choro.html#plotting-the-attribute-distribution",
    "href": "studio/week05/choro.html#plotting-the-attribute-distribution",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the attribute distribution",
    "text": "Plotting the attribute distribution\n\nimport seaborn"
  },
  {
    "objectID": "studio/week05/choro.html#plotting-the-attribute-distribution-1",
    "href": "studio/week05/choro.html#plotting-the-attribute-distribution-1",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the attribute distribution",
    "text": "Plotting the attribute distribution\n\nseaborn.displot(south_gdf, x='HR60')"
  },
  {
    "objectID": "studio/week05/choro.html#alternative-view-of-the-attribute-distribution",
    "href": "studio/week05/choro.html#alternative-view-of-the-attribute-distribution",
    "title": "Visualization for Area Unit Data",
    "section": "Alternative view of the attribute distribution",
    "text": "Alternative view of the attribute distribution\n\nsouth_gdf.HR60.describe()\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64"
  },
  {
    "objectID": "studio/week05/choro.html#spatial-distribution-default-choropleth",
    "href": "studio/week05/choro.html#spatial-distribution-default-choropleth",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Default Choropleth)",
    "text": "Spatial Distribution (Default Choropleth)\n\nsouth_gdf.plot(column='HR60')"
  },
  {
    "objectID": "studio/week05/choro.html#spatial-distribution-changing-the-classification",
    "href": "studio/week05/choro.html#spatial-distribution-changing-the-classification",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Changing the classification)",
    "text": "Spatial Distribution (Changing the classification)\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles')"
  },
  {
    "objectID": "studio/week05/choro.html#spatial-distribution-adding-a-legend",
    "href": "studio/week05/choro.html#spatial-distribution-adding-a-legend",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Adding a legend)",
    "text": "Spatial Distribution (Adding a legend)\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True)"
  },
  {
    "objectID": "studio/week05/choro.html#mapclassify",
    "href": "studio/week05/choro.html#mapclassify",
    "title": "Visualization for Area Unit Data",
    "section": "Mapclassify",
    "text": "Mapclassify\n\nimport mapclassify"
  },
  {
    "objectID": "studio/week05/choro.html#quantiles",
    "href": "studio/week05/choro.html#quantiles",
    "title": "Visualization for Area Unit Data",
    "section": "Quantiles",
    "text": "Quantiles\n\nmapclassify.Quantiles(south_gdf.HR60)\n\nQuantiles\n\n   Interval      Count\n----------------------\n[ 0.00,  2.50] |   283\n( 2.50,  5.10] |   282\n( 5.10,  7.62] |   282\n( 7.62, 10.98] |   282\n(10.98, 92.94] |   283"
  },
  {
    "objectID": "studio/week05/choro.html#quantiles-changing-the-number-of-classes",
    "href": "studio/week05/choro.html#quantiles-changing-the-number-of-classes",
    "title": "Visualization for Area Unit Data",
    "section": "Quantiles: Changing the number of classes",
    "text": "Quantiles: Changing the number of classes\n\nmapclassify.Quantiles(south_gdf.HR60, k=10)\n\nQuantiles\n\n   Interval      Count\n----------------------\n[ 0.00,  0.00] |   180\n( 0.00,  2.50] |   103\n( 2.50,  3.93] |   141\n( 3.93,  5.10] |   141\n( 5.10,  6.25] |   141\n( 6.25,  7.62] |   141\n( 7.62,  9.19] |   141\n( 9.19, 10.98] |   141\n(10.98, 14.31] |   141\n(14.31, 92.94] |   142"
  },
  {
    "objectID": "studio/week05/choro.html#equal-interval",
    "href": "studio/week05/choro.html#equal-interval",
    "title": "Visualization for Area Unit Data",
    "section": "Equal Interval",
    "text": "Equal Interval\n\nmapclassify.EqualInterval(south_gdf.HR60, k=10)\n\nEqualInterval\n\n   Interval      Count\n----------------------\n[ 0.00,  9.29] |  1000\n( 9.29, 18.59] |   358\n(18.59, 27.88] |    39\n(27.88, 37.17] |     8\n(37.17, 46.47] |     4\n(46.47, 55.76] |     2\n(55.76, 65.06] |     0\n(65.06, 74.35] |     0\n(74.35, 83.64] |     0\n(83.64, 92.94] |     1"
  },
  {
    "objectID": "studio/week05/choro.html#maximum-breaks",
    "href": "studio/week05/choro.html#maximum-breaks",
    "title": "Visualization for Area Unit Data",
    "section": "Maximum Breaks",
    "text": "Maximum Breaks\n\nmapclassify.MaximumBreaks(south_gdf.HR60, k=10)\n\nMaximumBreaks\n\n   Interval      Count\n----------------------\n[ 0.00, 29.42] |  1400\n(29.42, 30.74] |     1\n(30.74, 33.40] |     1\n(33.40, 35.94] |     1\n(35.94, 39.00] |     4\n(39.00, 43.29] |     1\n(43.29, 48.96] |     1\n(48.96, 52.69] |     1\n(52.69, 73.12] |     1\n(73.12, 92.94] |     1"
  },
  {
    "objectID": "studio/week05/choro.html#fisher-jenks",
    "href": "studio/week05/choro.html#fisher-jenks",
    "title": "Visualization for Area Unit Data",
    "section": "Fisher-Jenks",
    "text": "Fisher-Jenks\n\nmapclassify.FisherJenks(south_gdf.HR60, k=10)\n\nFisherJenks\n\n   Interval      Count\n----------------------\n[ 0.00,  1.71] |   216\n( 1.71,  4.45] |   278\n( 4.45,  7.08] |   287\n( 7.08, 10.02] |   288\n(10.02, 13.59] |   176\n(13.59, 19.60] |   121\n(19.60, 28.77] |    34\n(28.77, 40.74] |     8\n(40.74, 53.30] |     3\n(53.30, 92.94] |     1"
  },
  {
    "objectID": "studio/week05/choro.html#boxplot",
    "href": "studio/week05/choro.html#boxplot",
    "title": "Visualization for Area Unit Data",
    "section": "BoxPlot",
    "text": "BoxPlot\n\nmapclassify.BoxPlot(south_gdf.HR60)\n\nBoxPlot\n\n   Interval      Count\n----------------------\n( -inf, -6.90] |     0\n(-6.90,  3.21] |   353\n( 3.21,  6.25] |   353\n( 6.25,  9.96] |   353\n( 9.96, 20.07] |   311\n(20.07, 92.94] |    42"
  },
  {
    "objectID": "studio/week05/choro.html#head-tail",
    "href": "studio/week05/choro.html#head-tail",
    "title": "Visualization for Area Unit Data",
    "section": "Head Tail",
    "text": "Head Tail\n\nmapclassify.HeadTailBreaks(south_gdf.HR60)\n\nHeadTailBreaks\n\n   Interval      Count\n----------------------\n[ 0.00,  7.29] |   802\n( 7.29, 12.41] |   405\n(12.41, 18.18] |   147\n(18.18, 26.87] |    40\n(26.87, 38.73] |    13\n(38.73, 56.98] |     4\n(56.98, 92.94] |     1"
  },
  {
    "objectID": "studio/week05/choro.html#customization",
    "href": "studio/week05/choro.html#customization",
    "title": "Visualization for Area Unit Data",
    "section": "Customization",
    "text": "Customization\n\nLegends\nColor Schemes"
  },
  {
    "objectID": "studio/week05/choro.html#legends",
    "href": "studio/week05/choro.html#legends",
    "title": "Visualization for Area Unit Data",
    "section": "Legends",
    "text": "Legends\n\nsouth_gdf[['STATE_NAME', 'HR60', 'HR90']].head()\n\n\n\n\n\n\n\n\nSTATE_NAME\nHR60\nHR90\n\n\n\n\n0\nWest Virginia\n1.682864\n0.946083\n\n\n1\nWest Virginia\n4.607233\n1.234934\n\n\n2\nWest Virginia\n0.974132\n2.621009\n\n\n3\nWest Virginia\n0.876248\n4.461577\n\n\n4\nDelaware\n4.228385\n6.712736"
  },
  {
    "objectID": "studio/week05/choro.html#create-a-boolean-variable",
    "href": "studio/week05/choro.html#create-a-boolean-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Create a Boolean variable",
    "text": "Create a Boolean variable\n\nsouth_gdf['increased' ] =  south_gdf.HR90 &gt; south_gdf.HR60"
  },
  {
    "objectID": "studio/week05/choro.html#mapping-the-boolean-variable",
    "href": "studio/week05/choro.html#mapping-the-boolean-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Mapping the Boolean variable",
    "text": "Mapping the Boolean variable\n\nsouth_gdf.plot(column='increased', categorical=True, legend=True);"
  },
  {
    "objectID": "studio/week05/choro.html#change-the-values",
    "href": "studio/week05/choro.html#change-the-values",
    "title": "Visualization for Area Unit Data",
    "section": "Change the values",
    "text": "Change the values\n\nv = south_gdf.increased.map({True: 'Increased', False: 'Decreased'})\nsouth_gdf['Increased'] = v"
  },
  {
    "objectID": "studio/week05/choro.html#map-the-new-variable",
    "href": "studio/week05/choro.html#map-the-new-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Map the new variable",
    "text": "Map the new variable\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True);"
  },
  {
    "objectID": "studio/week05/choro.html#legend-positioning",
    "href": "studio/week05/choro.html#legend-positioning",
    "title": "Visualization for Area Unit Data",
    "section": "Legend Positioning",
    "text": "Legend Positioning\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (1.3, 1)});"
  },
  {
    "objectID": "studio/week05/choro.html#legend-title",
    "href": "studio/week05/choro.html#legend-title",
    "title": "Visualization for Area Unit Data",
    "section": "Legend Title",
    "text": "Legend Title\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (1.3, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );"
  },
  {
    "objectID": "studio/week05/choro.html#more-adjustments",
    "href": "studio/week05/choro.html#more-adjustments",
    "title": "Visualization for Area Unit Data",
    "section": "More Adjustments",
    "text": "More Adjustments\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );"
  },
  {
    "objectID": "studio/week05/choro.html#more-adjustments-1",
    "href": "studio/week05/choro.html#more-adjustments-1",
    "title": "Visualization for Area Unit Data",
    "section": "More Adjustments",
    "text": "More Adjustments\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );"
  },
  {
    "objectID": "studio/week05/choro.html#color-schemes",
    "href": "studio/week05/choro.html#color-schemes",
    "title": "Visualization for Area Unit Data",
    "section": "Color schemes",
    "text": "Color schemes\n\nmatplotlib Hunter (2007)\nColorBrewer Harrower and Brewer (2003)"
  },
  {
    "objectID": "studio/week05/choro.html#sequential-color-schemes",
    "href": "studio/week05/choro.html#sequential-color-schemes",
    "title": "Visualization for Area Unit Data",
    "section": "Sequential Color Schemes",
    "text": "Sequential Color Schemes\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='Blues');"
  },
  {
    "objectID": "studio/week05/choro.html#change-the-color-map-single-hue",
    "href": "studio/week05/choro.html#change-the-color-map-single-hue",
    "title": "Visualization for Area Unit Data",
    "section": "Change the color map: Single Hue",
    "text": "Change the color map: Single Hue\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='Greens');"
  },
  {
    "objectID": "studio/week05/choro.html#change-the-color-map-multiple-hues",
    "href": "studio/week05/choro.html#change-the-color-map-multiple-hues",
    "title": "Visualization for Area Unit Data",
    "section": "Change the color map: Multiple Hues",
    "text": "Change the color map: Multiple Hues\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu');"
  },
  {
    "objectID": "studio/week05/choro.html#diverging-color-map",
    "href": "studio/week05/choro.html#diverging-color-map",
    "title": "Visualization for Area Unit Data",
    "section": "Diverging Color Map",
    "text": "Diverging Color Map\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n               cmap='coolwarm',\n           );"
  },
  {
    "objectID": "studio/week05/choro.html#alternative-diverging-color-map",
    "href": "studio/week05/choro.html#alternative-diverging-color-map",
    "title": "Visualization for Area Unit Data",
    "section": "Alternative Diverging Color Map",
    "text": "Alternative Diverging Color Map\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n               cmap='bwr',\n           );"
  },
  {
    "objectID": "studio/week05/choro.html#qualitative-color-scheme",
    "href": "studio/week05/choro.html#qualitative-color-scheme",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True)"
  },
  {
    "objectID": "studio/week05/choro.html#qualitative-color-scheme-1",
    "href": "studio/week05/choro.html#qualitative-color-scheme-1",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True)"
  },
  {
    "objectID": "studio/week05/choro.html#qualitative-color-scheme-2",
    "href": "studio/week05/choro.html#qualitative-color-scheme-2",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1)})"
  },
  {
    "objectID": "studio/week05/choro.html#qualitative-color-scheme-3",
    "href": "studio/week05/choro.html#qualitative-color-scheme-3",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_axes([0, 0, 1, 1])\nax.axis('off')\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1)}, ax=ax);"
  },
  {
    "objectID": "studio/week05/choro.html#comparisons",
    "href": "studio/week05/choro.html#comparisons",
    "title": "Visualization for Area Unit Data",
    "section": "Comparisons",
    "text": "Comparisons\n\nDeciles\nMaximum Breaks\nFisher Jenks"
  },
  {
    "objectID": "studio/week05/choro.html#deciles",
    "href": "studio/week05/choro.html#deciles",
    "title": "Visualization for Area Unit Data",
    "section": "Deciles",
    "text": "Deciles\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);"
  },
  {
    "objectID": "studio/week05/choro.html#maximum-breaks-1",
    "href": "studio/week05/choro.html#maximum-breaks-1",
    "title": "Visualization for Area Unit Data",
    "section": "Maximum Breaks",
    "text": "Maximum Breaks\n\nsouth_gdf.plot(column='HR60', scheme='MaximumBreaks', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);"
  },
  {
    "objectID": "studio/week05/choro.html#fisher-jenks-1",
    "href": "studio/week05/choro.html#fisher-jenks-1",
    "title": "Visualization for Area Unit Data",
    "section": "Fisher Jenks",
    "text": "Fisher Jenks\n\nsouth_gdf.plot(column='HR60', scheme='FisherJenks', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);"
  },
  {
    "objectID": "studio/week05/choro.html#statistical-fit",
    "href": "studio/week05/choro.html#statistical-fit",
    "title": "Visualization for Area Unit Data",
    "section": "Statistical Fit",
    "text": "Statistical Fit\n\ny = south_gdf.HR60\nq10 = mapclassify.Quantiles(y, k=10)\nmb10 = mapclassify.MaximumBreaks(y, k=10)\nfj10 = mapclassify.FisherJenks(y, k=10)\nprint(f'Deciles: {q10.adcm:.1f}, MB: {mb10.adcm:.1f}, FJ: {fj10.adcm:.1f}')\n\nDeciles: 1140.3, MB: 5688.1, FJ: 1027.5"
  },
  {
    "objectID": "studio/week05/choro.html#statistical-fit-1",
    "href": "studio/week05/choro.html#statistical-fit-1",
    "title": "Visualization for Area Unit Data",
    "section": "Statistical Fit",
    "text": "Statistical Fit"
  },
  {
    "objectID": "studio/week05/choro.html#recap-of-key-points",
    "href": "studio/week05/choro.html#recap-of-key-points",
    "title": "Visualization for Area Unit Data",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nAreal Unit Data\nChoropleth Mapping\nClassification Schemes\nMap Customization"
  },
  {
    "objectID": "studio/week05/choro.html#questions",
    "href": "studio/week05/choro.html#questions",
    "title": "Visualization for Area Unit Data",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "studio/week05/choro.html#references",
    "href": "studio/week05/choro.html#references",
    "title": "Visualization for Area Unit Data",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nHarrower, Mark, and Cynthia A. Brewer. 2003. “ColorBrewer.org: An Online Tool for Selecting Colour Schemes for Maps.” The Cartographic Journal 40 (1): 27–37. https://doi.org/10.1179/000870403235002042.\n\n\nHunter, John D. 2007. “Matplotlib: A 2D Graphics Environment.” Computing in Science & Engineering 9 (3): 90–95. https://doi.org/10.1109/MCSE.2007.55."
  },
  {
    "objectID": "studio/week05/studio.html",
    "href": "studio/week05/studio.html",
    "title": "Studio 05 Choropleth Mapping",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 2, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week05/studio.html#instructions",
    "href": "studio/week05/studio.html#instructions",
    "title": "Studio 05 Choropleth Mapping",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 2, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week05/studio.html#data",
    "href": "studio/week05/studio.html#data",
    "title": "Studio 05 Choropleth Mapping",
    "section": "Data",
    "text": "Data\nYou will use the south data set introduced in the previous lecture for this studio."
  },
  {
    "objectID": "studio/week05/studio.html#reading-the-relevant-file-to-create-a-geodataframe",
    "href": "studio/week05/studio.html#reading-the-relevant-file-to-create-a-geodataframe",
    "title": "Studio 05 Choropleth Mapping",
    "section": "Reading the relevant file to create a GeoDataFrame",
    "text": "Reading the relevant file to create a GeoDataFrame\n\nimport libpysal\nimport geopandas\nsouth = libpysal.examples.load_example('South')"
  },
  {
    "objectID": "studio/week05/studio.html#reading-the-shapefile",
    "href": "studio/week05/studio.html#reading-the-shapefile",
    "title": "Studio 05 Choropleth Mapping",
    "section": "Reading the shapefile",
    "text": "Reading the shapefile\n\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))"
  },
  {
    "objectID": "studio/week05/studio.html#explore-the-documentation-of-the-example",
    "href": "studio/week05/studio.html#explore-the-documentation-of-the-example",
    "title": "Studio 05 Choropleth Mapping",
    "section": "Explore the documentation of the example",
    "text": "Explore the documentation of the example\nYou will be mapping and analyzing family income inequality in the South. Determine the name of the relevant variable to use"
  },
  {
    "objectID": "studio/week05/studio.html#develop-a-choropleth-map-for-inequality-in-1960.",
    "href": "studio/week05/studio.html#develop-a-choropleth-map-for-inequality-in-1960.",
    "title": "Studio 05 Choropleth Mapping",
    "section": "Develop a choropleth map for inequality in 1960.",
    "text": "Develop a choropleth map for inequality in 1960.\n\nUse Quintiles\nExplore different color maps\nDevelop and document several versions of the map for 1960\nJustify your final choice\nInterpret the spatial distribution as it is shown in your final map"
  },
  {
    "objectID": "studio/week05/studio.html#develop-diverging-maps-of-changes-in-inequality-from-1960-1990",
    "href": "studio/week05/studio.html#develop-diverging-maps-of-changes-in-inequality-from-1960-1990",
    "title": "Studio 05 Choropleth Mapping",
    "section": "Develop diverging maps of changes in inequality from 1960-1990",
    "text": "Develop diverging maps of changes in inequality from 1960-1990\n\nJustify your color map\nJustify your classification scheme\nInterpret the spatial distribution as it is shown in your final map"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html",
    "href": "studio/week04/studio4_geosnap.html",
    "title": "geosnap and geoprocessing",
    "section": "",
    "text": "geosnap - the geospatial neighborhood analysis package - provides a suite of tools for understanding the composition and extent of [endogenous] neighborhoods and regions in a study area. It provides:\n\nsimple access to commonly-used datasets in urban and regional analyses:\n\ndemographic data (Census/ACS)\nemployment (LEHD)\nenvironment (EPA)\ntravel infrastructure (OSM)\npublic education systems (NCES)\n\nan easy interface to build geodemographic typologies\n\nclassic aspatial typologies\nconstrained homogenous regions\n\nbuilt-in functionality to facilitate spatiotemporal analysis\n\nwithin time-period standardization\nboundary harmonization\ninflation adjustment\n\nbespoke plotting tools to help visualize neighborhood dynamics\n\ntemporally-static choropleth mapping\nanimated mapping\n\nstate-of-the-art techniques for modeling neighborhood change over time\n\nspatial Markov transition models\nsequence analysis\n\n\nToday, we want to focus on getting data from geosnap. This involves two basic steps: instantiate a DataStore class which points to datasets installed on the 385 course server, then querying the new DataStore object using functions from the geosnap io (for input-ouput) module\n\nimport geopandas as gpd\nimport pandas as pd\nimport geosnap\ngeosnap.__version__\n\n'0.14.0'\n\n\n\nfrom geosnap import DataStore\n\nAll of the datasets available in geosnap can be streamed from the cloud or installed on a local machine for analysis. In many cases, streaming works fine, but for repeated use of the same datasets, it is easier to install the data permanently. We have already done that on the course server. To ensure geosnap can access that data, we instantiate a new DataStore object pointing to the location of the data\n\ndatasets = DataStore(\"/srv/data/geosnap\")\n\nThe datasets object can now be used to read and write data from the \"/srv/data/geosnap/\" folder, which is where the course data lives).\nAs a quick shorthand to see the available datasets, you can use the dir function to peek inside the datasets object\n\ndir(datasets)\n\n['acs',\n 'bea_regions',\n 'blocks_2000',\n 'blocks_2010',\n 'blocks_2020',\n 'codebook',\n 'counties',\n 'ejscreen',\n 'lodes_codebook',\n 'ltdb',\n 'msa_definitions',\n 'msas',\n 'ncdb',\n 'nces',\n 'seda',\n 'show_data_dir',\n 'states',\n 'tracts_1990',\n 'tracts_2000',\n 'tracts_2010',\n 'tracts_2020']\n\n\nEach of these is a dataset that can be accessed. For more information on the datasets, see the geosnap datasets page.\nAs one example, we can collect data from the U.S. Census American Community Survey (5-year survey estimates) using the get_acs function in geosnap’s io module.\n\nfrom geosnap import io as gio\n\nFirst we import the io module, aliased as gio, then we query the DataStore (called datasets) for ACS data at the tract level for state 06 (which is California) and year 2016 (which is the 2012-2016 ACS).\n\n\n\nfrom geosnap.io import get_acs\n\nca = get_acs(datasets, state_fips=['06'], level='tract', years=[2016])\n\n/home/serge/miniforge3/envs/workshop-pysal/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_acs()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nThe ca variable now holds a geodataframe of California census data at the tract level. To get a different year or a different geographic level, we could specify different input parameters to the get_acs function\n\nca.head()\n\n\n\n\n\n\n\n\ngeoid\nn_mexican_pop\nn_cuban_pop\nn_puerto_rican_pop\nn_russian_pop\nn_italian_pop\nn_german_pop\nn_irish_pop\nn_scandaniavian_pop\nn_foreign_born_pop\n...\np_poverty_rate\np_poverty_rate_over_65\np_poverty_rate_children\np_poverty_rate_white\np_poverty_rate_black\np_poverty_rate_hispanic\np_poverty_rate_native\np_poverty_rate_asian\ngeometry\nyear\n\n\n\n\n0\n06001400100\n55.0\n0.0\n13.0\n49.0\n62.0\n147.0\n13.0\n8.0\n843.0\n...\n3.752906\n0.531385\n0.631020\n3.055463\n0.000000\n0.000000\n0.0\n0.000000\nMULTIPOLYGON (((-122.24692 37.88544, -122.2466...\n2016\n\n\n1\n06001400200\n118.0\n0.0\n25.0\n17.0\n39.0\n57.0\n26.0\n6.0\n243.0\n...\n5.430328\n1.946721\n0.000000\n4.047131\n0.000000\n0.563525\n0.0\n0.000000\nMULTIPOLYGON (((-122.25792 37.84261, -122.2577...\n2016\n\n\n2\n06001400300\n171.0\n0.0\n0.0\n0.0\n154.0\n81.0\n75.0\n0.0\n857.0\n...\n8.732777\n1.765962\n0.329905\n3.299049\n3.648360\n0.426936\n0.0\n0.000000\nMULTIPOLYGON (((-122.26563 37.83764, -122.2655...\n2016\n\n\n3\n06001400400\n127.0\n9.0\n0.0\n56.0\n55.0\n84.0\n37.0\n0.0\n471.0\n...\n6.445406\n0.721501\n0.000000\n3.799904\n0.673401\n0.553151\n0.0\n0.000000\nMULTIPOLYGON (((-122.26183 37.84162, -122.2618...\n2016\n\n\n4\n06001400500\n282.0\n29.0\n11.0\n10.0\n7.0\n103.0\n51.0\n0.0\n635.0\n...\n9.081168\n0.375033\n0.000000\n4.178945\n3.375301\n3.402089\n0.0\n0.642915\nMULTIPOLYGON (((-122.26951 37.84858, -122.2693...\n2016\n\n\n\n\n5 rows × 158 columns\n\n\n\n\nca.plot()\n\n\n\n\n\n\n\n\nTo trim down the existing dataset, for example to “slice out” the tracts in San Diego county, we use pandas dataframe operations. Here we use the geoid column to select tracts that begin with “06073”, which is the county FIPS code for San Diego\n\nsd = ca[ca.geoid.str.startswith('06073')]\n\n\nsd.plot()\n\n\n\n\n\n\n\n\n\n\n\nThe Environmental Protection Agency (EPA)’s envrironmental justice screening tool (EJSCREEN) is a national dataset that provides a wealth of environmental (and some demographic) data at a blockgroup level. For a full list of indicators and their metadata, see the EPA page, but this dataset includes important variables like air toxics cancer risk,ozone concentration in the air, particulate matter, and proximity to superfund sites.\nThe EJSCREEN data can be queried similarly to the ACS data. For example to get blockgroup-level data for the Seattle metropolitan region in 2019, we would use the following\n\nsea_ejscreen = gio.get_ejscreen(datasets, msa_fips=\"42660\", years=2019).to_crs(4326)\n\n/home/serge/miniforge3/envs/workshop-pysal/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_ejscreen()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nA description of the variables in the EJSCREEN data is available here. A subset of the interesting variables we might examine is provided in the table below\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nDSLPM\nDiesel particulate matter level in air\n\n\nCANCER\nAir toxics cancer risk\n\n\nRESP\nAir toxics respiratory hazard index\n\n\nPTRAF\nTraffic proximity and volume\n\n\nPWDIS\nIndicator for major direct dischargers to water\n\n\nPNPL\nProximity to National Priorities List (NPL) sites\n\n\nPRMP\nProximity to Risk Management Plan (RMP) facilities\n\n\nPTSDF\nProximity to Treatment Storage and Disposal (TSDF) facilities\n\n\nOZONE\nOzone level in air\n\n\nPM25\nPM2.5 level in air\n\n\n\n\nsea_ejscreen.plot()"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#census-data",
    "href": "studio/week04/studio4_geosnap.html#census-data",
    "title": "geosnap and geoprocessing",
    "section": "",
    "text": "from geosnap.io import get_acs\n\nca = get_acs(datasets, state_fips=['06'], level='tract', years=[2016])\n\n/home/serge/miniforge3/envs/workshop-pysal/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_acs()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nThe ca variable now holds a geodataframe of California census data at the tract level. To get a different year or a different geographic level, we could specify different input parameters to the get_acs function\n\nca.head()\n\n\n\n\n\n\n\n\ngeoid\nn_mexican_pop\nn_cuban_pop\nn_puerto_rican_pop\nn_russian_pop\nn_italian_pop\nn_german_pop\nn_irish_pop\nn_scandaniavian_pop\nn_foreign_born_pop\n...\np_poverty_rate\np_poverty_rate_over_65\np_poverty_rate_children\np_poverty_rate_white\np_poverty_rate_black\np_poverty_rate_hispanic\np_poverty_rate_native\np_poverty_rate_asian\ngeometry\nyear\n\n\n\n\n0\n06001400100\n55.0\n0.0\n13.0\n49.0\n62.0\n147.0\n13.0\n8.0\n843.0\n...\n3.752906\n0.531385\n0.631020\n3.055463\n0.000000\n0.000000\n0.0\n0.000000\nMULTIPOLYGON (((-122.24692 37.88544, -122.2466...\n2016\n\n\n1\n06001400200\n118.0\n0.0\n25.0\n17.0\n39.0\n57.0\n26.0\n6.0\n243.0\n...\n5.430328\n1.946721\n0.000000\n4.047131\n0.000000\n0.563525\n0.0\n0.000000\nMULTIPOLYGON (((-122.25792 37.84261, -122.2577...\n2016\n\n\n2\n06001400300\n171.0\n0.0\n0.0\n0.0\n154.0\n81.0\n75.0\n0.0\n857.0\n...\n8.732777\n1.765962\n0.329905\n3.299049\n3.648360\n0.426936\n0.0\n0.000000\nMULTIPOLYGON (((-122.26563 37.83764, -122.2655...\n2016\n\n\n3\n06001400400\n127.0\n9.0\n0.0\n56.0\n55.0\n84.0\n37.0\n0.0\n471.0\n...\n6.445406\n0.721501\n0.000000\n3.799904\n0.673401\n0.553151\n0.0\n0.000000\nMULTIPOLYGON (((-122.26183 37.84162, -122.2618...\n2016\n\n\n4\n06001400500\n282.0\n29.0\n11.0\n10.0\n7.0\n103.0\n51.0\n0.0\n635.0\n...\n9.081168\n0.375033\n0.000000\n4.178945\n3.375301\n3.402089\n0.0\n0.642915\nMULTIPOLYGON (((-122.26951 37.84858, -122.2693...\n2016\n\n\n\n\n5 rows × 158 columns\n\n\n\n\nca.plot()\n\n\n\n\n\n\n\n\nTo trim down the existing dataset, for example to “slice out” the tracts in San Diego county, we use pandas dataframe operations. Here we use the geoid column to select tracts that begin with “06073”, which is the county FIPS code for San Diego\n\nsd = ca[ca.geoid.str.startswith('06073')]\n\n\nsd.plot()"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#epa-environmental-justice-screening-data",
    "href": "studio/week04/studio4_geosnap.html#epa-environmental-justice-screening-data",
    "title": "geosnap and geoprocessing",
    "section": "",
    "text": "The Environmental Protection Agency (EPA)’s envrironmental justice screening tool (EJSCREEN) is a national dataset that provides a wealth of environmental (and some demographic) data at a blockgroup level. For a full list of indicators and their metadata, see the EPA page, but this dataset includes important variables like air toxics cancer risk,ozone concentration in the air, particulate matter, and proximity to superfund sites.\nThe EJSCREEN data can be queried similarly to the ACS data. For example to get blockgroup-level data for the Seattle metropolitan region in 2019, we would use the following\n\nsea_ejscreen = gio.get_ejscreen(datasets, msa_fips=\"42660\", years=2019).to_crs(4326)\n\n/home/serge/miniforge3/envs/workshop-pysal/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_ejscreen()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nA description of the variables in the EJSCREEN data is available here. A subset of the interesting variables we might examine is provided in the table below\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nDSLPM\nDiesel particulate matter level in air\n\n\nCANCER\nAir toxics cancer risk\n\n\nRESP\nAir toxics respiratory hazard index\n\n\nPTRAF\nTraffic proximity and volume\n\n\nPWDIS\nIndicator for major direct dischargers to water\n\n\nPNPL\nProximity to National Priorities List (NPL) sites\n\n\nPRMP\nProximity to Risk Management Plan (RMP) facilities\n\n\nPTSDF\nProximity to Treatment Storage and Disposal (TSDF) facilities\n\n\nOZONE\nOzone level in air\n\n\nPM25\nPM2.5 level in air\n\n\n\n\nsea_ejscreen.plot()"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#geospatial-operations",
    "href": "studio/week04/studio4_geosnap.html#geospatial-operations",
    "title": "geosnap and geoprocessing",
    "section": "Geospatial Operations",
    "text": "Geospatial Operations\nGeopandas can carry out all standard GIS operations using methods implemented on a GeoDataFrame, for example\n\nclip: “cut” the extent of one dataset using the boundaries of another\ndissolve: aggregate geometries using a common value from an attribute (e.g. remove interior boundaries from larger container polygons, e.g. counties within a state)\nsimplify: remove vertices from the input geometries\nbuffer: extend the boundaries of input geometries by a fixed distance (always returns polygons)\ncentroid: compute the geometric center of input geometries (always returns points)\nconvex/concave hull: compute the most efficient convex/convave polygon that contains vertices from all input geometries\n\nBy combining these operations along with spatial predicates, we can create queries based on the topological relationships between two sets of geographic units, which is often critical for creating variables of interest.\nTo demonstrate, we will first collect data from OpenStreetMap (OSM), specifically highways in the Seattle metro. In OSM parlance, this means we’re querying for “highways” with the “motorway” tag (which means “the highest-performance roads within a territory. It should be used only on roads with control of access, or selected roads with limited access depending on the local context and prevailing convention. Those roads are generally referred to as motorways, freeways or expressways in English.”)\n\nimport osmnx as ox\n\n\nhighways = ox.features_from_polygon(\n    sea_ejscreen.union_all(), tags={\"highway\": \"motorway\"}\n)\n\nThis returns a new GeoDataFrame storing each highway as a line feature.\n\nhighways.head()\n\n\n\n\n\n\n\n\n\ngeometry\nhighway\nref\nfixme\npayment:good_to_go\nsource\nname\nlit\nbus:lanes\nhgv\n...\nmotorcycle:lanes:conditional\nsidewalk\nhov:lanes:backward\nhov:lanes:forward\nhazmat\nstart_date\nsidewalk:left\nsidewalk:right\nbridge:movable\nwikidata\n\n\nelement\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nway\n4634293\nLINESTRING (-122.31862 47.64265, -122.3177 47....\nmotorway\nWA 520\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4644156\nLINESTRING (-122.32264 47.65701, -122.3226 47....\nmotorway\nI 5\nNaN\nNaN\nNaN\nShip Canal Bridge\nyes\nNaN\ndesignated\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4644167\nLINESTRING (-122.32242 47.6467, -122.3224 47.6...\nmotorway\nI 5\nNaN\nNaN\nNaN\nShip Canal Bridge\nyes\nNaN\ndesignated\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4644173\nLINESTRING (-122.32265 47.6467, -122.32258 47....\nmotorway\nI 5 Express\nNaN\nNaN\nNaN\nShip Canal Bridge\nyes\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4709507\nLINESTRING (-122.32598 47.73592, -122.32558 47...\nmotorway\nI 5\nNaN\nNaN\nNaN\nNaN\nNaN\ndesignated|||\ndesignated\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 104 columns\n\n\n\n\nhighways.plot()\n\n\n\n\n\n\n\n\nNotice in the call to features_from_polygon above, we used the unary_union operator on the Seattle tracts dataframe. This effectively combines all the tracts into a single polygon so we are querying anything that intersects any tract, rather than querying intersections with each tract individually. We can do the same thing on the highway GeoDataFrame to see the effect\n\n# note in geopandas &lt;1.0 this is `highways.unary_union`\n\nhw_union = highways.union_all()\n\n\nhw_union\n\n\n\n\n\n\n\n\nNow hw_union is a single shapely.Polygon with no attribute information\n\ngpd.GeoDataFrame(geometry=[hw_union], crs=4326).explore(tiles='CartoDB Positron')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#integrating-spatial-datasets",
    "href": "studio/week04/studio4_geosnap.html#integrating-spatial-datasets",
    "title": "geosnap and geoprocessing",
    "section": "Integrating Spatial Datasets",
    "text": "Integrating Spatial Datasets\nLet’s assume the role of a public health epidemiologist who is interested in equity issues surrounding exposure to highways and automobile emissions. We may be interested in who lives near the highway and whether the population nearby experiences a heightened exposure to toxic emissions.\n\nSelect by Location\nOne simple question would be, which tracts have a highway run through them? We can formalize that by asking which tracts intersect the highway system.\n\nhighway_blockgroups = sea_ejscreen[sea_ejscreen.intersects(hw_union)]\nhighway_blockgroups.plot()\n\n\n\n\n\n\n\n\nA more complicated question is, which tracts are within 1.5km of a road? This is ‘complicated’ because it forces us to formalize an ill-defined relationship: the distance between a polygon and the nearest point on a line. What does it mean for the polygon to be ‘within’ 1.5km? Does that mean the whole tract? most of it? any part of it?\nIf we can define a most suitable distance measure, the technical selection is easy to execute using an intermediate geometry.\n\nroad_buffer = highways.to_crs(highways.estimate_utm_crs()).buffer(1500)\n\n\ngpd.GeoDataFrame(geometry=[road_buffer.union_all()], crs=road_buffer.crs).explore(tiles='CartoDB Positron')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nsea_ejscreen.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsea_ejscreen[sea_ejscreen.intersects(road_buffer.union_all())]\n\n\n\n\n\n\n\n\ngeoid\nACSTOTPOP\nACSIPOVBAS\nACSEDUCBAS\nACSTOTHH\nACSTOTHU\nMINORPOP\nMINORPCT\nLOWINCOME\nLOWINCPCT\n...\nT_PM25_P2\nT_PM25_P6\nAREALAND\nAREAWATER\nNPL_CNT\nTSDF_CNT\nShape_Length\nShape_Area\ngeometry\nyear\n\n\n\n\n\n\n0 rows × 368 columns\n\n\n\nThis gives us back nothing… There is no intersection because the EJSCREEN data is still stored in Lat/Long, but we reprojected the road buffer into UTM\n\nsea_ejscreen = sea_ejscreen.to_crs(road_buffer.crs)\n\nBy selecting the tracts that intersect with the interstate buffer, we are codifying the tracts as ‘near the highway’ if any portion of a tract is within 1.5km. This can be an awkard choice when polygons are irregularly shaped or heteogeneously sized (Census tracts are both). This means large tracts get included as ‘near’, even when a small portion of the polygon is within the 1.5km threshold (like the tract on the far Eastern edge).\n\nsea_ejscreen[sea_ejscreen.intersects(road_buffer.union_all())].plot()\n\n\n\n\n\n\n\n\nAlternatively, we might ask, which tracts have their center within 1.5km of a highway? Or more formally, which tracts have their centroids intersect with the 1500m buffer.\n\nsea_ejscreen[sea_ejscreen.centroid.intersects(road_buffer.union_all())].plot()\n\n\n\n\n\n\n\n\nIf we are happy with that definition of proximity, we can use the spatial selection to create and update a new attribute on the dataframe. Here, we will select the tracts whose centroids are within the threshold distance, then create a new column called “highway_buffer”, set to “inside” (using the indices of the spatial selection to define which rows are being set).\n\n# get the dataframe index of the tracts intersecting the buffer\n\ninside_idx = sea_ejscreen[\n    sea_ejscreen.centroid.intersects(road_buffer.union_all())\n].index\n\n\n# set the 'highway_buffer' attribute to 'inside' for the indices within\nsea_ejscreen.loc[inside_idx, \"highway_buffer\"] = \"inside\"\n\n# fill all NaN values in the column with 'outside'\nsea_ejscreen[\"highway_buffer\"] = sea_ejscreen[\"highway_buffer\"].fillna(\"outside\").astype('category')\n\nNow ‘highway_buffer’ is a binary variable defining whether a tract is “near” a highway or not. We could have set these values to one and zero, but setting them as a categorical variable means that the geopandas plot method uses a different kind of coloring scheme that matches the data more appropriately.\n\nsea_ejscreen[['highway_buffer', 'geometry']].explore(\"highway_buffer\", legend=True, tiles='CartoDB Positron')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nThen, we can use this spatial distinction as a grouping variable to look at average values inside versus outside the threshold zone.\n\nsea_ejscreen.groupby(\"highway_buffer\")[[\"PM25\", \"DSLPM\", \"MINORPCT\"]].mean()\n\n/tmp/ipykernel_17288/860608503.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  sea_ejscreen.groupby(\"highway_buffer\")[[\"PM25\", \"DSLPM\", \"MINORPCT\"]].mean()\n\n\n\n\n\n\n\n\n\nPM25\nDSLPM\nMINORPCT\n\n\nhighway_buffer\n\n\n\n\n\n\n\ninside\n6.298818\n1.043487\n0.404843\n\n\noutside\n6.061902\n0.723160\n0.283832\n\n\n\n\n\n\n\nOn average, both PM2.5 and Disel Particulate Matter levels are higher for tracts located within 1.5km of an OSM ‘motorway’ (what we think is probably an interstate highway). The share of residents identifying as a racial or ethnic miority is also 12% higher on average.\n\n\nSpatial Join\nIn the example above, we use only the geometric relationship between observations to make selections from one dataset. In other cases, we need to attach attribute data from one dataset to the other using spatial relationships. For example we might want to count the number of health clinics that fall inside each census tract. This actually entails two operations: attaching census tract identifiers to each clinic, then aggregating by tract identifier and counting all clinics within\nOnce again we will query OSM, this time looking for an amenity with the ‘clinic’ tag\n\nclinics = ox.features_from_polygon(\n    sea_ejscreen.to_crs(4326).union_all(), tags={\"amenity\": \"clinic\"}\n)\nclinics = clinics.reset_index().set_index(\"id\")\n\n\nclinics.head()\n\n\n\n\n\n\n\n\nelement\ngeometry\namenity\nhealthcare\nname\nbrand\nbrand:wikidata\nhealthcare:counselling\noperator\noperator:wikidata\n...\nstart_date\nele\ngnis:feature_id\nref\nbuilding:material\nwaste_disposal\nwikidata\nowner\nlayer\ntype\n\n\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1242268219\nnode\nPOINT (-122.11025 47.67027)\nclinic\nclinic\nOverlake Clinics - Urgent Care\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1248759443\nnode\nPOINT (-122.35027 47.64978)\nclinic\nclinic\nZoomCare\nZoomCare\nQ64120374\nNaN\nZoomCare\nQ64120374\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1273816342\nnode\nPOINT (-122.18631 47.62807)\nclinic\nclinic\nEvergreen Integrative Medicine L.L.P.\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1273816350\nnode\nPOINT (-122.186 47.62807)\nclinic\nclinic\nRomanick MD PLLC\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1381933749\nnode\nPOINT (-122.18496 47.62548)\nclinic\nclinic\nMedical Arts Associates\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 110 columns\n\n\n\nThe clinics dataset now has manuy types of clinics, and also has a mixed geometry type; some clinics are stored as polygons (where the building footprint has been digitized) whereas others are simply stored as points. Lets filter the dataset to include only those defined as clinic (e.g. not counseling) and only points (not polygons)\nWe can do this in two steps like\n\nclinics = clinics[(clinics.healthcare == \"clinic\") & (clinics.element == \"node\")]\n\n\nclinics.explore(tiles='CartoDB Positron', tooltip=['name', 'healthcare'])\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nclinics = clinics.to_crs(sea_ejscreen.crs)\n\n\nclinics_geoid = clinics.sjoin(sea_ejscreen[[\"geoid\", \"geometry\"]])\n\n\nclinics_geoid.head()\n\n\n\n\n\n\n\n\nelement\ngeometry\namenity\nhealthcare\nname\nbrand\nbrand:wikidata\nhealthcare:counselling\noperator\noperator:wikidata\n...\ngnis:feature_id\nref\nbuilding:material\nwaste_disposal\nwikidata\nowner\nlayer\ntype\nindex_right\ngeoid\n\n\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1242268219\nnode\nPOINT (566792.704 5280036.188)\nclinic\nclinic\nOverlake Clinics - Urgent Care\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1326\n530330323092\n\n\n1248759443\nnode\nPOINT (548794.035 5277580.42)\nclinic\nclinic\nZoomCare\nZoomCare\nQ64120374\nNaN\nZoomCare\nQ64120374\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n172\n530330049002\n\n\n1273816342\nnode\nPOINT (561132.643 5275283.673)\nclinic\nclinic\nEvergreen Integrative Medicine L.L.P.\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n699\n530330237003\n\n\n1273816350\nnode\nPOINT (561155.932 5275284.017)\nclinic\nclinic\nRomanick MD PLLC\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n699\n530330237003\n\n\n1381933749\nnode\nPOINT (561236.936 5274997.501)\nclinic\nclinic\nMedical Arts Associates\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n699\n530330237003\n\n\n\n\n5 rows × 112 columns\n\n\n\nNow we want to count clinics in each geoid. Since we know osmid uniquely identifies each clinic, we can reset the index, then groupby the ‘geoid’ variable, counting the unique ’osmid’s in each one\n\nclinic_count = clinics_geoid.reset_index().groupby(\"geoid\").count()[\"id\"]\n\n\nclinic_count\n\ngeoid\n530330001003    1\n530330002002    1\n530330006004    2\n530330012004    1\n530330013003    1\n               ..\n530610519252    1\n530610527072    1\n530610535093    1\n530610538023    1\n530610538024    1\nName: id, Length: 177, dtype: int64\n\n\nclinic_count is now a pandas series where the index refers to the census tract of interest and the value corresponds to the number of clinics that fall inside.\n\nsea_ejscreen = sea_ejscreen.merge(\n    clinic_count.rename(\"clinic_count\"), left_on=\"geoid\", right_index=True, how=\"left\"\n)\n\n\nsea_ejscreen.clinic_count\n\n0       NaN\n1       NaN\n2       1.0\n3       NaN\n4       NaN\n       ... \n2478    NaN\n2479    NaN\n2480    NaN\n2481    NaN\n2482    NaN\nName: clinic_count, Length: 2483, dtype: float64\n\n\nNow the sea_ejscreen GeoDataFrame has a new column called ‘clinic_count’ that holds the number of clinics inside. Since we know that NaN (Not a number) refers to zero in this case, we can go ahead and fill the missing data.\n\nsea_ejscreen[\"clinic_count\"] = sea_ejscreen[\"clinic_count\"].fillna(0)\n\n\nsea_ejscreen[['clinic_count', 'geometry']].explore(\n    \"clinic_count\", scheme='fisher_jenks', cmap='Reds', tiles='CartoDB DarkMatter', style_kwds=dict(weight=0.2)\n)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "studio/python_course.html",
    "href": "studio/python_course.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "studio/python_course.html#instructions",
    "href": "studio/python_course.html#instructions",
    "title": "",
    "section": "Instructions",
    "text": "Instructions\n\nGo to http://www.codeacademy.com and create a free account, or sign in with a social media or GitHub account.\nTake the self-paced entry-level minicourse on Python 2.3\nThe minicourse has 12 units, each with 1-2 lessons to be done in a browser. Complete the first 9 units of the course, up to and including “Exam Statistics.”\n\n\n\n\n\n\n\nTime Requirements\n\n\n\nCompleting this primer should take between 6-8 hours. You should spread out your effort in 30-minute chunks over a few weeks."
  },
  {
    "objectID": "studio/python_course.html#submission-due-september-23-330-pm",
    "href": "studio/python_course.html#submission-due-september-23-330-pm",
    "title": "",
    "section": "Submission (Due: September 23, 3:30 PM)",
    "text": "Submission (Due: September 23, 3:30 PM)\nWhen you have completed the nine units, take a screenshot that shows your name on the screen as well as all the checks. Upload the screenshot to Canvas."
  },
  {
    "objectID": "studio/python_course.html#footnotes",
    "href": "studio/python_course.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe Python Primer is inspired by and modeled after the work of Robert Talbert.↩︎\nIf you are interested in further exploring Python for geography, an excellent course is Geog 383.↩︎\nDo not sign up for the Python 3 course as it is not free. We will cover the main differences between Python 2 and Python 3 in the studio sessions.↩︎"
  },
  {
    "objectID": "studio/week02/index.html",
    "href": "studio/week02/index.html",
    "title": "Week 2 Studio: Pandas",
    "section": "",
    "text": "This week we introduce Pandas:\n\nIntroduction to Pandas\nStudio exercise",
    "crumbs": [
      "Home",
      "09-04 Studio 2: Pandas"
    ]
  },
  {
    "objectID": "studio/week02/pandas.html",
    "href": "studio/week02/pandas.html",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "In this notebook we introduce pandas (McKinney 2010) which is the main package for working with data in Python."
  },
  {
    "objectID": "studio/week02/pandas.html#introduction",
    "href": "studio/week02/pandas.html#introduction",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "In this notebook we introduce pandas (McKinney 2010) which is the main package for working with data in Python."
  },
  {
    "objectID": "studio/week02/pandas.html#import",
    "href": "studio/week02/pandas.html#import",
    "title": "Introduction to Pandas",
    "section": "Import",
    "text": "Import\nWe start by importing the package, and aliasing it as pd\n\nimport pandas as pd\n\nAliasing allows us to use pd in place of having to type out pandas in what follows."
  },
  {
    "objectID": "studio/week02/pandas.html#dataframe-creation",
    "href": "studio/week02/pandas.html#dataframe-creation",
    "title": "Introduction to Pandas",
    "section": "DataFrame Creation",
    "text": "DataFrame Creation\nPandas main data structure is called a DataFrame. We will create our first DataFrame by reading a csv file.\n\n1home = \"/home/serge\"\ncities_df = pd.read_csv(f\"{home}/data/385/studio02/cities.csv\")\n\n\n1\n\nChange the value home to be equal to jupyter-student where student is your id.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe sure to reread the instructions to change the path in the previous cell if you wish to follow along in your own notebook.\n\n\nAsking for the values of the cities_df give us:\n\ncities_df\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\n\n\n\n\n\n\n\nThis data set is composed of the capital cities for the 50 states.\nWe can see what type of object cities_df is using type:\n\ntype(cities_df)\n\npandas.core.frame.DataFrame\n\n\nAs an analogy, you can think of a DataFrame as a spreadsheet with rows and columns. This mental model will help to orient you. We will see that the DataFrame extends spreadsheets in powerful ways for data analysis.\nA DataFrame, like most Python objects, has a number of attributes and methods.\nIts shape attribute tells us how many observations and variables we have.\n\ncities_df.shape\n\n(50, 4)\n\n\nIn this case our data set has 50 observations on 4 variables."
  },
  {
    "objectID": "studio/week02/pandas.html#series",
    "href": "studio/week02/pandas.html#series",
    "title": "Introduction to Pandas",
    "section": "Series",
    "text": "Series\nEach variable is stored as a Series:\n\ntype(cities_df.longitude)\n\npandas.core.series.Series\n\n\n\ncities_df.longitude\n\n0     -86.300568\n1    -134.420212\n2    -112.096962\n3     -92.288986\n4    -121.493629\n5    -104.984856\n6     -72.682198\n7     -75.519722\n8    -157.857376\n9     -84.281296\n10    -84.388229\n11   -116.199722\n12    -89.654961\n13    -86.162643\n14    -93.603729\n15    -95.677956\n16    -84.875374\n17    -91.187393\n18    -69.781693\n19    -76.490936\n20    -71.063698\n21    -84.555328\n22    -93.102211\n23    -90.182106\n24    -92.172935\n25   -112.018417\n26    -96.699654\n27   -119.766121\n28    -71.537994\n29    -74.769913\n30   -105.939728\n31    -78.639099\n32   -100.783318\n33    -73.757874\n34    -82.999069\n35    -97.503342\n36   -123.030403\n37    -76.883598\n38    -71.414963\n39    -81.033211\n40   -100.346405\n41    -86.784241\n42    -97.740349\n43   -111.888237\n44    -72.580536\n45    -77.433640\n46   -122.905014\n47    -81.612328\n48    -89.384445\n49   -104.820236\nName: longitude, dtype: float64\n\n\nWhen we ask for the contents of the series, we see two columns of numbers. The first is a set of integers which is the index. Each value in the index locates the particular observation in the series.\nThe next column of values stores the values of the series. Here the values are decimal degrees of longitude for the capital cities."
  },
  {
    "objectID": "studio/week02/pandas.html#data-types",
    "href": "studio/week02/pandas.html#data-types",
    "title": "Introduction to Pandas",
    "section": "Data Types",
    "text": "Data Types\nThe info method of the DataFrame will summarize information about our DataFrame\n\ncities_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50 entries, 0 to 49\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   name         50 non-null     object \n 1   description  50 non-null     object \n 2   latitude     50 non-null     float64\n 3   longitude    50 non-null     float64\ndtypes: float64(2), object(2)\nmemory usage: 1.7+ KB\n\n\nWe have four columns, the first two of which are of type object and the last two are of type float64.\nThe names of our variables in the DataFrame are stored in the columns attribute:\n\ncities_df.columns\n\nIndex(['name', 'description', 'latitude', 'longitude'], dtype='object')\n\n\nWe can use the column name to access the particular series:\n\ncities_df.longitude\n\n0     -86.300568\n1    -134.420212\n2    -112.096962\n3     -92.288986\n4    -121.493629\n5    -104.984856\n6     -72.682198\n7     -75.519722\n8    -157.857376\n9     -84.281296\n10    -84.388229\n11   -116.199722\n12    -89.654961\n13    -86.162643\n14    -93.603729\n15    -95.677956\n16    -84.875374\n17    -91.187393\n18    -69.781693\n19    -76.490936\n20    -71.063698\n21    -84.555328\n22    -93.102211\n23    -90.182106\n24    -92.172935\n25   -112.018417\n26    -96.699654\n27   -119.766121\n28    -71.537994\n29    -74.769913\n30   -105.939728\n31    -78.639099\n32   -100.783318\n33    -73.757874\n34    -82.999069\n35    -97.503342\n36   -123.030403\n37    -76.883598\n38    -71.414963\n39    -81.033211\n40   -100.346405\n41    -86.784241\n42    -97.740349\n43   -111.888237\n44    -72.580536\n45    -77.433640\n46   -122.905014\n47    -81.612328\n48    -89.384445\n49   -104.820236\nName: longitude, dtype: float64\n\n\n\ncities_df.name\n\n0            Alabama\n1             Alaska\n2            Arizona\n3           Arkansas\n4         California\n5           Colorado\n6        Connecticut\n7           Delaware\n8             Hawaii\n9            Florida\n10           Georgia\n11             Idaho\n12          Illinois\n13           Indiana\n14              Iowa\n15            Kansas\n16          Kentucky\n17         Louisiana\n18             Maine\n19          Maryland\n20     Massachusetts\n21          Michigan\n22         Minnesota\n23       Mississippi\n24          Missouri\n25           Montana\n26          Nebraska\n27            Nevada\n28     New Hampshire\n29        New Jersey\n30        New Mexico\n31    North Carolina\n32      North Dakota\n33          New York\n34              Ohio\n35          Oklahoma\n36            Oregon\n37      Pennsylvania\n38      Rhode Island\n39    South Carolina\n40      South Dakota\n41         Tennessee\n42             Texas\n43              Utah\n44           Vermont\n45          Virginia\n46        Washington\n47     West Virginia\n48         Wisconsin\n49           Wyoming\nName: name, dtype: object\n\n\nAs each series is an object, it too comes with attributes and methods:\n\ncities_df.longitude.max()\n\nnp.float64(-69.781693)\n\n\n\ncities_df.name.max()\n\n'Wyoming'\n\n\n\ncities_df.longitude.mean()\n\nnp.float64(-93.46593707999999)\n\n\n\ncities_df.name.min()\n\n'Alabama'\n\n\n\ncities_df.longitude.describe()\n\ncount     50.000000\nmean     -93.465937\nstd       18.669710\nmin     -157.857376\n25%     -103.811006\n50%      -89.918533\n75%      -79.237627\nmax      -69.781693\nName: longitude, dtype: float64\n\n\n\ncities_df.name.describe()\n\ncount          50\nunique         50\ntop       Alabama\nfreq            1\nName: name, dtype: object\n\n\nNote how the same method behaves for series of different types."
  },
  {
    "objectID": "studio/week02/pandas.html#creating-new-series",
    "href": "studio/week02/pandas.html#creating-new-series",
    "title": "Introduction to Pandas",
    "section": "Creating new series",
    "text": "Creating new series\nA common workflow in data analysis is to create, or derive, new variables based upon existing variables. For example, let’s define a variable that will denote whether a capital city is in the east or west of the country. Here we will use the median longitude as the comparison point:\n\ncities_df.longitude.median()\n\nnp.float64(-89.9185335)\n\n\n\ncities_df.longitude &lt; cities_df.longitude.median()\n\n0     False\n1      True\n2      True\n3      True\n4      True\n5      True\n6     False\n7     False\n8      True\n9     False\n10    False\n11     True\n12    False\n13    False\n14     True\n15     True\n16    False\n17     True\n18    False\n19    False\n20    False\n21    False\n22     True\n23     True\n24     True\n25     True\n26     True\n27     True\n28    False\n29    False\n30     True\n31    False\n32     True\n33    False\n34    False\n35     True\n36     True\n37    False\n38    False\n39    False\n40     True\n41    False\n42     True\n43     True\n44    False\n45    False\n46     True\n47    False\n48    False\n49     True\nName: longitude, dtype: bool\n\n\nThis creates a series that has data type bool, meaning True if the city is at a longitude less than that of the median longitude. False if it is east of that value. We can use this information to create a new series on the DataFrame called east:\n\ncities_df['east'] = cities_df.longitude &gt; cities_df.longitude.median()\n\nAnd, we can do this for a second variable south:\n\ncities_df['south'] = cities_df.latitude &lt; cities_df.latitude.median()\n\nBased on those two Boolean variables we can create an additional variable called region that tells us which of four regions the capital city is located in.\n\ncities_df['region'] = 4 * cities_df.east * cities_df.south + 3 * (1 - cities_df.east) * cities_df.south \\\n                      + 2 * (1-cities_df.east) * (1-cities_df.south) + cities_df.east * (1-cities_df.south)\n\nregion takes on four values, 1 if the city is in the North East, 2 North West, 3 South West, and 4 South East.\n\ncities_df.head(20)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\n4\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\n2\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\n3\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\n3\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\n3\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\n3\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\n1\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\n4\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\n3\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\n4\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\n4\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\n2\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\n1\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\n4\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\n2\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\n3\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\n4\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\n3\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\n1\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\n4"
  },
  {
    "objectID": "studio/week02/pandas.html#plotting",
    "href": "studio/week02/pandas.html#plotting",
    "title": "Introduction to Pandas",
    "section": "Plotting",
    "text": "Plotting\nPandas comes with built-in plotting facilities. We can try out the default plot method:\n\ncities_df.plot('longitude', 'latitude')\n\n\n\n\n\n\n\n\nThis isn’t quite what we want as the default is to plot the first series and the second series together with line segments connecting each pair of sequential observations.\nBut we can try a different method to get what we want:\n\ncities_df.plot.scatter('longitude', 'latitude')\n\n\n\n\n\n\n\n\nThat’s better as now we see the cities represented as points.\n\n\n\n\n\n\nWarning\n\n\n\nWe are treating longitude and latitude as Cartesian coordinates in the plots. This is technically not correct as they are spherical coordinates. We will correct this later on in the course when we get to spatial data analysis proper.\n\n\nThere are a number of powerful visualization packages in Python that allow us to go beyond what is available in Pandas. To see one of them here, we import seaborn\n\nimport seaborn as sbn\n\nand redo our plot:\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude');\n\n\n\n\n\n\n\n\nSo far, not much difference from what we did with pandas. But we can specify a hue variable to distinguish what region the cities are in:\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude', hue='region');\n\n\n\n\n\n\n\n\nGreat. But the numbers on the legend are not that informative. Let’s change them:\n\ncities_df.region.map({1:'NE', 2:'NW', 3:'SW', 4:'SE'})\n\n0     SE\n1     NW\n2     SW\n3     SW\n4     SW\n5     SW\n6     NE\n7     SE\n8     SW\n9     SE\n10    SE\n11    NW\n12    NE\n13    SE\n14    NW\n15    SW\n16    SE\n17    SW\n18    NE\n19    SE\n20    NE\n21    NE\n22    NW\n23    SW\n24    SW\n25    NW\n26    NW\n27    SW\n28    NE\n29    NE\n30    SW\n31    SE\n32    NW\n33    NE\n34    NE\n35    SW\n36    NW\n37    NE\n38    NE\n39    SE\n40    NW\n41    SE\n42    SW\n43    NW\n44    NE\n45    SE\n46    NW\n47    SE\n48    NE\n49    NW\nName: region, dtype: object\n\n\n\ncities_df['region'] = cities_df.region.map({1:'NE', 2:'NW', 3:'SW', 4:'SE'})\n\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude', hue='region');\n\n\n\n\n\n\n\n\nMuch better.\n\ncities_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW"
  },
  {
    "objectID": "studio/week02/pandas.html#dataframe-operations",
    "href": "studio/week02/pandas.html#dataframe-operations",
    "title": "Introduction to Pandas",
    "section": "DataFrame Operations",
    "text": "DataFrame Operations\nPandas has a number of powerful methods that allow us to manipulate the DataFrame in interesting ways. Here we look at three:\n\nsorting\ngrouping\nfiltering\n\n\nSorting\nWe can sort the DataFrame by the values of a given column. For example, to find the southern-most capital city:\n\ncities_df.sort_values(by='latitude')\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n\n\n\n\n\nTo find the northern-most city:\n\ncities_df.sort_values(by='latitude', ascending=False)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n\n\n\n\n\n\n\nIf we don’t want to see all the other columns, we can subset the dataframe first:\n\ncities_df[['name', 'description', 'latitude']].sort_values(by='latitude', ascending=False)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n\n\n46\nWashington\nOlympia\n47.035805\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n\n\n25\nMontana\nHelena\n46.585709\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n\n\n36\nOregon\nSalem\n44.938461\n\n\n40\nSouth Dakota\nPierre\n44.367031\n\n\n18\nMaine\nAugusta\n44.307167\n\n\n44\nVermont\nMontpelier\n44.262436\n\n\n11\nIdaho\nBoise\n43.617775\n\n\n28\nNew Hampshire\nConcord\n43.206898\n\n\n48\nWisconsin\nMadison\n43.074684\n\n\n21\nMichigan\nLansing\n42.733635\n\n\n33\nNew York\nAlbany\n42.652843\n\n\n20\nMassachusetts\nBoston\n42.358162\n\n\n38\nRhode Island\nProvidence\n41.830914\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n\n\n14\nIowa\nDes Moines\n41.591087\n\n\n49\nWyoming\nCheyenne\n41.140259\n\n\n26\nNebraska\nLincoln\n40.808075\n\n\n43\nUtah\nSalt Lake City\n40.777477\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n\n\n29\nNew Jersey\nTrenton\n40.220596\n\n\n34\nOhio\nColumbus\n39.961346\n\n\n12\nIllinois\nSpringfield\n39.798363\n\n\n13\nIndiana\nIndianapolis\n39.768623\n\n\n5\nColorado\nDenver\n39.739227\n\n\n27\nNevada\nCarson City\n39.163914\n\n\n7\nDelaware\nDover\n39.157307\n\n\n15\nKansas\nTopeka\n39.048191\n\n\n19\nMaryland\nAnnapolis\n38.978764\n\n\n24\nMissouri\nJefferson City\n38.579201\n\n\n4\nCalifornia\nSacramento\n38.576668\n\n\n47\nWest Virginia\nCharleston\n38.336246\n\n\n16\nKentucky\nFrankfort\n38.186722\n\n\n45\nVirginia\nRichmond\n37.538857\n\n\n41\nTennessee\nNashville\n36.165810\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n\n\n3\nArkansas\nLittle Rock\n34.746613\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n\n\n2\nArizona\nPhoenix\n33.448143\n\n\n0\nAlabama\nMontgomery\n32.377716\n\n\n23\nMississippi\nJackson\n32.303848\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n\n\n9\nFlorida\nTallahassee\n30.438118\n\n\n42\nTexas\nAustin\n30.274670\n\n\n8\nHawaii\nHonolulu\n21.307442\n\n\n\n\n\n\n\n\n\nGrouping\nThe groupby method of the DataFrame allows us to split the dataframe, apply a function, and combine the results. This allows us to group data in interesting ways.\nSuppose we wanted to know how many cities were in the east and west?\n\ncities_df.groupby(by='east').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\nsouth\nregion\n\n\neast\n\n\n\n\n\n\n\n\n\n\nFalse\n25\n25\n25\n25\n25\n25\n\n\nTrue\n25\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\nAnd for south and north:\n\ncities_df.groupby(by='south').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nregion\n\n\nsouth\n\n\n\n\n\n\n\n\n\n\nFalse\n25\n25\n25\n25\n25\n25\n\n\nTrue\n25\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\nHow about by region?\n\ncities_df.groupby(by='region').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\n\n\nregion\n\n\n\n\n\n\n\n\n\n\nNE\n13\n13\n13\n13\n13\n13\n\n\nNW\n12\n12\n12\n12\n12\n12\n\n\nSE\n12\n12\n12\n12\n12\n12\n\n\nSW\n13\n13\n13\n13\n13\n13\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs we will see later in the course, there are different notions of a spatial median. This will unravel the mystery of why we have equal numbers of cities in the north and south, and east and west, but not in the four regions.\n\n\nIn addition to applying the count method on the groubby object, we could use other functions. For example, we may want to know the median coordinate values in each of the four regions:\n\ncities_df[['region', 'longitude', 'latitude']].groupby(by='region').median()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\n\n\nregion\n\n\n\n\n\n\nNE\n-73.757874\n42.358162\n\n\nNW\n-108.354236\n44.652746\n\n\nSE\n-82.946812\n36.852334\n\n\nSW\n-97.740349\n35.492207\n\n\n\n\n\n\n\n\n\nFiltering\nFiltering allows us to subset the DataFrame based on some conditions. For example, what if we wanted to create a new DataFrame that only contained the southern capital cities:\n\nsouth_df = cities_df[cities_df.south]\n\n\nsouth_df.shape\n\n(25, 7)\n\n\n\nsouth_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n\n\n\n\n\nAnd to get a DataFrame for the northern cities, we could use a complement filter:\n\nnorth_df = cities_df[~cities_df.south]\n\nThe ~ operator can be thought of flipping the boolean condition.\n\nnorth_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n\n\n\n\n\nWe could combine these to get the DataFrame for cities in the North East region:\n\nne_df = cities_df[~cities_df.south & cities_df.east]\n\n\nne_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n\n\n\n\n\nLike most things we will want to do, there are typically multiple ways to accomplish this in Python. Here we can get a set of regional DataFrames in one shot:\n\ndfs = {r:data for r, data in cities_df.groupby('region')}\n\n\ndfs\n\n{'NE':              name   description   latitude  longitude  east  south region\n 6     Connecticut  Hartford&lt;br&gt;  41.764046 -72.682198  True  False     NE\n 12       Illinois   Springfield  39.798363 -89.654961  True  False     NE\n 18          Maine       Augusta  44.307167 -69.781693  True  False     NE\n 20  Massachusetts        Boston  42.358162 -71.063698  True  False     NE\n 21       Michigan       Lansing  42.733635 -84.555328  True  False     NE\n 28  New Hampshire       Concord  43.206898 -71.537994  True  False     NE\n 29     New Jersey       Trenton  40.220596 -74.769913  True  False     NE\n 33       New York        Albany  42.652843 -73.757874  True  False     NE\n 34           Ohio      Columbus  39.961346 -82.999069  True  False     NE\n 37   Pennsylvania    Harrisburg  40.264378 -76.883598  True  False     NE\n 38   Rhode Island    Providence  41.830914 -71.414963  True  False     NE\n 44        Vermont    Montpelier  44.262436 -72.580536  True  False     NE\n 48      Wisconsin       Madison  43.074684 -89.384445  True  False     NE,\n 'NW':             name     description   latitude   longitude   east  south region\n 1         Alaska          Juneau  58.301598 -134.420212  False  False     NW\n 11         Idaho           Boise  43.617775 -116.199722  False  False     NW\n 14          Iowa      Des Moines  41.591087  -93.603729  False  False     NW\n 22     Minnesota        St. Paul  44.955097  -93.102211  False  False     NW\n 25       Montana          Helena  46.585709 -112.018417  False  False     NW\n 26      Nebraska         Lincoln  40.808075  -96.699654  False  False     NW\n 32  North Dakota        Bismarck  46.820850 -100.783318  False  False     NW\n 36        Oregon           Salem  44.938461 -123.030403  False  False     NW\n 40  South Dakota          Pierre  44.367031 -100.346405  False  False     NW\n 43          Utah  Salt Lake City  40.777477 -111.888237  False  False     NW\n 46    Washington         Olympia  47.035805 -122.905014  False  False     NW\n 49       Wyoming        Cheyenne  41.140259 -104.820236  False  False     NW,\n 'SE':               name   description   latitude  longitude  east  south region\n 0          Alabama    Montgomery  32.377716 -86.300568  True   True     SE\n 7         Delaware         Dover  39.157307 -75.519722  True   True     SE\n 9          Florida   Tallahassee  30.438118 -84.281296  True   True     SE\n 10         Georgia   Atlanta&lt;br&gt;  33.749027 -84.388229  True   True     SE\n 13         Indiana  Indianapolis  39.768623 -86.162643  True   True     SE\n 16        Kentucky     Frankfort  38.186722 -84.875374  True   True     SE\n 19        Maryland     Annapolis  38.978764 -76.490936  True   True     SE\n 31  North Carolina       Raleigh  35.780430 -78.639099  True   True     SE\n 39  South Carolina      Columbia  34.000343 -81.033211  True   True     SE\n 41       Tennessee     Nashville  36.165810 -86.784241  True   True     SE\n 45        Virginia      Richmond  37.538857 -77.433640  True   True     SE\n 47   West Virginia    Charleston  38.336246 -81.612328  True   True     SE,\n 'SW':            name     description   latitude   longitude   east  south region\n 2       Arizona         Phoenix  33.448143 -112.096962  False   True     SW\n 3      Arkansas     Little Rock  34.746613  -92.288986  False   True     SW\n 4    California      Sacramento  38.576668 -121.493629  False   True     SW\n 5      Colorado          Denver  39.739227 -104.984856  False   True     SW\n 8        Hawaii        Honolulu  21.307442 -157.857376  False   True     SW\n 15       Kansas          Topeka  39.048191  -95.677956  False   True     SW\n 17    Louisiana     Baton Rouge  30.457069  -91.187393  False   True     SW\n 23  Mississippi         Jackson  32.303848  -90.182106  False   True     SW\n 24     Missouri  Jefferson City  38.579201  -92.172935  False   True     SW\n 27       Nevada     Carson City  39.163914 -119.766121  False   True     SW\n 30   New Mexico        Santa Fe  35.682240 -105.939728  False   True     SW\n 35     Oklahoma   Oklahoma City  35.492207  -97.503342  False   True     SW\n 42        Texas          Austin  30.274670  -97.740349  False   True     SW}\n\n\nThey are stored in a dictionary, so we could access each one using the region ‘key’.\n\ndfs['NE'].head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE"
  },
  {
    "objectID": "studio/week02/pandas.html#merge",
    "href": "studio/week02/pandas.html#merge",
    "title": "Introduction to Pandas",
    "section": "Merge",
    "text": "Merge\nA common workflow in spatial analysis is combining different data sets. Often we will have information on the locations or geographical coordinates in one data set, but that data set may not include any substantive attribute information. We may have a second data set that has the attribute information we are interested in, but this second data set lacks geographical coordinates. So we will have cause to merge the two data sets\n\npopulation_df = pd.read_csv(f\"{home}/data/385/studio02/captial_population.csv\")\n\n\npopulation_df.head()\n\n\n\n\n\n\n\n\nState\nCapital\nSince\nArea\nCityPop\nMSAPop\nCSAPop\nrank_in_state\narea\n\n\n\n\n0\nAlabama\nMontgomery\n1846\n159.8 sq mi (414 km2)\n200603\n386047\n476207.0\n3\n159.8\n\n\n1\nAlaska\nJuneau\n1906\n2,716.7 sq mi (7,036 km2)\n32255\n32255\nNaN\n3\n2716.7\n\n\n2\nArizona\nPhoenix\n1889\n517.6 sq mi (1,341 km2)\n1608139\n4845832\n4899104.0\n1\n517.6\n\n\n3\nArkansas\nLittle Rock\n1821\n116.2 sq mi (301 km2)\n202591\n748031\n912604.0\n1\n116.2\n\n\n4\nCalifornia\nSacramento\n1854\n97.9 sq mi (254 km2)\n524943\n2397382\n2680831.0\n6\n97.9\n\n\n\n\n\n\n\n\nmerged = pd.merge(cities_df, population_df, left_on='name', right_on='State')\n\n\nmerged.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nState\nCapital\nSince\nArea\nCityPop\nMSAPop\nCSAPop\nrank_in_state\narea\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\nAlabama\nMontgomery\n1846\n159.8 sq mi (414 km2)\n200603\n386047\n476207.0\n3\n159.8\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\nAlaska\nJuneau\n1906\n2,716.7 sq mi (7,036 km2)\n32255\n32255\nNaN\n3\n2716.7\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\nArizona\nPhoenix\n1889\n517.6 sq mi (1,341 km2)\n1608139\n4845832\n4899104.0\n1\n517.6\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\nArkansas\nLittle Rock\n1821\n116.2 sq mi (301 km2)\n202591\n748031\n912604.0\n1\n116.2\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\nCalifornia\nSacramento\n1854\n97.9 sq mi (254 km2)\n524943\n2397382\n2680831.0\n6\n97.9\n\n\n\n\n\n\n\n\nmerged.shape\n\n(50, 16)\n\n\n\nmerged = pd.merge(cities_df, population_df[['CityPop', 'rank_in_state', 'area', 'State']], left_on='name', right_on='State')\n\n\nmerged.shape\n\n(50, 11)"
  },
  {
    "objectID": "studio/week02/pandas.html#saving-files",
    "href": "studio/week02/pandas.html#saving-files",
    "title": "Introduction to Pandas",
    "section": "Saving Files",
    "text": "Saving Files\nIn addition to reading data files, as we did at the beginning of this session, pandas can also create files to save to disk. It is very useful to separate your more complicated data analysis workflows into stages. Typically, the earlier stages will involve data reading, creation of new variables, and or merging different data sets. Much like we have done here. Subsequent steps would be analyzing the data that we have just constructed.\nWe do not want to have to repeat the data processing steps each time we need to carry out the analysis. To avoid this, we have our data processing notebooks save the newly created data to external files. This way the analysis notebooks only have to read these newly created files - we do not have to recreate them.\nLet’s save our latest DataFrame to a csv so we can use it again later.\n\nmerged.to_csv(\"merged.csv\", index=False)\n\nWe can show that the merge above will work irrespective of order.\n\nmerged.sort_values(by='description')\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n99224\n6\n21.40\nNew York\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n40812\n7\n6.73\nMaryland\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n498715\n1\n133.50\nGeorgia\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n18899\n10\n55.40\nMaine\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n961855\n4\n305.10\nTexas\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n227470\n2\n76.80\nLouisiana\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n73622\n2\n26.90\nNorth Dakota\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n235684\n1\n63.80\nIdaho\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n675647\n1\n89.60\nMassachusetts\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n58639\n6\n143.40\nNevada\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n48864\n1\n31.60\nWest Virginia\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n65132\n1\n21.10\nWyoming\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n136632\n2\n125.20\nSouth Carolina\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n905748\n1\n210.30\nOhio\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n43976\n3\n64.30\nNew Hampshire\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n715522\n1\n153.30\nColorado\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n214133\n1\n75.80\nIowa\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n39403\n2\n22.40\nDelaware\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n28602\n15\n14.70\nKentucky\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n50099\n9\n8.11\nPennsylvania\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n121054\n4\n17.30\nConnecticut\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n32091\n6\n14.00\nMontana\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n350964\n1\n68.40\nHawaii\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n887642\n1\n361.50\nIndiana\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n153701\n1\n104.90\nMississippi\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n43228\n15\n27.30\nMissouri\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.70\nAlaska\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n112644\n5\n35.00\nMichigan\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n291082\n2\n74.60\nNebraska\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.20\nArkansas\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n269840\n2\n68.70\nWisconsin\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.80\nAlabama\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n8074\n6\n10.20\nVermont\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n689447\n1\n525.90\nTennessee\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n681054\n1\n620.30\nOklahoma\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n55605\n23\n16.70\nWashington\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.60\nArizona\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n14091\n9\n13.00\nSouth Dakota\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n190934\n1\n18.50\nRhode Island\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n467665\n2\n114.60\nNorth Carolina\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n226610\n4\n60.10\nVirginia\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.90\nCalifornia\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n175535\n3\n45.70\nOregon\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n199723\n1\n109.10\nUtah\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n87505\n4\n37.30\nNew Mexico\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n114394\n7\n54.00\nIllinois\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n311527\n2\n52.80\nMinnesota\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n196169\n8\n95.70\nFlorida\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n126587\n5\n56.00\nKansas\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n90871\n10\n7.66\nNew Jersey\n\n\n\n\n\n\n\nLet’s write this out to a second new file:\n\nmerged.sort_values(by='description').to_csv('merged1.csv', index=False)\n\nNow read it in and redo a merge to compare to what we did above\n\npop_df = pd.read_csv('merged1.csv')\n\n\npop_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n99224\n6\n21.40\nNew York\n\n\n1\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n40812\n7\n6.73\nMaryland\n\n\n2\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n498715\n1\n133.50\nGeorgia\n\n\n3\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n18899\n10\n55.40\nMaine\n\n\n4\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n961855\n4\n305.10\nTexas\n\n\n\n\n\n\n\n\nmerged1 = pd.merge(cities_df, pop_df[['CityPop', 'rank_in_state', 'area', 'State']], left_on='name', right_on='State')\n\n\nmerged1.shape\n\n(50, 11)\n\n\n\nmerged1.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.8\nAlabama\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.7\nAlaska\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.6\nArizona\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.2\nArkansas\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.9\nCalifornia\n\n\n\n\n\n\n\n\nmerged.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.8\nAlabama\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.7\nAlaska\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.6\nArizona\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.2\nArkansas\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.9\nCalifornia"
  },
  {
    "objectID": "studio/meet.html",
    "href": "studio/meet.html",
    "title": "",
    "section": "",
    "text": "Code\nf# Instructions for Creating a Google Meet Meeting for Small Group Activities"
  },
  {
    "objectID": "studio/meet.html#overview",
    "href": "studio/meet.html#overview",
    "title": "",
    "section": "Overview",
    "text": "Overview\nIn this activity, you’ll work in small groups to collaborate on a task. To facilitate your work, each group will create a Google Meet meeting where you can share your screens and discuss the activity in real-time."
  },
  {
    "objectID": "studio/meet.html#steps-to-create-a-google-meet-meeting",
    "href": "studio/meet.html#steps-to-create-a-google-meet-meeting",
    "title": "",
    "section": "Steps to Create a Google Meet Meeting",
    "text": "Steps to Create a Google Meet Meeting\n\n1. Choose a Group Leader\n\nSelect one person in your group to create the Google Meet meeting. This person will be responsible for sharing the meeting link with the rest of the group.\n\n\n\n2. Create the Google Meet Meeting\n\nThe group leader should follow these steps:\n\nOpen Google Meet:\n\nGo to Google Meet in your web browser.\n\nStart a New Meeting:\n\nClick on the New meeting button.\nSelect Start an instant meeting.\n\nCopy the Meeting Link:\n\nOnce the meeting is created, a window will pop up with the meeting link.\nClick on Copy meeting link to copy the URL to your clipboard.\n\n\n\n\n\n3. Share the Meeting Link with Your Group\n\nThe group leader should share the copied meeting link with the rest of the group members. This can be done via:\n\nClass communication platform (chat)\nDirect message or text\n\n\n\n\n4. Join the Google Meet Meeting\n\nEach group member should click on the link provided by the group leader to join the meeting.\n\n\n\n5. Share Your Screen\n\nTo share your screen during the meeting:\n\nClick on the Present Now button:\n\nThis button is located at the bottom of the Google Meet window.\n\nChoose What to Share:\n\nYou can select to share your entire screen, a specific window, or a specific browser tab.\n\nClick on Share:\n\nOnce you’ve selected what to share, click Share to start presenting to the group.\n\n\n\n\n\n6. Collaborate on the Activity\n\nUse the screen sharing feature to work together on the assigned activity. Discuss, brainstorm, and contribute as a team.\n\n\n\n7. Wrap Up\n\nWhen your group has completed the activity, you can leave the Google Meet meeting by clicking the Leave call button."
  },
  {
    "objectID": "studio/meet.html#troubleshooting-tips",
    "href": "studio/meet.html#troubleshooting-tips",
    "title": "",
    "section": "Troubleshooting Tips",
    "text": "Troubleshooting Tips\n\nAudio Issues: If you’re having trouble hearing others, make sure your microphone and speakers are properly connected and not muted.\nScreen Sharing Not Working: Ensure that you have granted the necessary permissions for screen sharing in your browser.\nInternet Connection: If your connection is unstable, try moving closer to your Wi-Fi router or switching to a wired connection if possible."
  },
  {
    "objectID": "studio/meet.html#additional-resources",
    "href": "studio/meet.html#additional-resources",
    "title": "",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nGoogle Meet Help Center\n\nGood luck with your activity, and make the most of your collaborative time!"
  },
  {
    "objectID": "studio/week08/local.html",
    "href": "studio/week08/local.html",
    "title": "Studio 08 Local Spatial Autocorrelation",
    "section": "",
    "text": "DUE: Wednesday, October 23, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-16 Studio 8: Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week08/local.html#instructions",
    "href": "studio/week08/local.html#instructions",
    "title": "Studio 08 Local Spatial Autocorrelation",
    "section": "",
    "text": "DUE: Wednesday, October 23, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-16 Studio 8: Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week08/local.html#part-1-setup",
    "href": "studio/week08/local.html#part-1-setup",
    "title": "Studio 08 Local Spatial Autocorrelation",
    "section": "Part 1: Setup",
    "text": "Part 1: Setup\n\nInstall and import the necessary libraries:\n\nYou will need to install libraries such as geopandas, pysal, and matplotlib to work with spatial data and visualize results.\n\nLoad the South dataset:\n\nThe South dataset includes homicide rates and geographical information. Load the dataset for analysis.",
    "crumbs": [
      "Home",
      "10-16 Studio 8: Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week08/local.html#part-2-exploratory-data-analysis-eda",
    "href": "studio/week08/local.html#part-2-exploratory-data-analysis-eda",
    "title": "Studio 08 Local Spatial Autocorrelation",
    "section": "Part 2: Exploratory Data Analysis (EDA)",
    "text": "Part 2: Exploratory Data Analysis (EDA)\n\nPlot the spatial distribution of homicide rates:\n\nCreate a choropleth map to visualize the spatial distribution of homicide rates across the southern U.S.\n\nInitial analysis:\n\nWhat general patterns do you observe about the spatial distribution of homicide rates?\nAre there regions where homicide rates seem to cluster?",
    "crumbs": [
      "Home",
      "10-16 Studio 8: Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week08/local.html#part-3-local-spatial-autocorrelation-with-lisa",
    "href": "studio/week08/local.html#part-3-local-spatial-autocorrelation-with-lisa",
    "title": "Studio 08 Local Spatial Autocorrelation",
    "section": "Part 3: Local Spatial Autocorrelation with LISA",
    "text": "Part 3: Local Spatial Autocorrelation with LISA\n\nCreate a spatial weights matrix:\n\nUse Queen contiguity to define neighboring areas.\n\nCompute Local Moran’s I:\n\nCalculate Local Moran’s I to explore spatial autocorrelation in homicide rates.\n\nInterpret LISA Results:\n\nExamine whether high or low values cluster spatially and whether these clusters are statistically significant.",
    "crumbs": [
      "Home",
      "10-16 Studio 8: Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week08/local.html#part-4-visualizing-lisa-results",
    "href": "studio/week08/local.html#part-4-visualizing-lisa-results",
    "title": "Studio 08 Local Spatial Autocorrelation",
    "section": "Part 4: Visualizing LISA Results",
    "text": "Part 4: Visualizing LISA Results\n\nCreate a LISA Cluster Map:\n\nVisualize clusters (hotspots and cold spots) of homicide rates using a LISA cluster map.\n\nAnswer these questions:\n\nWhich areas show statistically significant clustering of high homicide rates (hotspots)?\nWhich areas show statistically significant clustering of low homicide rates (cold spots)?\nAre there any areas classified as spatial outliers?",
    "crumbs": [
      "Home",
      "10-16 Studio 8: Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week08/local.html#part-5-further-analysis-and-discussion",
    "href": "studio/week08/local.html#part-5-further-analysis-and-discussion",
    "title": "Studio 08 Local Spatial Autocorrelation",
    "section": "Part 5: Further Analysis and Discussion",
    "text": "Part 5: Further Analysis and Discussion\n\nExplore relationships between LISA clusters and socio-economic factors:\n\nCompare LISA results with other socio-economic variables (e.g., income levels) to identify potential correlations with homicide rates.\n\nDiscussion:\n\nWhat factors might contribute to the observed spatial patterns in homicide rates?\nCan you think of policy interventions that might target identified hotspots or cold spots?",
    "crumbs": [
      "Home",
      "10-16 Studio 8: Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week07/global.html",
    "href": "studio/week07/global.html",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 16, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-09 Studio 7: Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week07/global.html#instructions",
    "href": "studio/week07/global.html#instructions",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "",
    "text": "Teams\nDUE: Wednesday, October 16, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell).",
    "crumbs": [
      "Home",
      "10-09 Studio 7: Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week07/global.html#input-files",
    "href": "studio/week07/global.html#input-files",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "Input Files",
    "text": "Input Files\nIn this studio you will be analyzing the spatial patterns of homicide rates in the southern US Counties, from the South built-in dataset from libpysal.",
    "crumbs": [
      "Home",
      "10-09 Studio 7: Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week07/global.html#join-count-analysis",
    "href": "studio/week07/global.html#join-count-analysis",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "Join Count Analysis",
    "text": "Join Count Analysis\nFor each decade that the homicide rate is recorded complete the following:\n\nCreate a binary variable reporting high and low county homicide rates using the median rate as the threshold.\nConstruct a queen contiguity matrix for the counties.\nDescribe the patterns you see across the decades.\nCreate a binary map of the spatial distribution for each decade.\nCarry out a join counts analysis on the binary variable using the queen contiguity matrix for each decade.\nCreate a time series plot of the number of BB joins for each decade.\nProvide a narrative interpretation of your findings. Specify the null hypothesis for each decade, and state your decision whether to reject or fail to reject the null hypothesis.",
    "crumbs": [
      "Home",
      "10-09 Studio 7: Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week07/global.html#morans-i-analysis",
    "href": "studio/week07/global.html#morans-i-analysis",
    "title": "Studio 07 Global Spatial Autocorrelation",
    "section": "Moran’s I Analysis",
    "text": "Moran’s I Analysis\nFor each decade that the homicide rate is recorded complete the following:\n\nCreate a choropleth map of the spatial distribution of the county homicide rates for each decade.\nDescribe the patterns you see across the decades.\nCarry out a Moran’s I analysis on the original homicide variable using the queen contiguity matrix for each decade.\nCreate a time series plot of the value of the Moran’s I statistic.\nProvide a narrative interpretation of your findings. Specify the null hypothesis for each decade, and state your decision whether to reject or fail to reject the null hypothesis in each period.",
    "crumbs": [
      "Home",
      "10-09 Studio 7: Global Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "studio/week01/index.html",
    "href": "studio/week01/index.html",
    "title": "Studio 1: Jupyter Hub",
    "section": "",
    "text": "In this first studio session, we will do three things:\n\nGet started with Jupyter Hub\nSet up collaboration in studios\nCollaborate on our first studio activity",
    "crumbs": [
      "Home",
      "08-28 Studio 1: Jupyter Hub"
    ]
  },
  {
    "objectID": "studio/week01/intro.html",
    "href": "studio/week01/intro.html",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "",
    "text": "In this Session we introduce the computational environment for the course."
  },
  {
    "objectID": "studio/week01/intro.html#logging-on-to-jupyter-hub",
    "href": "studio/week01/intro.html#logging-on-to-jupyter-hub",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Logging on to Jupyter Hub",
    "text": "Logging on to Jupyter Hub\nEach registered student is given an account on our course Jupyter Hub installation.\nIf you are on campus, and using a campus IP, go to http://130.191.118.182/hub/login\n\n\n\nlogon\n\n\nYour Username is the prefix of your SDSU email (the part before the @).\nFor the Password, you set that the first time you log on. It can be anything you choose, but you must remember it.\nIf you are off-campus, you must first connect to the university’s Virtual Private Network."
  },
  {
    "objectID": "studio/week01/intro.html#interface",
    "href": "studio/week01/intro.html#interface",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Interface",
    "text": "Interface\nWe will be exploring the components of the Jupyter Lab Interface.\n\nMain work area\nleft sidebar\nmenu bar\nfile browser\n\n\n\n\nlogon\n\n\n\nMain work area\nThe main work area arranges activities and documents into panels of tabs.\nDocuments can be notebooks, text files, while activities can be terminals or code consoles.\nIt currently has a single tab entitled Launcher which contains a set of, well, launchers.\n\n\nLeft sidebar\nThe left sidebar contains a file browser (next to the main work area). The thin panel to the left of the file browser has three icons for:\n\ncommand pallet\ntable of contents\nextension manager"
  },
  {
    "objectID": "studio/week01/intro.html#notebooks",
    "href": "studio/week01/intro.html#notebooks",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Notebooks",
    "text": "Notebooks\nLet’s open our first document.\nDouble-click the Square icon under Notebook in the Launcher tab.\nThis will result in:\n\n\n\nnotebook\n\n\nNow, the main work area has a single tab with the title Untitled.ipynb. This is our first jupyter notebook.\nThe extension ipynb tells us so.\nWe also see that the filename is showing up in the file browser.\nIt is good practice to give your notebooks (and files) meaningful names. To do so you can right click on the tab or in the file browser and give it a new name introduction.ipynb.\n\n\n\nnotebook renamed"
  },
  {
    "objectID": "studio/week01/intro.html#cell-types",
    "href": "studio/week01/intro.html#cell-types",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Cell Types",
    "text": "Cell Types\nA notebook is composed of cells. Currently, our notebook as a single cell.\nCells can be of different types. There are three possible types:\n\nCode\nMarkdown\nRaw\n\nWhat happens with the contents of a cell depends upon its type. We can have cells of different types in the same notebook - in other words, all the cells in a notebook do not have to be of the same type. This opens up rich possibilities for creating computational documents.\n\nCode\nThe type of a cell is indicated in the dropdown of the tabs icon bar. Our current cell is of type Code.\nA code cell should contain, well, code. By this we mean, a set of statements that the kernel for our language can understand. Think of the kernel as a machine that is going to take our code and convert it into some type of result or action.\nIn our case, the kernel is Python. This is indicated in the upper right portion of the notebook tab.\nLet’s enter some code in our code cell:\n\nEnter 3**2\nShift-return\n\n\n\n\nRunning a code cell\n\n\nWhen we used the key-chord Shift-return (while holding the shift key down also hit return) from inside the code cell, this took the contents of the cell 3**2 and passed it off to the Python interpreter. Since this was legit Python code, we got a result of 9 in an output cell.\nThen the interface gives us a new empty code cell, so we can continue if we wish.\nBut, instead of continuing, let’s say we wanted a different calculation. Put the cursor back in the first code cell and change this to 10 * 3**2 and rerun the cell.\n\n\n\nRe-running a code cell\n\n\nAgain, this is legit Python code so we get a new result. The other things that have changed are the numbers on the left of the cells. Now we have a [2] in front of the code cell and its output cell. This indicates that we have run 2 code cells in this session.\nThe current cell is indicated by the blue vertical bar. This is where we would enter new code as we progress.\nLet’s progress.\nIn the current cell, enter x = 10 * 3**2 and run the cell.\n\n\n\nRunning a code cell with an assignment\n\n\nWe don’t get an output cell in this case. This is because our code is an assignment statement. This means we assign the value of the statement on the right of the = into the variable x on the left side.\nTo see the value of x, enter x in the next code cell and run the cell:\n\n\n\nRunning a code cell with an output\n\n\nWith this, we have the basics of entering Python code and running it. Let’s turn our attention to the next type of cell: Markdown.\n\n\nMarkdown\nMarkdown is a markup language invented by John Gruber to make it easier for humans to write web pages.\nLet’s change the type of the current cell. There are two ways to do this.\nThe first way is to click on the cell type dropdown (currently set to Code) and select Markdown. This results in:\n\n\n\nChanging to Markdown\n\n\nWe still have the blue indicator to the left of the current cell. But we no longer of the [ ]: next to the cell.\nTo enter some Markdown, put the cursor in the cell and enter:\nThis next word will be **bold**.\n\n\n\nEditing Markdown\n\n\nThen run the Markdown cell with Shift-return:\n\n\n\n“Running” Markdown\n\n\nThis is a bit different from what we saw when we ran a code cell. In the case of a Markdown cell, what happens is that when we “run” the cell, the contents of the cell gets handed off to a different kernel, one that knows the Markdown markup. The kernel then translate from the markdown input and returns actual html that gets rendered in the same cell.\nWe can change our cell by double-clicking in it. Let’s add some more Markdown by changing the cell contents to:\n## Markdown Cells\n\nHere we are demonstrating `Markdown`.\n\nThe next word will be in **bold**.\n\nThe next word will be in *italics*.\n\n### Lists\n\nWe can do unordered lists:\n\n- dog\n- cat\n- monkey\n\nAs well as ordered lists\n\n1. dogs\n1. monkey\n1. cat\n\n\n\nMore Markdown\n\n\nOnce we have entered this, “run” the cell with Shift-return:\n\n\n\nMore Rendered Markdown\n\n\nBefore we do more with Markdown, let’s learn a bit about our last cell type Raw.\n\n\nRaw\nTo see the utility of the Raw cell type, double-click into the Markdown cell. In the cell, copy all the contents of the cell (click and drag with the mouse, then Control-C (Linux/Windows) Command-C (Mac) ).\nMove the cursor into the next cell and paste (Control-V (Linux/Windows), Command-V (Mac)).\nThen, in this last cell change the cell type to Raw so your screen should look like:\n\n\n\nRaw Cell Type\n\n\nNext, jump up to the Markdown cell, and run that cell to render it. Then, render the Raw cell:\n\n\n\nRaw Cell As Reference\n\n\nThis shows us that we can use Raw cells to display the syntax used to get a rendered cell. This can be helpful to document how things were done."
  },
  {
    "objectID": "studio/week01/intro.html#cell-modes",
    "href": "studio/week01/intro.html#cell-modes",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Cell Modes",
    "text": "Cell Modes\nIn addition to having different cell types, cells have two modes.\n\nCommand Mode\nEdit Mode\n\nThese are mutually exclusive modes - only one is active. In other words, you a cell is either in command mode or edit mode.\n\nCommand Mode (Running Cells)\nIn command mode we can, not suprsingly, run cells. We already know how to do this. Make the cell active (by moving the cursor to the cell), then use Ctrl-return.\nHow do we know we are in command mode? A couple of ways.\nIf you are in a code cell, if the cell does not have a blue border, you are in command mode:\n\n\n\nCode cell in Command mode\n\n\nIf the code cell has a blue border you are in edit mode:\n\n\n\nCode cell in Edit mode\n\n\nIf you are in edit mode and want to switch to command mode, use the Esc key.\nIf you are in command mode and want to switch to edit mode, simply click in the cell to start editing.\nIn addition to letting us run cells, command mode also allows us to manipulate cells. The two sets of most common manipulations we do in command mode are:\n\nCut and paste cells (move)\nSplit and merge cells\n\nTo demonstrate the first, recall the figure that had the Raw cell below the Markdown cell. It might be more helpful to have the Raw cell before (above) the Markdown cell.\nTo do this.\nFrom the empty code cell:\n\nEnter command mode (Esc)\nHit the k key. This moves the cursor up into the raw cell.\nHit the x key. This will cut the current cell.\nMove up two cells by repeating k k\nPaste the cut cell with v\n\nYour notebook should now look something like:\n\n\n\nCode cell in Edit mode\n\n\nTo demonstrate splitting cells, let’s say we want to break our Markdown cell into two separate Markdown cells such that the Lists subsection is in its own cell.\nTo do this,\n\nMake the Markdown cell active by moving down one with j.\nOnce the Markdown cell is active, get into edit mode (click into the cell).\nMove the cursor to the empty ilne before Lists.\nCtrl-Shift-- (That’s the Ctrl key held down, with the Shift key followed by -).\n\nThe result should be:\n\n\n\nSpliltting a cell\n\n\nTo merge cells together.\n\nEnter command mode\nShift-k to select the current cell and the cell above it.\nShift-m to merge the two cells.\n\n\n\n\nMerging two cells\n\n\n\n\nEdit Mode\nLet’s create an empty cell and edit it. Assume we want to add a new cell above the current cell. This is done with a.\n\n\n\nCreating a new cell above the current cell\n\n\nLet’s make this a Markdown cell, using the second approach I hinted at above.\n\nEnter command mode\nm\n\nNote that it is lower-case m here. Now we can enter Markdown by clicking in the new cell and filling it in with whatever we want. For example:\n### Using Raw and Markdown cells\nThe cell below will be the rendered markdown. The cell above is the raw markdown in a raw cell for reference\nRendering the cell should give:\n\n\n\nRendered new cell\n\n\nAs our notebooks grow, it would be nice to be able to jump around without endlessly scrolling. Remember the table of contents that lives in the Left sidebar? This can come in handy when you have a long Markdown document and can use the TOC to jump around quickly.\nTo see this work, let’s first go to the top of the notebook by scrolling up. Then, 1. Add a new cell above the current cell. 2. Make it a Markdown Cell 3. Enter ## Python code cells 4. Render the cell\nAfter rendering, the cell, click the table of contents icon in the left sidebar:\n\n\n\nTable of Contents\n\n\nYou can now click on the entries in the table of contents to jump to that section/subsection in the notebook."
  },
  {
    "objectID": "studio/week01/intro.html#saving-and-exporting",
    "href": "studio/week01/intro.html#saving-and-exporting",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Saving and Exporting",
    "text": "Saving and Exporting\nIt is good practice to save your notebook as you go. Use Ctrl-s to do so or Command-s (mac).\nIf there are any unsaved changes, the little black dot in the notebook tab will be visible:\n\n\n\nUnsaved changes\n\n\nAfter saving your notebook, it will live on the course server, so you can come back to it later (see logging off below). Sometimes, you will need to export or download a copy of your notebook to hand in for credit. To do this:\n\nMake sure the notebook you want to save is the active tab in the main work area\nClick on the file browser icon in the left side bar.\nFrom the Menu bar: File-Save and Export Notebook As-pdf\n\nThis should create a pdf file on your local computer that you can hand in.\nIf you get an error that looks like:\n\n\n\nSaving error\n\n\nThis is due to having the Raw cell in the notebook. To fix it, simply delete the Raw cell and try to export again. We won’t be using Raw cells in the assignments so this won’t be an issue moving forward."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Geography 385 Spatial Data Analysis is an introduction to exploratory spatial data analysis taught by Professor Sergio Rey at San Diego State University."
  },
  {
    "objectID": "lectures/week03/lecture.html#syllabus",
    "href": "lectures/week03/lecture.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus"
  },
  {
    "objectID": "lectures/week03/lecture.html#spatial-data-analysis",
    "href": "lectures/week03/lecture.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week03/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week03/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#eda-approach",
    "href": "lectures/week03/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week03/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#historical-context",
    "href": "lectures/week03/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#snow-map",
    "href": "lectures/week03/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#snow-map-1",
    "href": "lectures/week03/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week03/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#vector-data",
    "href": "lectures/week03/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#vector-data-1",
    "href": "lectures/week03/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#raster-data",
    "href": "lectures/week03/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#raster-data-1",
    "href": "lectures/week03/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#attribute-data",
    "href": "lectures/week03/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#attribute-data-1",
    "href": "lectures/week03/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week03/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week03/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#remote-sensing",
    "href": "lectures/week03/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week03/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week03/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week03/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week03/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week03/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week03/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week03/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week03/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week03/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#questions",
    "href": "lectures/week03/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#references",
    "href": "lectures/week03/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "lectures/week05/choro.html#imports",
    "href": "lectures/week05/choro.html#imports",
    "title": "Visualization for Area Unit Data",
    "section": "Imports",
    "text": "Imports\n\nimport geopandas\nimport libpysal",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#example",
    "href": "lectures/week05/choro.html#example",
    "title": "Visualization for Area Unit Data",
    "section": "Example",
    "text": "Example\n\nsouth = libpysal.examples.load_example('South')",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#inspecting-the-example",
    "href": "lectures/week05/choro.html#inspecting-the-example",
    "title": "Visualization for Area Unit Data",
    "section": "Inspecting the example",
    "text": "Inspecting the example\n\nlibpysal.examples.explain('South')",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#reading-the-shapefile",
    "href": "lectures/week05/choro.html#reading-the-shapefile",
    "title": "Visualization for Area Unit Data",
    "section": "Reading the shapefile",
    "text": "Reading the shapefile\n\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#plotting-the-geometries",
    "href": "lectures/week05/choro.html#plotting-the-geometries",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the Geometries",
    "text": "Plotting the Geometries\n\nsouth_gdf.plot()",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#plotting-the-attribute-distribution",
    "href": "lectures/week05/choro.html#plotting-the-attribute-distribution",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the attribute distribution",
    "text": "Plotting the attribute distribution\n\nimport seaborn",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#plotting-the-attribute-distribution-1",
    "href": "lectures/week05/choro.html#plotting-the-attribute-distribution-1",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the attribute distribution",
    "text": "Plotting the attribute distribution\n\nseaborn.displot(south_gdf, x='HR60')",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#alternative-view-of-the-attribute-distribution",
    "href": "lectures/week05/choro.html#alternative-view-of-the-attribute-distribution",
    "title": "Visualization for Area Unit Data",
    "section": "Alternative view of the attribute distribution",
    "text": "Alternative view of the attribute distribution\n\nsouth_gdf.HR60.describe()\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#spatial-distribution-default-choropleth",
    "href": "lectures/week05/choro.html#spatial-distribution-default-choropleth",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Default Choropleth)",
    "text": "Spatial Distribution (Default Choropleth)\n\nsouth_gdf.plot(column='HR60')",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#spatial-distribution-changing-the-classification",
    "href": "lectures/week05/choro.html#spatial-distribution-changing-the-classification",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Changing the classification)",
    "text": "Spatial Distribution (Changing the classification)\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles')",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#spatial-distribution-adding-a-legend",
    "href": "lectures/week05/choro.html#spatial-distribution-adding-a-legend",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Adding a legend)",
    "text": "Spatial Distribution (Adding a legend)\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True)",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#mapclassify",
    "href": "lectures/week05/choro.html#mapclassify",
    "title": "Visualization for Area Unit Data",
    "section": "Mapclassify",
    "text": "Mapclassify\n\nimport mapclassify",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#quantiles",
    "href": "lectures/week05/choro.html#quantiles",
    "title": "Visualization for Area Unit Data",
    "section": "Quantiles",
    "text": "Quantiles\n\nmapclassify.Quantiles(south_gdf.HR60)\n\nQuantiles\n\n   Interval      Count\n----------------------\n[ 0.00,  2.50] |   283\n( 2.50,  5.10] |   282\n( 5.10,  7.62] |   282\n( 7.62, 10.98] |   282\n(10.98, 92.94] |   283",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#quantiles-changing-the-number-of-classes",
    "href": "lectures/week05/choro.html#quantiles-changing-the-number-of-classes",
    "title": "Visualization for Area Unit Data",
    "section": "Quantiles: Changing the number of classes",
    "text": "Quantiles: Changing the number of classes\n\nmapclassify.Quantiles(south_gdf.HR60, k=10)\n\nQuantiles\n\n   Interval      Count\n----------------------\n[ 0.00,  0.00] |   180\n( 0.00,  2.50] |   103\n( 2.50,  3.93] |   141\n( 3.93,  5.10] |   141\n( 5.10,  6.25] |   141\n( 6.25,  7.62] |   141\n( 7.62,  9.19] |   141\n( 9.19, 10.98] |   141\n(10.98, 14.31] |   141\n(14.31, 92.94] |   142",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#equal-interval",
    "href": "lectures/week05/choro.html#equal-interval",
    "title": "Visualization for Area Unit Data",
    "section": "Equal Interval",
    "text": "Equal Interval\n\nmapclassify.EqualInterval(south_gdf.HR60, k=10)\n\nEqualInterval\n\n   Interval      Count\n----------------------\n[ 0.00,  9.29] |  1000\n( 9.29, 18.59] |   358\n(18.59, 27.88] |    39\n(27.88, 37.17] |     8\n(37.17, 46.47] |     4\n(46.47, 55.76] |     2\n(55.76, 65.06] |     0\n(65.06, 74.35] |     0\n(74.35, 83.64] |     0\n(83.64, 92.94] |     1",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#maximum-breaks",
    "href": "lectures/week05/choro.html#maximum-breaks",
    "title": "Visualization for Area Unit Data",
    "section": "Maximum Breaks",
    "text": "Maximum Breaks\n\nmapclassify.MaximumBreaks(south_gdf.HR60, k=10)\n\nMaximumBreaks\n\n   Interval      Count\n----------------------\n[ 0.00, 29.42] |  1400\n(29.42, 30.74] |     1\n(30.74, 33.40] |     1\n(33.40, 35.94] |     1\n(35.94, 39.00] |     4\n(39.00, 43.29] |     1\n(43.29, 48.96] |     1\n(48.96, 52.69] |     1\n(52.69, 73.12] |     1\n(73.12, 92.94] |     1",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#fisher-jenks",
    "href": "lectures/week05/choro.html#fisher-jenks",
    "title": "Visualization for Area Unit Data",
    "section": "Fisher-Jenks",
    "text": "Fisher-Jenks\n\nmapclassify.FisherJenks(south_gdf.HR60, k=10)\n\nFisherJenks\n\n   Interval      Count\n----------------------\n[ 0.00,  1.71] |   216\n( 1.71,  4.45] |   278\n( 4.45,  7.08] |   287\n( 7.08, 10.02] |   288\n(10.02, 13.59] |   176\n(13.59, 19.60] |   121\n(19.60, 28.77] |    34\n(28.77, 40.74] |     8\n(40.74, 53.30] |     3\n(53.30, 92.94] |     1",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#boxplot",
    "href": "lectures/week05/choro.html#boxplot",
    "title": "Visualization for Area Unit Data",
    "section": "BoxPlot",
    "text": "BoxPlot\n\nmapclassify.BoxPlot(south_gdf.HR60)\n\nBoxPlot\n\n   Interval      Count\n----------------------\n( -inf, -6.90] |     0\n(-6.90,  3.21] |   353\n( 3.21,  6.25] |   353\n( 6.25,  9.96] |   353\n( 9.96, 20.07] |   311\n(20.07, 92.94] |    42",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#head-tail",
    "href": "lectures/week05/choro.html#head-tail",
    "title": "Visualization for Area Unit Data",
    "section": "Head Tail",
    "text": "Head Tail\n\nmapclassify.HeadTailBreaks(south_gdf.HR60)\n\nHeadTailBreaks\n\n   Interval      Count\n----------------------\n[ 0.00,  7.29] |   802\n( 7.29, 12.41] |   405\n(12.41, 18.18] |   147\n(18.18, 26.87] |    40\n(26.87, 38.73] |    13\n(38.73, 56.98] |     4\n(56.98, 92.94] |     1",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#customization",
    "href": "lectures/week05/choro.html#customization",
    "title": "Visualization for Area Unit Data",
    "section": "Customization",
    "text": "Customization\n\nLegends\nColor Schemes",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#legends",
    "href": "lectures/week05/choro.html#legends",
    "title": "Visualization for Area Unit Data",
    "section": "Legends",
    "text": "Legends\n\nsouth_gdf[['STATE_NAME', 'HR60', 'HR90']].head()\n\n\n\n\n\n\n\n\nSTATE_NAME\nHR60\nHR90\n\n\n\n\n0\nWest Virginia\n1.682864\n0.946083\n\n\n1\nWest Virginia\n4.607233\n1.234934\n\n\n2\nWest Virginia\n0.974132\n2.621009\n\n\n3\nWest Virginia\n0.876248\n4.461577\n\n\n4\nDelaware\n4.228385\n6.712736",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#create-a-boolean-variable",
    "href": "lectures/week05/choro.html#create-a-boolean-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Create a Boolean variable",
    "text": "Create a Boolean variable\n\nsouth_gdf['increased' ] =  south_gdf.HR90 &gt; south_gdf.HR60",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#mapping-the-boolean-variable",
    "href": "lectures/week05/choro.html#mapping-the-boolean-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Mapping the Boolean variable",
    "text": "Mapping the Boolean variable\n\nsouth_gdf.plot(column='increased', categorical=True, legend=True);",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#change-the-values",
    "href": "lectures/week05/choro.html#change-the-values",
    "title": "Visualization for Area Unit Data",
    "section": "Change the values",
    "text": "Change the values\n\nv = south_gdf.increased.map({True: 'Increased', False: 'Decreased'})\nsouth_gdf['Increased'] = v",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#map-the-new-variable",
    "href": "lectures/week05/choro.html#map-the-new-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Map the new variable",
    "text": "Map the new variable\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True);",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#legend-positioning",
    "href": "lectures/week05/choro.html#legend-positioning",
    "title": "Visualization for Area Unit Data",
    "section": "Legend Positioning",
    "text": "Legend Positioning\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (1.3, 1)});",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#legend-title",
    "href": "lectures/week05/choro.html#legend-title",
    "title": "Visualization for Area Unit Data",
    "section": "Legend Title",
    "text": "Legend Title\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (1.3, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#more-adjustments",
    "href": "lectures/week05/choro.html#more-adjustments",
    "title": "Visualization for Area Unit Data",
    "section": "More Adjustments",
    "text": "More Adjustments\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#more-adjustments-1",
    "href": "lectures/week05/choro.html#more-adjustments-1",
    "title": "Visualization for Area Unit Data",
    "section": "More Adjustments",
    "text": "More Adjustments\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#color-schemes",
    "href": "lectures/week05/choro.html#color-schemes",
    "title": "Visualization for Area Unit Data",
    "section": "Color schemes",
    "text": "Color schemes\n\nmatplotlib Hunter (2007)\nColorBrewer Harrower and Brewer (2003)",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#sequential-color-schemes",
    "href": "lectures/week05/choro.html#sequential-color-schemes",
    "title": "Visualization for Area Unit Data",
    "section": "Sequential Color Schemes",
    "text": "Sequential Color Schemes\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='Blues');",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#change-the-color-map-single-hue",
    "href": "lectures/week05/choro.html#change-the-color-map-single-hue",
    "title": "Visualization for Area Unit Data",
    "section": "Change the color map: Single Hue",
    "text": "Change the color map: Single Hue\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='Greens');",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#change-the-color-map-multiple-hues",
    "href": "lectures/week05/choro.html#change-the-color-map-multiple-hues",
    "title": "Visualization for Area Unit Data",
    "section": "Change the color map: Multiple Hues",
    "text": "Change the color map: Multiple Hues\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu');",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#diverging-color-map",
    "href": "lectures/week05/choro.html#diverging-color-map",
    "title": "Visualization for Area Unit Data",
    "section": "Diverging Color Map",
    "text": "Diverging Color Map\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n               cmap='coolwarm',\n           );",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#alternative-diverging-color-map",
    "href": "lectures/week05/choro.html#alternative-diverging-color-map",
    "title": "Visualization for Area Unit Data",
    "section": "Alternative Diverging Color Map",
    "text": "Alternative Diverging Color Map\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n               cmap='bwr',\n           );",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme",
    "href": "lectures/week05/choro.html#qualitative-color-scheme",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True)",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme-1",
    "href": "lectures/week05/choro.html#qualitative-color-scheme-1",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True)",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme-2",
    "href": "lectures/week05/choro.html#qualitative-color-scheme-2",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1)})",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme-3",
    "href": "lectures/week05/choro.html#qualitative-color-scheme-3",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_axes([0, 0, 1, 1])\nax.axis('off')\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1)}, ax=ax);",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#comparisons",
    "href": "lectures/week05/choro.html#comparisons",
    "title": "Visualization for Area Unit Data",
    "section": "Comparisons",
    "text": "Comparisons\n\nDeciles\nMaximum Breaks\nFisher Jenks",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#deciles",
    "href": "lectures/week05/choro.html#deciles",
    "title": "Visualization for Area Unit Data",
    "section": "Deciles",
    "text": "Deciles\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#maximum-breaks-1",
    "href": "lectures/week05/choro.html#maximum-breaks-1",
    "title": "Visualization for Area Unit Data",
    "section": "Maximum Breaks",
    "text": "Maximum Breaks\n\nsouth_gdf.plot(column='HR60', scheme='MaximumBreaks', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#fisher-jenks-1",
    "href": "lectures/week05/choro.html#fisher-jenks-1",
    "title": "Visualization for Area Unit Data",
    "section": "Fisher Jenks",
    "text": "Fisher Jenks\n\nsouth_gdf.plot(column='HR60', scheme='FisherJenks', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#statistical-fit",
    "href": "lectures/week05/choro.html#statistical-fit",
    "title": "Visualization for Area Unit Data",
    "section": "Statistical Fit",
    "text": "Statistical Fit\n\ny = south_gdf.HR60\nq10 = mapclassify.Quantiles(y, k=10)\nmb10 = mapclassify.MaximumBreaks(y, k=10)\nfj10 = mapclassify.FisherJenks(y, k=10)\nprint(f'Deciles: {q10.adcm:.1f}, MB: {mb10.adcm:.1f}, FJ: {fj10.adcm:.1f}')\n\nDeciles: 1140.3, MB: 5688.1, FJ: 1027.5",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#statistical-fit-1",
    "href": "lectures/week05/choro.html#statistical-fit-1",
    "title": "Visualization for Area Unit Data",
    "section": "Statistical Fit",
    "text": "Statistical Fit",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#recap-of-key-points",
    "href": "lectures/week05/choro.html#recap-of-key-points",
    "title": "Visualization for Area Unit Data",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nAreal Unit Data\nChoropleth Mapping\nClassification Schemes\nMap Customization",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#questions",
    "href": "lectures/week05/choro.html#questions",
    "title": "Visualization for Area Unit Data",
    "section": "Questions",
    "text": "Questions",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#references",
    "href": "lectures/week05/choro.html#references",
    "title": "Visualization for Area Unit Data",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nHarrower, Mark, and Cynthia A. Brewer. 2003. “ColorBrewer.org: An Online Tool for Selecting Colour Schemes for Maps.” The Cartographic Journal 40 (1): 27–37. https://doi.org/10.1179/000870403235002042.\n\n\nHunter, John D. 2007. “Matplotlib: A 2D Graphics Environment.” Computing in Science & Engineering 9 (3): 90–95. https://doi.org/10.1109/MCSE.2007.55.",
    "crumbs": [
      "Home",
      "09-23 Choropleth Mapping"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#what-is-area-unit-data",
    "href": "lectures/week04/lecture_area.html#what-is-area-unit-data",
    "title": "Methods for Area Unit Data",
    "section": "What is Area Unit Data?",
    "text": "What is Area Unit Data?\n\nAnalysis of data associated with spatial zones or areas\nAreas may be regular in shape and size, or irregular",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#focus-in-area-unit-data-analysis",
    "href": "lectures/week04/lecture_area.html#focus-in-area-unit-data-analysis",
    "title": "Methods for Area Unit Data",
    "section": "Focus in Area Unit Data Analysis",
    "text": "Focus in Area Unit Data Analysis\n\nVariation in an attribute across our spatial units\nThe spatial variation is not continuous\nSpatial units are polygons\n\nvariation across polygons\nno variation within polygons",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#notation",
    "href": "lectures/week04/lecture_area.html#notation",
    "title": "Methods for Area Unit Data",
    "section": "Notation",
    "text": "Notation\nOur substantive attribute of interest is \\(Y\\).\nOur process is represented as:\n\\[\n\\{ Y(A_i), \\ A_i \\in A_1, A_2, \\ldots, A_n \\}\n\\]\n\\[\nA_1 \\cup A_2 \\cup \\ldots \\cup A_n = {R}\n\\]\n\n\\(Y(A_i)\\) is a set of random variables indexed by sub-regions\n\\(A_1, A_2, \\ldots , A_n\\) are sub-regions of \\({R}\\)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#areal-unit-data-lattice",
    "href": "lectures/week04/lecture_area.html#areal-unit-data-lattice",
    "title": "Methods for Area Unit Data",
    "section": "Areal Unit Data (Lattice)",
    "text": "Areal Unit Data (Lattice)\n\nSpatial Domain: \\({R}\\)\n\nDiscrete and fixed\nLocations nonrandom\nLocations countable\n\n\n\nExamples of lattice data\n\nAttributes collected by ZIP code\ncensus tract",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#lattice-data-indexing",
    "href": "lectures/week04/lecture_area.html#lattice-data-indexing",
    "title": "Methods for Area Unit Data",
    "section": "Lattice Data: Indexing",
    "text": "Lattice Data: Indexing\n\nSite\n\nEach location is now an area or site\nOne observation on \\(Y\\) for each site\nNeed a spatial index: \\(Y(s_i)\\)\n\n\n\n\\(Y(s_i)\\)\n\n\\(s_i\\) is a representative location within the site\ne.g., centroid, largest city\nAllows for measuring distances between sites",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#lattice-data-county-per-capita-incomes",
    "href": "lectures/week04/lecture_area.html#lattice-data-county-per-capita-incomes",
    "title": "Methods for Area Unit Data",
    "section": "Lattice Data: County Per Capita Incomes",
    "text": "Lattice Data: County Per Capita Incomes\n\n1969",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#objectives",
    "href": "lectures/week04/lecture_area.html#objectives",
    "title": "Methods for Area Unit Data",
    "section": "Objectives",
    "text": "Objectives\n\nInfer whether there are a spatial trend or pattern in the attribute values recorded over the sub-regions\nFirst order variation: Trend in the mean\nSecond order variation: Spatial dependence",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#choropleths",
    "href": "lectures/week04/lecture_area.html#choropleths",
    "title": "Methods for Area Unit Data",
    "section": "Choropleths",
    "text": "Choropleths",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#interactivity",
    "href": "lectures/week04/lecture_area.html#interactivity",
    "title": "Methods for Area Unit Data",
    "section": "Interactivity",
    "text": "Interactivity",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#spatial-dependence",
    "href": "lectures/week04/lecture_area.html#spatial-dependence",
    "title": "Methods for Area Unit Data",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\n\nHell might be a world without spatial dependence since it would be impossible to live there in any practical and meaningful way.\n\nLongley and Cheshire (2017)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#spatial-autocorrelation",
    "href": "lectures/week04/lecture_area.html#spatial-autocorrelation",
    "title": "Methods for Area Unit Data",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C.",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#spatial-autocorrelation-homicide-rates-1969",
    "href": "lectures/week04/lecture_area.html#spatial-autocorrelation-homicide-rates-1969",
    "title": "Methods for Area Unit Data",
    "section": "Spatial Autocorrelation (Homicide Rates 1969)",
    "text": "Spatial Autocorrelation (Homicide Rates 1969)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#imports",
    "href": "lectures/week04/lecture_area.html#imports",
    "title": "Methods for Area Unit Data",
    "section": "Imports",
    "text": "Imports\n\nimport geopandas\nimport libpysal",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#loading-an-example-data-set",
    "href": "lectures/week04/lecture_area.html#loading-an-example-data-set",
    "title": "Methods for Area Unit Data",
    "section": "Loading an example data set",
    "text": "Loading an example data set\n\nsouth = libpysal.examples.load_example('South')",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#finding-out-about-the-example",
    "href": "lectures/week04/lecture_area.html#finding-out-about-the-example",
    "title": "Methods for Area Unit Data",
    "section": "Finding out about the example",
    "text": "Finding out about the example\n\nlibpysal.examples.explain('South')",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#creating-a-geodataframe-from-a-file",
    "href": "lectures/week04/lecture_area.html#creating-a-geodataframe-from-a-file",
    "title": "Methods for Area Unit Data",
    "section": "Creating a GeoDataFrame from a file",
    "text": "Creating a GeoDataFrame from a file\n\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#plotting-the-geometries",
    "href": "lectures/week04/lecture_area.html#plotting-the-geometries",
    "title": "Methods for Area Unit Data",
    "section": "Plotting the geometries",
    "text": "Plotting the geometries\n\nsouth_gdf.plot()",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#checking-the-coordinate-reference-system",
    "href": "lectures/week04/lecture_area.html#checking-the-coordinate-reference-system",
    "title": "Methods for Area Unit Data",
    "section": "Checking the Coordinate Reference System",
    "text": "Checking the Coordinate Reference System\n\nsouth_gdf.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#turning-of-the-axis",
    "href": "lectures/week04/lecture_area.html#turning-of-the-axis",
    "title": "Methods for Area Unit Data",
    "section": "Turning of the axis",
    "text": "Turning of the axis\n\nax = south_gdf.plot()\nax.set_axis_off();",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#inspecting-the-gdf",
    "href": "lectures/week04/lecture_area.html#inspecting-the-gdf",
    "title": "Methods for Area Unit Data",
    "section": "Inspecting the GDF",
    "text": "Inspecting the GDF\n\nsouth_gdf.shape\n\n(1412, 70)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#inspecting-the-geoseries",
    "href": "lectures/week04/lecture_area.html#inspecting-the-geoseries",
    "title": "Methods for Area Unit Data",
    "section": "Inspecting the GeoSeries",
    "text": "Inspecting the GeoSeries\n\nsouth_gdf.geometry\n\n0       POLYGON ((-80.62805 40.39816, -80.60204 40.480...\n1       POLYGON ((-80.52625 40.16245, -80.5876 40.1750...\n2       POLYGON ((-80.52517 40.02275, -80.73843 40.035...\n3       POLYGON ((-80.52447 39.72113, -80.83248 39.718...\n4       POLYGON ((-75.7727 39.38301, -75.79144 39.7237...\n                              ...                        \n1407    POLYGON ((-79.14433 36.54606, -79.21706 36.549...\n1408    POLYGON ((-79.43775 37.61596, -79.45834 37.603...\n1409    POLYGON ((-80.12475 37.1251, -80.14045 37.1283...\n1410    POLYGON ((-76.39569 37.10771, -76.4027 37.0905...\n1411    POLYGON ((-77.53178 38.56506, -77.72094 38.840...\nName: geometry, Length: 1412, dtype: geometry",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#inspecting-the-columns",
    "href": "lectures/week04/lecture_area.html#inspecting-the-columns",
    "title": "Methods for Area Unit Data",
    "section": "Inspecting the Columns",
    "text": "Inspecting the Columns\n\nsouth_gdf.columns\n\nIndex(['NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'STFIPS',\n       'COFIPS', 'FIPSNO', 'SOUTH', 'HR60', 'HR70', 'HR80', 'HR90', 'HC60',\n       'HC70', 'HC80', 'HC90', 'PO60', 'PO70', 'PO80', 'PO90', 'RD60', 'RD70',\n       'RD80', 'RD90', 'PS60', 'PS70', 'PS80', 'PS90', 'UE60', 'UE70', 'UE80',\n       'UE90', 'DV60', 'DV70', 'DV80', 'DV90', 'MA60', 'MA70', 'MA80', 'MA90',\n       'POL60', 'POL70', 'POL80', 'POL90', 'DNL60', 'DNL70', 'DNL80', 'DNL90',\n       'MFIL59', 'MFIL69', 'MFIL79', 'MFIL89', 'FP59', 'FP69', 'FP79', 'FP89',\n       'BLK60', 'BLK70', 'BLK80', 'BLK90', 'GI59', 'GI69', 'GI79', 'GI89',\n       'FH60', 'FH70', 'FH80', 'FH90', 'geometry'],\n      dtype='object')",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#interactive-map",
    "href": "lectures/week04/lecture_area.html#interactive-map",
    "title": "Methods for Area Unit Data",
    "section": "Interactive Map",
    "text": "Interactive Map\n\nsouth_gdf.explore(column='HR60')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#describing-a-column",
    "href": "lectures/week04/lecture_area.html#describing-a-column",
    "title": "Methods for Area Unit Data",
    "section": "Describing a column",
    "text": "Describing a column\n\nsouth_gdf.HR60.describe()\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#static-choropleth-hr60",
    "href": "lectures/week04/lecture_area.html#static-choropleth-hr60",
    "title": "Methods for Area Unit Data",
    "section": "Static Choropleth: HR60",
    "text": "Static Choropleth: HR60\n\nax = south_gdf.plot(column='HR60', scheme='Quantiles', k=5,\n                    legend_kwds = {'loc': 'lower center'},\n                    legend=True)\nax.set_axis_off();",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#how-many-states-are-there-in-this-dataset",
    "href": "lectures/week04/lecture_area.html#how-many-states-are-there-in-this-dataset",
    "title": "Methods for Area Unit Data",
    "section": "How many states are there in this dataset",
    "text": "How many states are there in this dataset\n\nsouth_gdf.STATE_NAME.unique().shape\n\n(17,)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#how-many-counties",
    "href": "lectures/week04/lecture_area.html#how-many-counties",
    "title": "Methods for Area Unit Data",
    "section": "How many counties?",
    "text": "How many counties?\n\nsouth_gdf.shape[0]\n\n1412",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#how-many-counties-in-each-state",
    "href": "lectures/week04/lecture_area.html#how-many-counties-in-each-state",
    "title": "Methods for Area Unit Data",
    "section": "How many counties in each state?",
    "text": "How many counties in each state?\n\nsouth_gdf.groupby(by='STATE_NAME').count()\n\n\n\n\n\n\n\n\nNAME\nSTATE_FIPS\nCNTY_FIPS\nFIPS\nSTFIPS\nCOFIPS\nFIPSNO\nSOUTH\nHR60\nHR70\n...\nBLK90\nGI59\nGI69\nGI79\nGI89\nFH60\nFH70\nFH80\nFH90\ngeometry\n\n\nSTATE_NAME\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nArkansas\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n...\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n\n\nDelaware\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n...\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n\n\nDistrict of Columbia\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\nFlorida\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nGeorgia\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n...\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n\n\nKentucky\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n...\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n\n\nLouisiana\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n...\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n\n\nMaryland\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n...\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n\n\nMississippi\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n...\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n\n\nNorth Carolina\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n...\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n\n\nOklahoma\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n...\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n\n\nSouth Carolina\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n...\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n\n\nTennessee\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n...\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n\n\nTexas\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n...\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n\n\nVirginia\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n...\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n\n\nWest Virginia\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n...\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n\n\n\n\n17 rows × 69 columns",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#which-state-had-the-highest-median-county-homicide-rate-in-1960",
    "href": "lectures/week04/lecture_area.html#which-state-had-the-highest-median-county-homicide-rate-in-1960",
    "title": "Methods for Area Unit Data",
    "section": "Which state had the highest median county homicide rate in 1960?",
    "text": "Which state had the highest median county homicide rate in 1960?\n\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').median()\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n9.623977\n\n\nArkansas\n4.704111\n\n\nDelaware\n4.228385\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n9.970306\n\n\nGeorgia\n9.300076\n\n\nKentucky\n5.235436\n\n\nLouisiana\n6.840286\n\n\nMaryland\n5.335208\n\n\nMississippi\n8.919274\n\n\nNorth Carolina\n7.633043\n\n\nOklahoma\n4.269126\n\n\nSouth Carolina\n7.509437\n\n\nTennessee\n4.877751\n\n\nTexas\n4.326215\n\n\nVirginia\n6.672004\n\n\nWest Virginia\n2.623226",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#which-county-had-the-highest-maximum-county-homicide-rate-in-1960",
    "href": "lectures/week04/lecture_area.html#which-county-had-the-highest-maximum-county-homicide-rate-in-1960",
    "title": "Methods for Area Unit Data",
    "section": "Which county had the highest maximum county homicide rate in 1960?",
    "text": "Which county had the highest maximum county homicide rate in 1960?\n\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').max()\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n24.903499\n\n\nArkansas\n21.154427\n\n\nDelaware\n7.286472\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n40.744262\n\n\nGeorgia\n53.304904\n\n\nKentucky\n37.250885\n\n\nLouisiana\n18.243736\n\n\nMaryland\n14.327234\n\n\nMississippi\n24.833923\n\n\nNorth Carolina\n25.660127\n\n\nOklahoma\n17.088175\n\n\nSouth Carolina\n23.345940\n\n\nTennessee\n20.894275\n\n\nTexas\n92.936803\n\n\nVirginia\n23.575639\n\n\nWest Virginia\n11.482375",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#intra-state-dispersion",
    "href": "lectures/week04/lecture_area.html#intra-state-dispersion",
    "title": "Methods for Area Unit Data",
    "section": "Intra-state dispersion",
    "text": "Intra-state dispersion\n\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n4.742337\n\n\nArkansas\n4.574625\n\n\nDelaware\n1.815562\n\n\nDistrict of Columbia\nNaN\n\n\nFlorida\n7.990692\n\n\nGeorgia\n7.906488\n\n\nKentucky\n6.354316\n\n\nLouisiana\n4.189146\n\n\nMaryland\n4.064360\n\n\nMississippi\n4.972698\n\n\nNorth Carolina\n4.596952\n\n\nOklahoma\n4.231132\n\n\nSouth Carolina\n4.018644\n\n\nTennessee\n4.354979\n\n\nTexas\n8.223844\n\n\nVirginia\n4.826707\n\n\nWest Virginia\n2.773659\n\n\n\n\n\n\n\n\nsgdf = south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\ncv = sgdf / south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').mean() * 100\n\n\ncv.sort_values(by='HR60', ascending=False)\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nTexas\n144.992919\n\n\nKentucky\n96.815524\n\n\nWest Virginia\n93.234007\n\n\nArkansas\n81.223752\n\n\nOklahoma\n81.114430\n\n\nTennessee\n75.426226\n\n\nGeorgia\n73.774440\n\n\nMaryland\n71.898559\n\n\nFlorida\n68.252692\n\n\nVirginia\n66.924041\n\n\nLouisiana\n59.994571\n\n\nMississippi\n57.457024\n\n\nNorth Carolina\n57.013871\n\n\nAlabama\n49.070812\n\n\nSouth Carolina\n48.083524\n\n\nDelaware\n34.966796\n\n\nDistrict of Columbia\nNaN",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#recap-of-key-points",
    "href": "lectures/week04/lecture_area.html#recap-of-key-points",
    "title": "Methods for Area Unit Data",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinition of Area Unit Data\nObjectives of Area Unit Data Analysis\nArea Unit Data in Python",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#questions",
    "href": "lectures/week04/lecture_area.html#questions",
    "title": "Methods for Area Unit Data",
    "section": "Questions",
    "text": "Questions",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#references",
    "href": "lectures/week04/lecture_area.html#references",
    "title": "Methods for Area Unit Data",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nLongley, Paul A, and James A Cheshire. 2017. “Geographical Information Systems.” In The Routledge Handbook of Mapping and Cartography, 251–58. Routledge.",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#data-definitions",
    "href": "lectures/week04/04-spatial-data.html#data-definitions",
    "title": "Spatial Data",
    "section": "Data Definitions",
    "text": "Data Definitions\n\nfacts and statistics collected together for reference or analysis\n\n\nthe quantities, characters, or symbols on which operations are performed by a computer, being stored and transmitted in the form of electrical signals and recorded on magnetic, optical, or mechanical recording media.\n\n\nthings known or assumed as facts, making the basis of reasoning or calculate\n\nSource: Oxford languages"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#datas-place",
    "href": "lectures/week04/04-spatial-data.html#datas-place",
    "title": "Spatial Data",
    "section": "Data’s Place",
    "text": "Data’s Place\n\n\n\n\n\nDIKW Pyramid\n\n\n\n\ndata: discrete facts, unorganized and lacking context or information\ninformation: data imbued with meaning - what is in the data\nknowledge: perception of the world seen through information synthesis\nwisdom: “knowing the right things to do”"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#data-sets",
    "href": "lectures/week04/04-spatial-data.html#data-sets",
    "title": "Spatial Data",
    "section": "Data Sets",
    "text": "Data Sets\nA data set is a collection of observations recorded for individual units on a set of variables.\nVariables are sometimes referred to as attributes or features (in machine learning parlance)."
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#measurement-scales",
    "href": "lectures/week04/04-spatial-data.html#measurement-scales",
    "title": "Spatial Data",
    "section": "Measurement Scales",
    "text": "Measurement Scales\n\n\n\nScale\nOperations\nExample\n\n\n\n\nnominal\nmode, frequencies\nZip Code\n\n\nordinal\nA &gt; B\nRanks, Primary, Intermediate\n\n\ninterval\n+ -\nTime\n\n\nratio\n+ - * /\nWeight, Kelvin"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-data-is-special",
    "href": "lectures/week04/04-spatial-data.html#spatial-data-is-special",
    "title": "Spatial Data",
    "section": "Spatial Data is Special",
    "text": "Spatial Data is Special\n\nSpatial data comes in many varieties and it is not easy to arrive at a system of classification that is simultaneously exclusive, exhaustive, imaginative, and satisfying.\n\n– G. Upton & B. Fingleton"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#what-is-special-about-spatial-data-1",
    "href": "lectures/week04/04-spatial-data.html#what-is-special-about-spatial-data-1",
    "title": "Spatial Data",
    "section": "What is special about spatial data?",
    "text": "What is special about spatial data?\nLocation, Location, Location\nwhere matters\nDependence is the rule, not the exception\n\nspatial interaction, contagion, spill-overs\nspatial externalities\n\nSpatial Scale\n\nInference can change with scale"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#nature-of-spatial-data",
    "href": "lectures/week04/04-spatial-data.html#nature-of-spatial-data",
    "title": "Spatial Data",
    "section": "Nature of Spatial Data",
    "text": "Nature of Spatial Data\nGeoreferences\nattribute data together with location\nGeocoding\n\nassociate observations with location\npoint: latitude-longtitude (GPS)\nareal unit: spatial reference"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geocoding-on-line",
    "href": "lectures/week04/04-spatial-data.html#geocoding-on-line",
    "title": "Spatial Data",
    "section": "Geocoding on-line",
    "text": "Geocoding on-line\n\nGeocode Input"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geocoding-on-line-1",
    "href": "lectures/week04/04-spatial-data.html#geocoding-on-line-1",
    "title": "Spatial Data",
    "section": "Geocoding on-line",
    "text": "Geocoding on-line\n\nGeocode Output"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#on-the-map",
    "href": "lectures/week04/04-spatial-data.html#on-the-map",
    "title": "Spatial Data",
    "section": "On the Map?",
    "text": "On the Map?\n\nMap of Geocode Output"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#on-the-map-1",
    "href": "lectures/week04/04-spatial-data.html#on-the-map-1",
    "title": "Spatial Data",
    "section": "On the Map?",
    "text": "On the Map?\n\nErrors in Geocode Output"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#location",
    "href": "lectures/week04/04-spatial-data.html#location",
    "title": "Spatial Data",
    "section": "Location",
    "text": "Location\n\nGiven: in most spatial data analysis, no choice in location\nNo sampling in the usual sense\nData = attributes augmented with locational information"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-effects",
    "href": "lectures/week04/04-spatial-data.html#spatial-effects",
    "title": "Spatial Data",
    "section": "Spatial Effects",
    "text": "Spatial Effects\nThe Trilogy\n\nSpatial Dependence\nSpatial Heterogeneity\nSpatial Scale"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-dependence",
    "href": "lectures/week04/04-spatial-data.html#spatial-dependence",
    "title": "Spatial Data",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\nTobler’s First Law of Geography\n\n“everything depends on everything else, but closer things more so”\n\n\nStructure of spatial dependence\nDistance Decay\nCloseness = Similarity"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-heterogenety",
    "href": "lectures/week04/04-spatial-data.html#spatial-heterogenety",
    "title": "Spatial Data",
    "section": "Spatial Heterogenety",
    "text": "Spatial Heterogenety\nSpatial Instability\n\nProcess varies in some way over spatial units\nMultiple forms\n\nDiscrete = regimes\nContinuous = expansion method, GWR\n\nTrade-off\n\nSpatial homogeneity = stationary process\nUniqueness = extreme heterogeneity"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-scale-1",
    "href": "lectures/week04/04-spatial-data.html#spatial-scale-1",
    "title": "Spatial Data",
    "section": "Spatial Scale",
    "text": "Spatial Scale\nMismatch\n\nSpatial scale of the process\nSpatial scale of our measurement\n\nIssues\n\npoints too far apart = miss small distance variation\narea aggregates cannot provide information on individual behavior\nEcological Fallacy"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week04/04-spatial-data.html#modifiable-areal-unit-problem-maup",
    "title": "Spatial Data",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\nAggregation Problem\n\nspecial case of ecological fallacy\na million correlation coefficients\n\nZonation Problem\n\nsize\narangement\nHow many ways could you partition the coterminous US land area into 48 polygons?"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#maup-zonation-problem",
    "href": "lectures/week04/04-spatial-data.html#maup-zonation-problem",
    "title": "Spatial Data",
    "section": "MAUP Zonation Problem",
    "text": "MAUP Zonation Problem\n\nhttp://en.wikipedia.org/wiki/Modifiable_areal_unit_problem"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#maup-aggregation-problem",
    "href": "lectures/week04/04-spatial-data.html#maup-aggregation-problem",
    "title": "Spatial Data",
    "section": "MAUP Aggregation Problem",
    "text": "MAUP Aggregation Problem\n\n\n\n\n\nhttp://en.wikipedia.org/wiki/Modifiable_areal_unit_problem\n\n\n\n\nTrue rate = 1/3 = 33%\nA’s rate = (0 +1/2) /2 = 25%\nA’s weighted rate = 1/3 * 0 + 2/3 * 50 = 33%\nB’s rate = (0 + 100) /2 = 50%\nB’s weighted rate = 2/3 * 0 + 1/3 * 100 = 33%"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-process",
    "href": "lectures/week04/04-spatial-data.html#spatial-process",
    "title": "Spatial Data",
    "section": "Spatial Process",
    "text": "Spatial Process\nSpatial Random Field\na mathemtical construct to capture randomness of values distributed over space\n\\[\\{Z(s):s \\in D \\} \\]\n\n\\(s \\in R^d:\\) location (e.g., lat-lon)\n\\(D \\in R^d:\\) index set = possible locations\n\\(Z(s):\\) random variable at location \\(s\\)"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#types-of-spatial-data-1",
    "href": "lectures/week04/04-spatial-data.html#types-of-spatial-data-1",
    "title": "Spatial Data",
    "section": "Types of Spatial Data",
    "text": "Types of Spatial Data\n\nEvents\n\naddresses of crimes\n\nDiscrete Spatial Objects\n\ncounty crime rates\n\nContinuous surfaces\n\nair quality\nrainfall"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-pattern-analysis",
    "href": "lectures/week04/04-spatial-data.html#point-pattern-analysis",
    "title": "Spatial Data",
    "section": "Point Pattern Analysis",
    "text": "Point Pattern Analysis\nData\n\nmapped pattern = all the values\nnot a sample in the usual sense\n\nSpatial Process\n\nobservations as a realization of a random point process\npoints occur in space according to a mathematical model"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-patterns",
    "href": "lectures/week04/04-spatial-data.html#point-patterns",
    "title": "Spatial Data",
    "section": "Point Patterns",
    "text": "Point Patterns\nUnmarked Point Pattern\n\nonly location is recorded\nno other attribute information\n\nMarked Point Pattern\n\nLocation is recorded\nStochastic attributes are also recorded\ne.g., sales price at address, DBH of a tree"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-pattern-analysis-quadrat-methods",
    "href": "lectures/week04/04-spatial-data.html#point-pattern-analysis-quadrat-methods",
    "title": "Spatial Data",
    "section": "Point Pattern Analysis: Quadrat Methods",
    "text": "Point Pattern Analysis: Quadrat Methods\n\nQuadrat Analysis"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-pattern-analysis-distance-based-methods",
    "href": "lectures/week04/04-spatial-data.html#point-pattern-analysis-distance-based-methods",
    "title": "Spatial Data",
    "section": "Point Pattern Analysis: Distance Based Methods",
    "text": "Point Pattern Analysis: Distance Based Methods\n\nDistance Distributions"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#areal-unit-data-lattice",
    "href": "lectures/week04/04-spatial-data.html#areal-unit-data-lattice",
    "title": "Spatial Data",
    "section": "Areal Unit Data (Lattice)",
    "text": "Areal Unit Data (Lattice)\n\nSpatial Domain: \\(D\\)\n\nDiscrete and fixed\nLocations nonrandom\nLocations countable\n\n\n\nExamples of lattice data\n\nAttributes collected by ZIP code\ncensus tract"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#lattice-data-indexing",
    "href": "lectures/week04/04-spatial-data.html#lattice-data-indexing",
    "title": "Spatial Data",
    "section": "Lattice Data: Indexing",
    "text": "Lattice Data: Indexing\n\nSite\n\nEach location is now an area or site\nOne observation on \\(Z\\) for each site\nNeed a spatial index: \\(Z(s_i)\\)\n\n\n\n\\(Z(s_i)\\)\n\n\\(s_i\\) is a representative location within the site\ne.g., centroid, largest city\nAllows for measuring distances between sites"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#lattice-data-county-per-capita-incomes",
    "href": "lectures/week04/04-spatial-data.html#lattice-data-county-per-capita-incomes",
    "title": "Spatial Data",
    "section": "Lattice Data: County Per Capita Incomes",
    "text": "Lattice Data: County Per Capita Incomes\n\n1969"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-analysis",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-analysis",
    "title": "Spatial Data",
    "section": "Geostatistical Analysis",
    "text": "Geostatistical Analysis\n\nSpatial Domain: \\(D\\)\n\nA continuous and fixed set.\nMeaning \\(Z(s)\\) can be observed everywhere within \\(D\\).\nBetween any two sample locations \\(s_i\\) and \\(s_j\\) you can theoretically place an infinite number of other samples.\nBy fixed: the points in \\(D\\) are non-stochastic"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data",
    "title": "Spatial Data",
    "section": "Geostatistical Data",
    "text": "Geostatistical Data\n\nContinuous Variation\n\nBecause of the continuity of \\(D\\)\nGeostatistical data is referred to as “spatial data with continuous variation.”\nContinuity is associated with \\(D\\).\nAttribute \\(Z\\) may, or may not, be continuous."
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-monitoring-sites",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-monitoring-sites",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Monitoring Sites",
    "text": "Geostatistical Data: Monitoring Sites\n\nSites"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Surface Reconstruction",
    "text": "Geostatistical Data: Surface Reconstruction\n\nTessellation"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-1",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-1",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Surface Reconstruction",
    "text": "Geostatistical Data: Surface Reconstruction\n\nInterpolation"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-2",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-2",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Surface Reconstruction",
    "text": "Geostatistical Data: Surface Reconstruction\n\nKriging"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#network-data",
    "href": "lectures/week04/04-spatial-data.html#network-data",
    "title": "Spatial Data",
    "section": "Network Data",
    "text": "Network Data\n\n\nA network is a system of linear features connected at intersections and interchanges.\nThese intersections and interchanges are called nodes.\nThe linear feature connecting any given pair of nodes is called an arc.\nFormally, a network is defined as a directed graph \\(G = (N,\n      A)\\) consisting of an indexed set of nodes \\(N\\) with \\(n = |N|\\) and a spanning set of directed arcs \\(A\\) with \\(m = |A|\\), where \\(n\\) is the number of nodes and \\(m\\) is the number of arcs.\nEach arc on a network is represented as an ordered pair of nodes, in the form from node \\(i\\) to node \\(j\\), denoted by \\((i, j)\\)."
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#network-data-1",
    "href": "lectures/week04/04-spatial-data.html#network-data-1",
    "title": "Spatial Data",
    "section": "Network Data",
    "text": "Network Data\n\nStreet Network"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#flow-data",
    "href": "lectures/week04/04-spatial-data.html#flow-data",
    "title": "Spatial Data",
    "section": "Flow Data",
    "text": "Flow Data\n\nFlows"
  },
  {
    "objectID": "lectures/week08/local.html",
    "href": "lectures/week08/local.html",
    "title": "Local Spatial Autocorrelation",
    "section": "",
    "text": "In today’s lecture, we will delve into the concept of local spatial autocorrelation, an essential tool in geographic data science that allows us to explore spatial patterns at a more granular level. While global measures like Moran’s I provide an overall summary of spatial autocorrelation across an entire region, local spatial autocorrelation helps identify specific areas where values cluster or where unusual spatial patterns emerge. By examining local indicators of spatial association (LISA), we can detect hotspots, cold spots, and outliers, which are critical for understanding localized spatial phenomena. This approach is particularly valuable in fields like public health, urban studies, and environmental monitoring, where localized insights can inform targeted interventions.\nWe first review the basics of global spatial autocorrelation and then take a deeper dive into local spatial autocorrelation.",
    "crumbs": [
      "Home",
      "10-14 Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week08/local.html#imports",
    "href": "lectures/week08/local.html#imports",
    "title": "Local Spatial Autocorrelation",
    "section": "Imports",
    "text": "Imports\n\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport esda\nimport libpysal as lps\nimport contextily as cx\n\n\nimport seaborn as sns\nsns.set_context('notebook')\n%matplotlib inline\nimport warnings\nwarnings.simplefilter(\"ignore\")",
    "crumbs": [
      "Home",
      "10-14 Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week08/local.html#data",
    "href": "lectures/week08/local.html#data",
    "title": "Local Spatial Autocorrelation",
    "section": "Data",
    "text": "Data\nFor this exercise, we’ll use two datasets:\n\na set of polygons (census tracts) for the city of San Diego from the US Census American Community Survey 5-year estimates.\n\n\nCensus Polygons\n\nscag = gpd.read_parquet(\"~/data/scag_region.parquet\")\n\n\nsan_diego = scag[scag.geoid.str[:5]=='06073']\n\n\nsan_diego.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nIndex: 627 entries, 158 to 4567\nColumns: 194 entries, geoid to geometry\ndtypes: float64(191), geometry(1), int64(1), object(1)\nmemory usage: 955.2+ KB\n\n\n\nsan_diego = san_diego.dropna(subset=['median_home_value'])\n\n\nsan_diego = san_diego.to_crs(epsg=3857)\n\n\nf, ax = plt.subplots(figsize=(10,10))\n\nsan_diego.plot('median_home_value', ax=ax, alpha=0.6)\ncx.add_basemap(ax, crs=san_diego.crs.to_string(), source=cx.providers.CartoDB.Positron)\nax.axis('off')\n\n(np.float64(-13099175.999157175),\n np.float64(-12913655.059545828),\n np.float64(3827188.049586126),\n np.float64(3968975.95342782))\n\n\n\n\n\n\n\n\n\n\nsan_diego.median_home_value.hist()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(12,12))\n\nsan_diego.dropna(subset=['median_home_value']).to_crs(epsg=3857).plot('median_home_value', legend=True, scheme='quantiles', cmap='GnBu', k=5, ax=ax, alpha=0.7)\n\ncx.add_basemap(ax, crs=san_diego.crs.to_string(), source=cx.providers.CartoDB.Positron)\nax.axis('off')\n\nplt.title(\"Median Home Value (Quintiles)\", fontsize=16)\n\nplt.axis('off')\nplt.tight_layout()",
    "crumbs": [
      "Home",
      "10-14 Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week08/local.html#global-spatial-autocorrelation",
    "href": "lectures/week08/local.html#global-spatial-autocorrelation",
    "title": "Local Spatial Autocorrelation",
    "section": "Global Spatial Autocorrelation",
    "text": "Global Spatial Autocorrelation\nVisual inspection of the map pattern for the prices allows us to search for spatial structure. If the spatial distribution of the prices was random, then we should not see any clustering of similar values on the map. However, our visual system is drawn to the darker clusters along the coast, and a concentration of the lighter hues (lower prices) in the north central and south east. In the point data, the trees are too dense to make any sense of the pattern\nOur brains are very powerful pattern recognition machines. However, sometimes they can be too powerful and lead us to detect false positives, or patterns where there are no statistical patterns. This is a particular concern when dealing with visualization of irregular polygons of differning sizes and shapes.\nThe concept of spatial autocorrelation relates to the combination of two types of similarity: spatial similarity and attribute similarity. Although there are many different measures of spatial autocorrelation, they all combine these two types of simmilarity into a summary measure.\nLet’s use PySAL to generate these two types of similarity measures.\n\nSpatial Similarity\nWe have already encountered spatial weights in a previous notebook. In spatial autocorrelation analysis, the spatial weights are used to formalize the notion of spatial similarity. As we have seen there are many ways to define spatial weights, here we will use queen contiguity:\n\nwq =  lps.weights.Queen.from_dataframe(san_diego)\nwq.transform = 'r'\n\n\n\nAttribute Similarity\nSo the spatial weight between neighborhoods \\(i\\) and \\(j\\) indicates if the two are neighbors (i.e., geographically similar). What we also need is a measure of attribute similarity to pair up with this concept of spatial similarity. The spatial lag is a derived variable that accomplishes this for us. For neighborhood \\(i\\) the spatial lag is defined as: \\[ylag_i = \\sum_j w_{i,j} y_j\\]\n\ny = san_diego['median_home_value']\nylag = lps.weights.lag_spatial(wq, y)\n\n\nf, ax = plt.subplots(1, figsize=(12, 12))\n\nsan_diego.assign(cl=ylag).plot(column='cl', scheme='quantiles', \\\n        k=5, cmap='GnBu', linewidth=0.1, ax=ax, \\\n        edgecolor='white', legend=True)\n\ncx.add_basemap(ax, crs=san_diego.crs.to_string(), source=cx.providers.CartoDB.Positron)\nax.axis('off')\n\nplt.title(\"Spatial Lag Median Home Val (Quintiles)\", fontsize=16)\n\nplt.show()\n\n\n\n\n\n\n\n\nThe quintile map for the spatial lag tends to enhance the impression of value similarity in space. It is, in effect, a local smoother.\n\nsan_diego['lag_median_pri'] = ylag\n\nf,ax = plt.subplots(1,2,figsize=(12,4))\n\nsan_diego.plot(column='median_home_value', ax=ax[0],\n        scheme=\"quantiles\",  k=5, cmap='GnBu')\n\n#ax[0].axis(san_diego.total_bounds[np.asarray([0,2,1,3])])\nax[0].set_title(\"Price\", fontsize=16)\n\nsan_diego.plot(column='lag_median_pri', ax=ax[1],\n        scheme='quantiles', cmap='GnBu', k=5)\n\ncx.add_basemap(ax[0], crs=san_diego.crs.to_string(), source=cx.providers.CartoDB.Positron)\n\ncx.add_basemap(ax[1], crs=san_diego.crs.to_string(), source=cx.providers.CartoDB.Positron)\n\nax[1].set_title(\"Spatial Lag Price\", fontsize=16)\nax[0].axis('off')\nax[1].axis('off')\n\nplt.show()\n\n\n\n\n\n\n\n\nHowever, we still have the challenge of visually associating the value of the prices in a neighborhod with the value of the spatial lag of values for the focal unit. The latter is a weighted average of home prices in the focal county’s neighborhood.\nTo complement the geovisualization of these associations we can turn to formal statistical measures of spatial autocorrelation.\n\n\nTesting for Global Spatial Autocorrelation\n\nJoin counts\nOne way to formalize a test for spatial autocorrelation in a binary attribute is to consider the so-called joins. A join exists for each neighbor pair of observations, and the joins are reflected in our binary spatial weights object wq.\nEach unit can take on one of two values “Black” or “White”, analogous to the layout of a chessboard\n\nnrows, ncols = 9,9\nimage = np.zeros(nrows*ncols)\n\n# Set every other cell to 1\nimage[::2] = 1\n\n# Reshape things into a 9x9 grid.\nimage = image.reshape((nrows, ncols))\nplt.matshow(image, cmap='Greys')\nplt.axis('off')\nplt.show()\n\n\n\n\n\n\n\n\nand so for a given pair of neighboring locations there are three different types of joins that can arise:\n\nBlack Black (BB)\nWhite White (WW)\nBlack White (or White Black) (BW)\n\nWe can use the esda package from PySAL to carry out join count analysis. In the case of our point data, the join counts can help us determine whether different varieties of trees tend to grow together, spread randomly through space, or compete with one another for precious resources\n\n\nPolygon Data\nWith polygon data, we can conduct an analysis using a contiguity matrix. For our housing price data, we need to first discretize the variable we’re using; to keep things simple, we’ll binarize our price data using the median so that “high” values are tracts whose median home price is above the city’s median and “low” values are those below\n\ny.median()\n\nnp.float64(405416.57303370786)\n\n\n\nsan_diego.shape\n\n(627, 195)\n\n\n\nyb = y &gt; y.median()\nsum(yb)\n\n313\n\n\n\nyb = y &gt; y.median()\nlabels = [\"0 Low\", \"1 High\"]\nyb = [labels[i] for i in 1*yb] \nsan_diego['yb'] = yb\n\n\nfig, ax = plt.subplots(figsize=(12,12))\nsan_diego.plot(column='yb', cmap='binary', edgecolor='grey', legend=True, ax=ax)\n\n\n\n\n\n\n\n\nThe spatial distribution of the binary variable immediately raises questions about the juxtaposition of the “black” and “white” areas.\nGiven that we have 308 Black polygons on our map, what is the number of Black Black (BB) joins we could expect if the process were such that the Black polygons were randomly assigned on the map?\n\nyb = 1 * (y &gt; y.median()) # convert back to binary\nwq =  lps.weights.Queen.from_dataframe(san_diego)\nwq.transform = 'b'\nnp.random.seed(12345)\njc = esda.join_counts.Join_Counts(yb, wq)\n\nThe resulting object stores the observed counts for the different types of joins:\n\njc.bb\n\nnp.float64(754.0)\n\n\n\njc.ww\n\nnp.float64(745.0)\n\n\n\njc.bw\n\nnp.float64(475.0)\n\n\nNote that the three cases exhaust all possibilities:\n\njc.bb + jc.ww + jc.bw\n\nnp.float64(1974.0)\n\n\nand\n\nwq.s0 / 2\n\nnp.float64(1974.0)\n\n\nwhich is the unique number of joins in the spatial weights object.\nOur object tells us we have observed 736 BB joins:\n\njc.bb\n\nnp.float64(754.0)\n\n\nThe critical question for us, is whether this is a departure from what we would expect if the process generating the spatial distribution of the Black polygons were a completely random one? To answer this, PySAL uses random spatial permutations of the observed attribute values to generate a realization under the null of complete spatial randomness (CSR). This is repeated a large number of times (999 default) to construct a reference distribution to evaluate the statistical significance of our observed counts.\nThe average number of BB joins from the synthetic realizations is:\n\njc.mean_bb\n\nnp.float64(490.03103103103103)\n\n\nwhich is less than our observed count. The question is whether our observed value is so different from the expectation that we would reject the null of CSR?\n\nimport seaborn as sbn\nsbn.kdeplot(jc.sim_bb, shade=True)\nplt.vlines(jc.bb, 0, 0.005, color='r')\nplt.vlines(jc.mean_bb, 0,0.005)\nplt.xlabel('BB Counts')\n\nText(0.5, 0, 'BB Counts')\n\n\n\n\n\n\n\n\n\nThe density portrays the distribution of the BB counts, with the black vertical line indicating the mean BB count from the synthetic realizations and the red line the observed BB count for our prices. Clearly our observed value is extremely high. A pseudo p-value summarizes this:\n\njc.p_sim_bb\n\nnp.float64(0.001)\n\n\nSince this is below conventional significance levels, we would reject the null of complete spatial randomness in favor of spatial autocorrelation in market prices.\n\n\nContinuous Case\nThe join count analysis is based on a binary attribute, which can cover many interesting empirical applications where one is interested in presence and absence type phenomena. In our case, we artificially created the binary variable, and in the process we throw away a lot of information in our originally continuous attribute. Turning back to the original variable, we can explore other tests for spatial autocorrelation for the continuous case.\nFirst, we transform our weights to be row-standardized, from the current binary state:\n\nwq.transform = 'r'\n\n\ny = san_diego['median_home_value']\n\nMoran’s I is a test for global autocorrelation for a continuous attribute:\n\nnp.random.seed(12345)\nmi = esda.moran.Moran(y, wq)\nmi.I\n\nnp.float64(0.660917168991019)\n\n\nAgain, our value for the statistic needs to be interpreted against a reference distribution under the null of CSR. PySAL uses a similar approach as we saw in the join count analysis: random spatial permutations.\n\nfrom splot.esda import plot_moran\nplot_moran(mi, zstandard=True, figsize=(10,4))\nplt.show()\n\n\n\n\n\n\n\n\n\nmi.p_sim\n\nnp.float64(0.001)\n\n\nOn the left, we have the reference distribution versus the observed statistic; on the right, we have a plot of the focal value against its spatial lag, for which the Moran I statistic serves as the slope\nHere our observed value is again in the upper tail\n\nmi.p_sim\n\nnp.float64(0.001)",
    "crumbs": [
      "Home",
      "10-14 Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week08/local.html#local-autocorrelation-hot-spots-cold-spots-and-spatial-outliers",
    "href": "lectures/week08/local.html#local-autocorrelation-hot-spots-cold-spots-and-spatial-outliers",
    "title": "Local Spatial Autocorrelation",
    "section": "Local Autocorrelation: Hot Spots, Cold Spots, and Spatial Outliers",
    "text": "Local Autocorrelation: Hot Spots, Cold Spots, and Spatial Outliers\nLocal autocorrelation statistics provide indications of spatial autocorrelation in a subset of the data. With \\(n\\) observations, there are \\(n\\) such subsets, with each subset consisting of a focal unit together with the neighbors of the focal unit.\nPySAL has many local autocorrelation statistics. Let’s compute a local Moran statistic for the same data\n\nwq.transform = 'r'\nlag_price = lps.weights.lag_spatial(wq, san_diego['median_home_value'])\n\n\nnp.random.seed(12345)\nli = esda.moran.Moran_Local(y, wq)\n\nNow, instead of a single \\(I\\) statistic, we have an array of local \\(I_i\\) statistics, stored in the .Is attribute, and p-values from the simulation are in p_sim.\n\nfrom splot.esda import moran_scatterplot\n\nfig, ax = moran_scatterplot(li)\nax.set_xlabel('Price')\nax.set_ylabel('Spatial Lag of Price')\nplt.show()\n\n\n\n\n\n\n\n\nWe can again test for local clustering using permutations, but here we use conditional random permutations (different distributions for each focal location)\n\n(li.p_sim &lt; 0.05).sum()\n\nnp.int64(246)\n\n\n\nfig, ax = moran_scatterplot(li, p=0.05)\nax.set_xlabel('Price')\nax.set_ylabel('Spatial Lag of Price')\nplt.show()\n\n\n\n\n\n\n\n\nWe can distinguish the specific type of local spatial association reflected in the four quadrants of the Moran Scatterplot above: - High-High (upper right) - Low-Low (bottom left) - High-Low (lower right) - Low-High (upper left)\nThis information is encoded in the q attribution of the Local Moran object:\n\nli.q\n\narray([4, 1, 2, 3, 3, 3, 3, 4, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n       3, 2, 3, 2, 2, 1, 1, 2, 3, 3, 3, 3, 3, 2, 1, 3, 3, 3, 2, 1, 1, 1,\n       3, 1, 3, 3, 4, 3, 1, 1, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 3, 1, 2,\n       2, 1, 2, 4, 3, 3, 4, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 3, 1, 1,\n       3, 3, 2, 2, 2, 1, 4, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 3, 2,\n       2, 4, 3, 3, 1, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 1, 1, 3,\n       1, 3, 3, 3, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 1,\n       1, 3, 3, 3, 3, 1, 1, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1,\n       1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 3, 3, 2, 3, 4, 4, 2, 3, 3, 3, 3, 3,\n       3, 3, 3, 3, 3, 1, 3, 3, 2, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 3, 3, 3, 4, 1, 3, 3, 1, 2, 4, 3, 3, 3, 3, 3, 3, 1, 2, 3, 2,\n       2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 1, 2, 4, 3, 3, 1, 3, 3, 3, 3, 3, 1,\n       3, 3, 3, 2, 1, 1, 1, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 4,\n       1, 1, 1, 1, 3, 1, 3, 4, 4, 4, 3, 2, 1, 1, 2, 3, 3, 2, 3, 4, 3, 3,\n       3, 3, 3, 4, 3, 3, 4, 1, 3, 3, 3, 4, 1, 3, 3, 3, 3, 3, 4, 4, 3, 2,\n       3, 3, 1, 1, 4, 4, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 1, 1, 2, 3, 4,\n       1, 1, 3, 3, 1, 3, 3, 3, 2, 3, 3, 3, 4, 3, 1, 3, 3, 2, 1, 2, 3, 3,\n       4, 3, 3, 3, 3, 1, 1, 1, 3, 3, 3, 1, 1, 3, 3, 4, 1, 1, 1, 1, 2, 1,\n       1, 2, 3, 3, 3, 3, 4, 2, 1, 1, 1, 1, 1, 3, 3, 3, 1, 1, 2, 4, 1, 3,\n       3, 3, 2, 1, 2, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 4, 2, 1, 1, 3, 3, 1,\n       3, 3, 3, 3, 3, 2, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 2, 1,\n       1, 1, 1, 3, 3, 3, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 3, 1, 1,\n       1, 1, 3, 1, 3, 3, 2, 3, 1, 1, 3, 3, 3, 3, 4, 2, 1, 1, 1, 2, 3, 1,\n       3, 3, 1, 1, 3, 3, 1, 2, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 1, 1, 1,\n       3, 3, 1, 4, 1, 3, 1, 2, 1, 3, 1, 3, 3, 3, 3, 4, 3, 3, 4, 1, 4, 3,\n       3, 3, 3, 2, 3, 1, 1, 4, 1, 1, 1, 1, 3, 3, 1, 3, 3, 2, 2, 3, 2, 4,\n       1, 1, 1, 1, 3, 3, 4, 1, 3, 1, 2, 3, 1, 1, 1, 1, 2, 2, 3, 3, 3, 1,\n       3, 2, 1, 1, 3, 1, 1, 3, 3, 1, 3, 1, 1, 1, 3, 3, 3, 3, 1, 3, 1, 4,\n       4, 3, 3, 3, 3, 3, 1, 3, 4, 3, 3])\n\n\n\nHot Spots\nThe local statistic can be used to identify so-called “hot spots”. To be a hot spot, a focal unit has to satisfy two conditions:\n\nIt is in the High-High quadrant of the Moran Scatter Plot\nIt has a statistically significant Local Moran\n\n\nhotspot = (li.p_sim &lt; 0.05) * (li.q==1)\nprint(f\"There are {hotspot.sum()} hot spots\")\n\nThere are 98 hot spots\n\n\n\n\nCold Spots\nA second type of positive local spatial autocorrelation occurs in the case of “cold spots”. To be a cold spot, a focal unit has to satisfy two conditions:\n\nIt is in the Low-Low quadrant of the Moran Scatter Plot\nIt has a statistically significant Local Moran\n\n\ncoldspot = (li.p_sim &lt; 0.05) * (li.q==3)\nprint(f\"There are {coldspot.sum()} cold spots\")\n\nThere are 143 cold spots\n\n\n\n\nSpatial Outliers\nWhile hot spots and cold spots reflect positive local spatial autocorrelation, we know that another departure from spatial randomness can occur: negative spatial autocorrelation. This is when the value dissimilarity between the focal unit and those of its neighbors is larger than what could be due to random chance.\nThere are two types of spatial outliers.\nA doughnut (the kind with a hole) is a spatial outlier where the focal unit is low, but the neighboring values are high. This would place the observation in quadrant 2 of the scatter plot (LH). The position is a necessary, but not sufficient, condition for being classified as a doughnut. The local Moran value must also be statistically significant.\n\ndoughnut = (li.p_sim &lt; 0.05) * (li.q==2)\nprint(f\"There are {doughnut.sum()} doughnuts\")\n\nThere are 5 doughnuts\n\n\nThe second type of spatial outlier is the “diamond in the rough”. Here the focal value is high, but the neighboring values are low, and the local Moran value is statistically significant:\n\ndiamond = (li.p_sim &lt; 0.05) * (li.q==4)\nprint(f\"There are {diamond.sum()} diamonds\")\n\nThere are 0 diamonds\n\n\nIn this case, we do not have any diamond observations, despite having\n\n(li.q==4).sum()\n\nnp.int64(44)\n\n\nobservations in the HL quadrant of the scatter plot. In other words, all 44 of these observations have local statistics that are not significantly different from their expectation under the null of spatial randomness.\n\n\nCluster Map\nUsing splot, we can also plot these hot spots, cold spots, and spatial outliers on the original geodataframe\n\nfrom splot.esda import lisa_cluster\nlisa_cluster(li, san_diego, p=0.05, figsize = (9,9))\nplt.show()\n\n\n\n\n\n\n\n\nThe cluster map displays the locations having a statistically significant LISA value together with a label for the quadrant of the scatter plot. All other locations are colored grey and labeled as “ns” (not significant).\n\nfrom splot.esda import plot_local_autocorrelation\nplot_local_autocorrelation(li, san_diego, 'median_home_value')\n\n(&lt;Figure size 1440x384 with 3 Axes&gt;,\n array([&lt;Axes: title={'center': 'Moran Local Scatterplot'}, xlabel='Attribute', ylabel='Spatial Lag'&gt;,\n        &lt;Axes: &gt;, &lt;Axes: &gt;], dtype=object))\n\n\n\n\n\n\n\n\n\nRecall that we now have \\(n\\) statistics, one for each location. This is in contrast to the case of global autocorrelation where there was one statistic for all \\(n\\) locations. We can thus examine the statistical significance of any location with the local indicators:\n\nnp.random.seed(12345)\n\nli = esda.moran.Moran_Local(y, wq, keep_simulations=True)\n\n\nli.p_sim[0:10]\n\narray([0.46 , 0.274, 0.46 , 0.046, 0.482, 0.475, 0.03 , 0.442, 0.203,\n       0.003])\n\n\n\nli.p_sim[9]\n\nnp.float64(0.003)\n\n\n\nnull = li.sim\nobserved = li.Is[9]\n\n\nnull = li.sim[626]\nobserved = li.Is[626]\nimport seaborn as sbn\nsbn.kdeplot(null, shade=True)\nplt.vlines(observed,0, 0.2, color='r')\nplt.xlabel(\"Local I for tract 9\")\n\nText(0.5, 0, 'Local I for tract 9')\n\n\n\n\n\n\n\n\n\n\n\nA note on spatial clusters\nIt is important to note that only the focal units are symbolized on the cluster map. Because the LISA tells us about the spatial association between the value at the focal unit and the values in its neighboring units, the temptation is to include the neighboring values together with the focal unit, if the latter is significant. This would, however, be misleading in the case of a significant focal unit who had neighbors, some of which had LISA values that were not significant.\nInstead, the focal unit with a significant LISA forms the seed of a cluster. When it is contiguous to a different focal unit with a significant LISA of the same form, the cluster will consist of multiple spatial units. Such a connected component is a spatial cluster in the fullest sense.\nWe can identify these spatial clusters in multiple steps.\nFirst, we will create a categorical variable to identify the cluster type. In general our encoding looks like:\n\nNot significant: 0\nHot spot: 1\nDoughnut: 2\nCold spot\nDiamond: 4\n\n\ncluster_type = hotspot * 1 + doughnut * 2 + coldspot * 3 + diamond * 4\nsan_diego['cluster_type'] = cluster_type\nsan_diego.groupby(by='cluster_type').count()\n\n\n\n\n\n\n\n\ngeoid\nn_asian_under_15\nn_black_under_15\nn_hispanic_under_15\nn_native_under_15\nn_white_under_15\nn_persons_under_18\nn_asian_over_60\nn_black_over_60\nn_hispanic_over_60\n...\np_nonhisp_white_persons\np_white_over_60\np_black_over_60\np_hispanic_over_60\np_native_over_60\np_asian_over_60\np_disabled\ngeometry\nlag_median_pri\nyb\n\n\ncluster_type\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n381\n381\n381\n381\n381\n381\n381\n0\n0\n0\n...\n381\n0\n0\n0\n0\n0\n0\n381\n381\n381\n\n\n1\n98\n98\n98\n98\n98\n98\n98\n0\n0\n0\n...\n98\n0\n0\n0\n0\n0\n0\n98\n98\n98\n\n\n2\n5\n5\n5\n5\n5\n5\n5\n0\n0\n0\n...\n5\n0\n0\n0\n0\n0\n0\n5\n5\n5\n\n\n3\n143\n143\n143\n143\n143\n143\n143\n0\n0\n0\n...\n143\n0\n0\n0\n0\n0\n0\n143\n143\n143\n\n\n\n\n4 rows × 196 columns\n\n\n\nNote that in our example, we did not encounter any diamons, so that cluster type is absent.\nWe will reset the index to facilitate later steps:\n\nsan_diego =san_diego.set_index('geoid')\n\nWe can now create a categorical map for our cluster types:\n\nsan_diego.explore(column='cluster_type', categorical=True,\n                  legend=True,\n                  tooltip=['geoid', 'cluster_type'])\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nTo determine the spatial clusters, we will consider the intersection of two neighbor graphs:\n\nQueen contiguity\nCluster\n\nThe second neighbor graph is constructed as follows:\n\nimport libpysal\nprint(libpysal.__version__)\ng = libpysal.graph.Graph.build_block_contiguity(san_diego.cluster_type)\nprint(san_diego.shape, g.n)\ng.plot(san_diego)\n\n4.12.1\n(627, 196) 627\n\n\n\n\n\n\n\n\n\nThis is a very dense graph, as any pair of polygons that fall in the same cluster type are considered to be neighbors.\nWe can get some useful summary information from this graph:\n\ng.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n627\n\n\nNumber of edges:\n174612\n\n\nNumber of connected components:\n4\n\n\nNumber of isolates:\n0\n\n\nNumber of non-zero edges:\n174612\n\n\nPercentage of non-zero edges:\n44.42%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n174612\nGG:\n174612\n\n\nS1:\n349224\nG'G:\n174612\n\n\nS3:\n235288056\nG'G + GG:\n349224\n\n\n\n\n            \n                Graph indexed by: ['06073014901', '06073000300', '06073000800', '0607301850...]\n            \n            \n\n\nThe key thing to note here is that the graph has 4 connected components. These correspond to the four cluster types in our map from above.\nWe can build a similar neighbor graph for our Queen contiguity neighbors:\n\ngq = libpysal.graph.Graph.build_contiguity(san_diego)\ngq.plot(san_diego)\n\n\n\n\n\n\n\n\nThis is less dense than the Cluster graph.\n\ngq.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n627\n\n\nNumber of edges:\n3376\n\n\nNumber of connected components:\n1\n\n\nNumber of isolates:\n0\n\n\nNumber of non-zero edges:\n3376\n\n\nPercentage of non-zero edges:\n0.86%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n3376\nGG:\n3376\n\n\nS1:\n6752\nG'G:\n3376\n\n\nS3:\n80192\nG'G + GG:\n6752\n\n\n\n\n            \n                Graph indexed by: ['06073014901', '06073000300', '06073000800', '0607300220...]\n            \n            \n\n\nNote that the Queen graph has a single connected component.\nWith these two graphs in hand, a spatial component will be defined as a connected component in the graph that is the intersection of these two graphs:\n\ngint = gq.intersection(g)\ngint.plot(san_diego)\n\n\n\n\n\n\n\n\n\ngint.summary()\n\n\n            \n\nGraph Summary Statistics\n\n\nNumber of nodes:\n627\n\n\nNumber of edges:\n2646\n\n\nNumber of connected components:\n27\n\n\nNumber of isolates:\n15\n\n\nNumber of non-zero edges:\n2646\n\n\nPercentage of non-zero edges:\n0.68%\n\n\nNumber of asymmetries:\nNA\n\n\n\n\n            \n\nSum of weights and Traces\n\n\nS0:\n2646\nGG:\n2646\n\n\nS1:\n5292\nG'G:\n2646\n\n\nS3:\n52952\nG'G + GG:\n5292\n\n\n\n\n            \n                Graph indexed by: ['06073014901', '06073000300', '06073000800', '0607300220...]\n            \n            \n\n\nWe can determine that there are 27 connected components in the intersection graph. This means that we have 27 spatial clusters.\nWe can assign the component labels from the intersection graph to our geodataframe and then explore the spatial distribution of these connected components:\n\nsan_diego['spatial_clusters'] = gint.component_labels\nsan_diego.explore(column='spatial_clusters', categorical=True, legend=True,\n                                                 tooltip=['cluster_type', 'spatial_clusters'])\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nBecause of the limitation of the number of unique colors available in geopandas’ current implementation, this makes it difficult to pull out each of the 27 different spatial clusters.\nTo get a better view of things, we can focus on the census tract with index 9 that we saw above:\n\nsan_diego.iloc[9]\n\nn_asian_under_15                                                     5.0\nn_black_under_15                                                    24.0\nn_hispanic_under_15                                                982.0\nn_native_under_15                                                   14.0\nn_white_under_15                                                   274.0\n                                             ...                        \ngeometry               POLYGON ((-13031716.599895265 3914330.02083623...\nlag_median_pri                                             238153.651685\nyb                                                                 0 Low\ncluster_type                                                           3\nspatial_clusters                                                       3\nName: 06073020206, Length: 197, dtype: object\n\n\nHere we see that is is of cluster type 3, and happens to be in the spatial cluster with the label 3.\nWe can view the intersection of the two graphs focusing on this particular tract as follows:\n\nm = san_diego.loc[gint['06073020206'].index].explore(color=\"#25b497\", tooltip=['cluster_type', 'spatial_clusters'])\nsan_diego.loc[['06073020206']].explore(m=m, color=\"#fa94a5\")\ngint.explore(san_diego, m=m, focal='06073020206', tooltip=['cluster_type', 'spatial_clusters'])\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nThis shows that the census tract has four neighbors.\nTo see where this actually is with respect to the set of clusters of type 3, we isolate on those:\n\nsan_diego[san_diego.cluster_type==3].explore() # cold-spots\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nAnd, now we can embed tract 9 and its neighbors in this wider context:\n\nm = san_diego[san_diego.cluster_type==3].explore(column='spatial_clusters', categorical=True, legend=True,\n                                                 tooltip=['cluster_type', 'spatial_clusters'])\ngint.explore(san_diego, m=m, focal='06073020206', tooltip=['cluster_type', 'spatial_clusters'])\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nCluster type 3 (cold spot) accounts for 7 of the 27 spatial clusters.",
    "crumbs": [
      "Home",
      "10-14 Local Spatial Autocorrelation"
    ]
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#outline",
    "href": "lectures/week07/spatial_dependence.html#outline",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Outline",
    "text": "Outline\n\nConcepts and Issues\nNull and Alternative Hypotheses\nSpatial Autocorrelation Tests"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-dependence",
    "href": "lectures/week07/spatial_dependence.html#spatial-dependence",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\n\nThere is no question with respect to emergent geospatial science. The important harbingers were Geary’s article on spatial autocorrelation, Dacey’s paper about two- and K-color maps, and that of Bachi on geographic series.\n– Berry, Griifth, Tiefelsdorf (2008)"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-dependence-1",
    "href": "lectures/week07/spatial_dependence.html#spatial-dependence-1",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\nWorking Concept\n\nwhat happens at one place depends on events in nearby places\nall things are related but nearby things are more related than distant things (Tobler)\ncentral focus in lattice data analysis"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#goodchild-1991",
    "href": "lectures/week07/spatial_dependence.html#goodchild-1991",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Goodchild 1991",
    "text": "Goodchild 1991\n\na world without positive spatial dependence would be an impossible world\nimpossible to describe\nimpossible to live in\nhell is a place with no spatial dependence"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-dependence-2",
    "href": "lectures/week07/spatial_dependence.html#spatial-dependence-2",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\nCategorizing\n\nType: Substantive versus nuisance\nDirection: Positive versus negative\n\nIssues\n\nTime versus space\nInference"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#substantive-spatial-dependence",
    "href": "lectures/week07/spatial_dependence.html#substantive-spatial-dependence",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Substantive Spatial Dependence",
    "text": "Substantive Spatial Dependence\nProcess Based\n\nPart of the process under study\nLeaving it out\n\nIncomplete understanding\nBiased inferences"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#nuisance-spatial-dependence",
    "href": "lectures/week07/spatial_dependence.html#nuisance-spatial-dependence",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Nuisance Spatial Dependence",
    "text": "Nuisance Spatial Dependence\nNot Process Based\n\nArtifact of data collection\nProcess boundaries not matching data boundaries\nScattering across pixels\nGIS induced"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#boundary",
    "href": "lectures/week07/spatial_dependence.html#boundary",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Boundary",
    "text": "Boundary"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#boundary-mismatch",
    "href": "lectures/week07/spatial_dependence.html#boundary-mismatch",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Boundary Mismatch",
    "text": "Boundary Mismatch\n\n\nEven if \\(A\\) and \\(B\\) are independent\n\\(A'\\) and \\(B'\\) will be dependent"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#nusiance-vs.-substantive-dependence",
    "href": "lectures/week07/spatial_dependence.html#nusiance-vs.-substantive-dependence",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Nusiance vs. Substantive Dependence",
    "text": "Nusiance vs. Substantive Dependence\nIssues\n\nNot always easy to differentiate from substantive\nDifferent implications for each type\nSpecification strategies (Econometrics)\nBoth can be operating jointly"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#space-versus-time",
    "href": "lectures/week07/spatial_dependence.html#space-versus-time",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Space versus Time",
    "text": "Space versus Time\nTemporal Dependence\n\nPast influences the future\nRecursive\nOne dimension"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#space-versus-time-1",
    "href": "lectures/week07/spatial_dependence.html#space-versus-time-1",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Space versus Time",
    "text": "Space versus Time\nSpatial Dependence\n\nMulti-directional\nSimultaneous"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#terminology",
    "href": "lectures/week07/spatial_dependence.html#terminology",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Terminology",
    "text": "Terminology\nRelated Concepts\n\nSpatial Dependence\nSpatial Autocorrelation\nSpatial Association"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-dependence-3",
    "href": "lectures/week07/spatial_dependence.html#spatial-dependence-3",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\nDistributional Characteristic\n\nMultivariate density function\ndifficult/impossible to verify empirically\n\nDependent Distribution\n\ndoes not factor in marginal densities"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-autocorrelation",
    "href": "lectures/week07/spatial_dependence.html#spatial-autocorrelation",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nAuto = same variable\nCorrelation = scaled covariance\nSpatial - geographic pattern to the correlation"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-1",
    "href": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-1",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\nMeasurement of Moment of Distribution\n\noff-diagonal elements of variance-covariance matrix\nautocovariance\n\\(C[y_i,y_j] \\ne 0 \\ \\forall i\\ne j\\)\ncan be estimated\n\nSpatial Autocorrelation Coefficient\n\nsignificance test on coefficient = 0"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-2",
    "href": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-2",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\nJoint multivariate distribution function \\[f(y) = \\frac{ \\exp\\left[\n-\\frac{1}{2}\n(y-\\mu)'\n\\Sigma^{-1}\n(y-\\mu)\n\\right]}\n{\\sqrt{(2\\pi)^n|\\Sigma|}}\\]"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#variance-covariance-matrix",
    "href": "lectures/week07/spatial_dependence.html#variance-covariance-matrix",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Variance-Covariance Matrix",
    "text": "Variance-Covariance Matrix\n\\[\\Sigma=\n\\left[\n\\begin{array}{rrrr}\n\\sigma_{1,1}&\\sigma_{1,2}&\\ldots&\\sigma_{1,n}\\\\\n\\sigma_{2,1}&\\sigma_{2,2}&\\ldots&\\sigma_{2,n}\\\\\n\\vdots&\\vdots&\\ddots&\\vdots\\\\\n\\sigma_{n,1}&\\sigma_{n,2}&\\ldots&\\sigma_{n,n}\n\\end{array}\n\\right]\\]\n\ncovariance: \\(\\sigma_{i,j} = E[(y_i - \\mu_i)(y_j-\\mu_j)      ]\\)\nsymmetry: \\(\\sigma_{i,j} =\\sigma_{i,j}\\)\nvariance: \\(\\sigma_{i,i} = E[(y_i - \\mu_i)(y_i-\\mu_i)      ]\\)"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#correlation",
    "href": "lectures/week07/spatial_dependence.html#correlation",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Correlation",
    "text": "Correlation\n\\[\\rho_{ij} = \\frac{\\sigma_{ij}}{\\sqrt{\\sigma_{i}^2}\\sqrt{\\sigma_{j}^2}}\\] \\[-1.0 \\le \\rho_{ij} \\le 1.0\\]"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#data-types-and-autocorrelation",
    "href": "lectures/week07/spatial_dependence.html#data-types-and-autocorrelation",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Data Types and Autocorrelation",
    "text": "Data Types and Autocorrelation\nPoint Data\n\nfocus on geometric pattern\nrandom vs. nonrandom\nclustered vs. uniform\n\nGeostatistics\n\n2-D modeling of spatial covariance (pairs of observations in function of distance)\nkriging, spatial prediction"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#data-types-and-autocorrelation-1",
    "href": "lectures/week07/spatial_dependence.html#data-types-and-autocorrelation-1",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Data Types and Autocorrelation",
    "text": "Data Types and Autocorrelation\nLattice Data\n\nareal units: states, counties, census tracts, watersheds\npoints: centroids of areal units\nfocus on the spatial nonrandomness of attribute values"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-association",
    "href": "lectures/week07/spatial_dependence.html#spatial-association",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Association",
    "text": "Spatial Association\nNot a Rigorously Defined Term\n\nUsually the same as spatial autocorrelation\noften used in non-technical discussion\navoid unless meaning is clear"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-dependence-4",
    "href": "lectures/week07/spatial_dependence.html#spatial-dependence-4",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\nGood News (for geographers)\n\nSpace matters\nSuggestive of underlying process\n\nBad news\n\ninvalidates random sampling assumption\nnecessitates new methods = spatial statistics and spatial econometrics"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-dependence-implications",
    "href": "lectures/week07/spatial_dependence.html#spatial-dependence-implications",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Dependence: Implications",
    "text": "Spatial Dependence: Implications\nThe specific process we are simulating is as follows:\\[\\begin{aligned}\n\\label{eq:simdgp}y&=&X\\beta + \\epsilon \\\\ \\nonumber\\epsilon &=& \\lambda W \\epsilon + \\nu  \\end{aligned}\\] where \\(\\nu^{\\sim}N(0,\\sigma^{2}I)\\), \\(\\lambda\\) is a spatial autocorrelation parameter (scalar) and \\(W\\) is a spatial weights matrix. If \\(\\lambda=0\\) then the \\(i.i.d.\\) assumption holds, otherwise there is spatial dependence.\n\\(\\beta=40, \\ \\sigma^2=16, \\ x=[1,1,\\ldots]\\)\n\\(\\lambda=[0.0, 0.25, 0.50, 0.75], \\ n=25\\)"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-dependence-implications-1",
    "href": "lectures/week07/spatial_dependence.html#spatial-dependence-implications-1",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Dependence: Implications",
    "text": "Spatial Dependence: Implications\nFor each D.G.P. we are going to generate 500 samples of size \\(n=25\\) for our map. You can think of this as generating 500 maps using the same D.G.P.. For each sample we will then do the following:\n\nEstimate \\(\\mu\\) with \\(\\bar{y}\\)\nTest the hypothesis that \\(\\mu=40\\)"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#implications",
    "href": "lectures/week07/spatial_dependence.html#implications",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Implications",
    "text": "Implications\n\n\nMonte Carlo Results\n\n\n\\(\\lambda\\)\n0.00\n0.25\n0.50\n0.75\n\n\n\n\n\\(\\hat{\\mu}\\)\n39.947\n39.931\n39.901\n39.814\n\n\n\\(\\sigma_{\\bar{x}}\\)\n0.816\n1.090\n1.641\n3.304\n\n\n\\(p\\)\n0.056\n0.148\n0.278\n0.492"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-randomness",
    "href": "lectures/week07/spatial_dependence.html#spatial-randomness",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Randomness",
    "text": "Spatial Randomness\nNull Hypothesis"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-on-a-grid",
    "href": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-on-a-grid",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Autocorrelation on a Grid",
    "text": "Spatial Autocorrelation on a Grid\n\nNegative, Random, Positive"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#positive-spatial-autocorrelation",
    "href": "lectures/week07/spatial_dependence.html#positive-spatial-autocorrelation",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Positive Spatial Autocorrelation",
    "text": "Positive Spatial Autocorrelation\nClustering\n\nlike values tend to be in similar locations\n\nNeighbor similarity\n\nmore alike than they would be under spatial randomness\n\nCompatible with Diffusion\n\nbut not necessarily caused by diffusion"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#positive-spatial-autocorrelation-1",
    "href": "lectures/week07/spatial_dependence.html#positive-spatial-autocorrelation-1",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Positive Spatial Autocorrelation",
    "text": "Positive Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#negative-spatial-autocorrelation",
    "href": "lectures/week07/spatial_dependence.html#negative-spatial-autocorrelation",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Negative Spatial Autocorrelation",
    "text": "Negative Spatial Autocorrelation\nCheckerboard pattern\n\nanti-clustering\n\nNeighbor dissimilarity\n\nmore dissimilar than they would be under spatial randomness\n\nCompatible with Competition\n\nbut not necessarily caused by competition"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#negative-spatial-autocorrelation-1",
    "href": "lectures/week07/spatial_dependence.html#negative-spatial-autocorrelation-1",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Negative Spatial Autocorrelation",
    "text": "Negative Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#autocorrelation-and-diffusion",
    "href": "lectures/week07/spatial_dependence.html#autocorrelation-and-diffusion",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Autocorrelation and Diffusion",
    "text": "Autocorrelation and Diffusion\nOne does not necessarily imply the other\n\ndiffusion tends to yield positive spatial autocorrelation but the reverse is not necessary\npositive spatial correlation may be due to structural factors, without contagion or diffusion"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#true-vs.-apparent-contagion",
    "href": "lectures/week07/spatial_dependence.html#true-vs.-apparent-contagion",
    "title": "Spatial Autocorrelation Concepts",
    "section": "True vs. Apparent Contagion",
    "text": "True vs. Apparent Contagion\nWhat is the Cause behind the clustering?\n\nTrue contagion\n\nresult of a contagious process, social interaction, dynamic process\n\nApparent contagion\n\nspatial heterogeneity\nstratification\n\nCannot be distinguished in a pure cross section\nEquifinality or Identification Problem"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#clustering",
    "href": "lectures/week07/spatial_dependence.html#clustering",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Clustering",
    "text": "Clustering\nGlobal characeristic\n\nproperty of overall pattern = all observations\nare like values more grouped in space than random\ntest by means of a global spatial autocorrelation statistic\nno location of the clusters determined"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#clusters",
    "href": "lectures/week07/spatial_dependence.html#clusters",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Clusters",
    "text": "Clusters\nLocal characeristic\n\nwhere are the like values more grouped in space than random?\nproperty of local pattern = location-specific\ntest by means of a local spatial autocorrelation statistic\nlocal clusters may be compatible with global spatial randomness"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-statistic",
    "href": "lectures/week07/spatial_dependence.html#spatial-autocorrelation-statistic",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Spatial Autocorrelation Statistic",
    "text": "Spatial Autocorrelation Statistic\nStructure\n\nFormal Test of Match between Value Similarity and Locational Similarity\nStatistic Summarizes Both Aspects\nSignificance\n\nhow likely is it (p-value) that the computed statistic would take this (extreme) value in a spatially random pattern"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#attribute-similarity",
    "href": "lectures/week07/spatial_dependence.html#attribute-similarity",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Attribute Similarity",
    "text": "Attribute Similarity\n\nSummary of the similarity or dissimilarity of a variable at different locations\n\nvariable \\(y\\) at locations \\(i,j\\) with \\(i\\ne j\\)\n\nMeasures of similarity\n\ncross product: \\(y_i y_j\\)\n\nMeasures of dissimilarity\n\nsquared differences: \\((y_i - y_j)^2\\)\nabsolute differences: \\(|y_i - y_j|\\)"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#locational-similarity",
    "href": "lectures/week07/spatial_dependence.html#locational-similarity",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Locational Similarity",
    "text": "Locational Similarity\n\nFormalizing the notion of Neighbor\n\nwhen two spatial units a-priori are likely to interact\n\nSpatial Weights\n\nnot necessarility geographical\nmany approaches"
  },
  {
    "objectID": "lectures/week07/spatial_dependence.html#summary",
    "href": "lectures/week07/spatial_dependence.html#summary",
    "title": "Spatial Autocorrelation Concepts",
    "section": "Summary",
    "text": "Summary\nSpatial Dependence\n\nCore of Lattice Analysis\nSpatial Autocorrelation More Complex than Temporal Autocorrelation\nCombine Value and Locational Similarities"
  },
  {
    "objectID": "lectures/week01/index.html",
    "href": "lectures/week01/index.html",
    "title": "Week 1 Lecture: Course Overview",
    "section": "",
    "text": "In this first lecture we will provide an overview of the course.",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/index.html#syllabus",
    "href": "lectures/week01/index.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/index.html#spatial-data-analysis",
    "href": "lectures/week01/index.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/studio.html",
    "href": "lectures/week01/studio.html",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2\n\n\n\n\n[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week01/studio.html#objectives",
    "href": "lectures/week01/studio.html#objectives",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "lectures/week01/studio.html#instructions",
    "href": "lectures/week01/studio.html#instructions",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "[Studio module instructions go here…]"
  }
]
[
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nGillies, Sean et al. 2007--. “Shapely: Manipulation and Analysis of Geometric Objects.” toblerity.org. https://github.com/Toblerity/Shapely.\n\n\nJordahl, Kelsey, Joris Van den Bossche, Martin Fleischmann, Jacob Wasserman, James McBride, Jeffrey Gerard, Jeff Tratner, et al. 2020. “Geopandas/Geopandas: V0.8.1.” Zenodo. https://doi.org/10.5281/zenodo.3946761.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nLongley, Paul A, and James A Cheshire. 2017. “Geographical Information Systems.” In The Routledge Handbook of Mapping and Cartography, 251–58. Routledge.\n\n\nMcKinney, Wes. 2010. “Data Structures for Statistical Computing in Python.” In Proceedings of the 9th Python in Science Conference, edited by Stéfan van der Walt and Jarrod Millman, 56–61. https://doi.org/10.25080/Majora-92bf1922-00a .\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "syllabus.html#class-meetings",
    "href": "syllabus.html#class-meetings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Class Meetings",
    "text": "Class Meetings\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLecture\nLSN 111\nMon & Wed 3:30 - 4:45pm"
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Instructor",
    "text": "Instructor\n\n\n\nName\nOffice hours\nLocation\n\n\n\n\nSergio Rey\nMon 9:00 - 10:00 (by appointment)\nPSFA 361G"
  },
  {
    "objectID": "syllabus.html#introduction",
    "href": "syllabus.html#introduction",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Introduction",
    "text": "Introduction\nWelcome to GEOG 385: Spatial Data Analysis!\nThe purpose of this course is to introduce you to methods of spatial data analysis. The focus is on both the conceptual and applied aspects of spatial statistical methods. We will place particular emphasis on the computational aspects of Exploratory Spatial Data Analysis (ESDA) methods for diﬀerent types of spatial data including point processes, lattice data, geostatistical data, network data, and spatial interaction. Throughout the course you will gain valuable hands-on experience with several specialized software packages for spatial data analysis. The overriding goal of the course is for you to acquire familiarity with the fundamental methodological and operational issues in the statistical analysis of geographic information and the ability to extend these methods in your own research.\nThe course takes an explicitly computational thinking approach to its pedagogy. Students are introduced to computational concepts and tools that are increasingly important to research that engages with geospatial data. By adopting these tools, students acquire a deeper engagement with, and mastery of, the substantive concepts. Put differently, students will learn to code. But this is a means to the end goal: students will code to learn spatial data analysis.\nIn the scope of a 15-week semester course we can only introduce a handful of the key concepts and methods relevant to the field of spatial data analysis. As such, the course is not intended as an exhaustive treatment. Instead, the goal is that students will acquire an understanding of the more common and useful methods and practices, and use the course as an entry point for further engagement with the field."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGEOG 101 or GEOG 102\nSTAT 250 or comparable course in statistics.\n\nAll students are required to complete the prerequisite assessment quiz before 2024-08-28 3:30pm."
  },
  {
    "objectID": "syllabus.html#computational-learning",
    "href": "syllabus.html#computational-learning",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Computational Learning",
    "text": "Computational Learning\nWe will be using open source geospatial software throughout the course together with Jupyter Notebooks, and Python as our scripting language.\nAll software for the course will be made available through JupyterHub, a web-based framework. Students wishing to install these materials on their own machines will be given instructions to do so, but this is not required."
  },
  {
    "objectID": "syllabus.html#readings",
    "href": "syllabus.html#readings",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Readings",
    "text": "Readings\nAll required readings are available through the links listed below. Assigned readings should be completed before the date listed in the schedule (see below). Readings are a critical part of the discussions we will hold in class, and therefore being prepared for class means having completed the readings and thought about the content. It will be difficult to do well in this course without having completed the readings.\n\n\n\nAbbrevation\nSource\n\n\n\n\nGDA\nTenkanen, H., V. Heikinheimo, D. Whipp (2023) Python for Geographic Data Analysis. CRC Press.\n\n\nGDS\nRey, S.J., D. Arribas-Bel, L.J. Wolf (2023) Geographic Data Science with Python. CRC Press."
  },
  {
    "objectID": "syllabus.html#schedule-planned",
    "href": "syllabus.html#schedule-planned",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Schedule (Planned)",
    "text": "Schedule (Planned)\n\n\n\nWeek\nDate\nTopic\nReading\nDue\n\n\n\n\n1\n8-26\nIntroduction\n\nPrerequisite Quiz\n\n\n\n8-28\nJupyter\n\n\n\n\n2\n9-02\nLabor Day (Holiday)\n\n\n\n\n\n9-04\nPandas\nGDA 3\n\n\n\n3\n9-09\nSpatial Data Analysis\nGDS 1\n\n\n\n\n9-11\nGeopandas\nGDA 6\n\n\n\n4\n9-16\nArea Unit Data\nGDS 3\n\n\n\n\n9-18\nGeoprocessing: Area Units\nGDA 6\n\n\n\n5\n9-23\nVisualizing Area Unit Data\nGDS 5\nPython Primer\n\n\n\n9-25\nChoropleth Mapping\n\n\n\n\n6\n9-30\nSpatial Weights\nGDS 4\nTopic Approval\n\n\n\n10-02\nNeighbor Relations\n\nPeer Evaluation 1\n\n\n7\n10-07\nGlobal Spatial Autocorrelation\nGDS 6\n\n\n\n\n10-09\nTesting for Clustering\n\n\n\n\n8\n10-14\nLocal Spatial Autocorrelation\nGDS 7\nProject Proposal\n\n\n\n10-16\nCluster Detection\n\nPeer Evaluation 2\n\n\n9\n10-21\nClustering Area Unit Data\nGDS 10\n\n\n\n\n10-23\nRegion Building\n\n\n\n\n10\n10-28\nPoint Pattern Data\nGDS 8.1\n\n\n\n\n10-30\nGeoprocessing: Points\n\n\n\n\n11\n11-04\nCentrography\nGDS8.2\nData Visualization\n\n\n\n11-06\nDescribing Point Patterns\n\nPeer Evaluation 3\n\n\n12\n11-11\nVeteran’s Day (Holiday)\n\n\n\n\n\n11-13\nPoint Process Simulation\nGDS 8.3\n\n\n\n13\n11-18\nNearest Neighbor Statistics\n\nData Analysis\n\n\n\n11-20\nTesting for Randomness\n\nPeer Evaluation 4\n\n\n14\n11-25\nDistance Based Statistics\n\n\n\n\n\n11-27\nThanksgiving (Holiday)\n\n\n\n\n15\n12-02\nClustering Point Pattern Data\n\nNarrative\n\n\n\n12-04\nDBScan\n\n\n\n\n16\n12-09\nIntegrating Point and Area Data\n\n\n\n\n\n12-11\nGeoprocessing: Synthesis\n\nComputational Notebook\n\n\n17\n12-18\nFinal Presentations (1-3pm)"
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Grading",
    "text": "Grading\nGEOG 385 uses specification grading in evaluating student work and in determining your final course grade. Your course grade will be based on the quality and quantity of the work that you submit that is evaluated to be of an acceptable level of quality. The acceptable level of quality demonstrates competency in the concepts and methods covered in the course.\nThere is a two-step process for determination of your final course grade at the end of the quarter:\n\nUsing your quizzes and exercises, your base grade is determined.\nUsing your final exam results, determine if your base grade includes a \"plus\", \"minus\", or level drop to form the course grade.\n\n\nBase Grade\nFor Step 1, the base grade is determined using the following specification:\n\n\n\nLevel\nThresholds\n\n\n\n\nA-\nAll the B- Thresholds\n\n\n\nPass 11 or more reading quizzes\n\n\n\nParticipate in 12 or more studios\n\n\n\nComplete 4 peer evaluations\n\n\n\nPresentation of Computational Essay\n\n\nB-\nAll the C- Thresholds\n\n\n\nPass 9 or more reading quizzes\n\n\n\nParticipate in 8 or more studios\n\n\n\nComplete 3 peer evaluations\n\n\n\nComputational Essay\n\n\nC-\nAll the D- Thresholds\n\n\n\nPass 6 or more reading quizzes\n\n\n\nParticipate in 6 or more studios\n\n\n\nComplete 2 peer evaluations\n\n\nD-\nPass 4 or more reading quizzes\n\n\n\nParticipate in 4 or more studios\n\n\n\nComplete 1 peer evaluation\n\n\nF\nFailing to clear all the D- Thresholds\n\n\n\n\n\nFinal Grade\nFor Step 2, your final course grade is determined as follows:\nIf your base grade is not an A-:\n\n2 tokens can increment a B(C,D)- to a B(CD)\n3 tokens can increment a B(C,D)- to a B(CD)+\n\nIf your base grade is an A-:\n\n2 tokens increments an A- to an A\n3 tokens increments an A- to an A and earns a recommendation certificate\n\n\n\n\n\n\n\nNote\n\n\n\nNote that SDSU grading policy does not allow A+ grades."
  },
  {
    "objectID": "syllabus.html#quizzes",
    "href": "syllabus.html#quizzes",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Quizzes",
    "text": "Quizzes\nStarting in week three, there will be a quiz due before a session that pertains to the background reading that is required before our work in class. Quizzes are graded on a pass/fail basis."
  },
  {
    "objectID": "syllabus.html#studio-participation",
    "href": "syllabus.html#studio-participation",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Studio Participation",
    "text": "Studio Participation\nEach Wednesday, we will focus on hands-on exercises that explore the material from lecture. Each student will be assigned to a small group that works together to carry out a set of spatial data analysis tasks. At the end of the session each group will submit a single notebook demonstrating their work.\nEach notebook is graded using a CRN rubric that classifies work with marks of C (\"Demonstrates Competence\"), R (\"Needs Revision\"), or N (\"Not assessable\"):\nOf each notebook the following questions will be asked: Does the work demonstrate that the student understands the concepts? Does the work demonstrate competence and meet the expectations outlined in the exercise?\nIf the answer is \"yes\" to both of the questions, the group passes the hurdle for that studio.\nIf the initial submission does not clear the hurdle, then a second question is asked: Is there evidence of partial understanding of the concepts? If the answer to this question is \"Yes\" the group can exchange one token (from each student) to attempt a revision of their work. If the answer is \"No\", the group does not clear the hurdle for this exercise and will not have the opportunity to revise their work.\nFor our studio sessions on Wednesdays, it is essential that you bring your own device, such as a laptop or tablet. These sessions will involve hands-on activities that require access to software and online resources. Having your own device will allow you to fully participate and engage with the exercises. Please ensure your device is charged and ready to use at the start of each studio session. If you have any concerns about this requirement, please reach out to me in advance so we can make necessary arrangements."
  },
  {
    "objectID": "syllabus.html#computational-essay",
    "href": "syllabus.html#computational-essay",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Computational Essay",
    "text": "Computational Essay\nEach student will have the opportunity to write a computational essay using Jupyter notebooks to apply the methods of ESDA to a topic of their choice, approved by the instructor. The essay should demonstrate your ability to analyze spatial data, identify patterns, and interpret the results using ESDA techniques.\n\nInstructions\n\n1. Topic Selection\nSelect a topic of interest that involves spatial data. The topic should be relevant to your field of study or personal interest. Ensure that the data is accessible and suitable for spatial analysis. Submit your topic for approval by the instructor by September 16. If you are unsure about a topic, speak to the professor.\n\n\n2. Data Acquisition\nIdentify and acquire spatial data related to your chosen topic. This may include data from public repositories, government databases, or other reliable sources.\n\n\n3. ESDA Techniques\nApply appropriate ESDA methods such as spatial autocorrelation, clustering, and visualization techniques to explore your data. Use libraries like PySAL, GeoPandas, or others as needed.\n\n\n4. Analysis and Interpretation\nDocument your analysis in a Jupyter notebook. Include clear explanations of the methods used, the rationale behind your choices, and a discussion of your findings. Visualizations should be integrated into the narrative to support your analysis.\n\n\n5. Submission\nSubmit your Jupyter notebook along with a brief (500-word) reflection on what you learned from the analysis and how ESDA techniques enhanced your understanding of the topic. At submission you can indicate whether you wish to present your computational essay during the final period.\n\n\n\n\n\n\nImportant\n\n\n\nYou must demonstrate competency on each of the stages above to have the computational essay count towards your base grade.\n\n\n\n\n\nDeadline\nSubmit your completed essay by December 12, Midnight."
  },
  {
    "objectID": "syllabus.html#final-exam-activity",
    "href": "syllabus.html#final-exam-activity",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Final Exam Activity",
    "text": "Final Exam Activity\nOur final exam activity is scheduled for December 18 from 1-3pm. Students who applied to submit their computational essay will present during this period."
  },
  {
    "objectID": "syllabus.html#sec-tokens",
    "href": "syllabus.html#sec-tokens",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Tokens",
    "text": "Tokens\nEach student is provided with three tokens at the beginning of the semester.\n\nUsing Tokens\n\nCredit for a reading quiz that was failed (1 token).\nObtaining a one-day extension for a milestone prior to due date (1 token).\nHanding in a milestone activity one day late without permission (2 tokens).\nRevising a milestone that was submitted on-time but evaluated as \"Needing Revision\" (1 token).\nRevising a studio exercise that needs revision (1 token).\nRequesting a make-up date for the presentation by 2024-12-01 17:00 (3 tokens)\nMissing a studio session (3 tokens).\nAny tokens remaining after determination of the base grade will be used to determine the final course grade (see above).\n\nTo use a token you must complete a request using the token spending form.\n\n\nEarning Tokens\nAdditional tokens can be earned in several ways:\n\nSubmitting topics for discussion in lectures in our board\nAttending an in-person office hour to discuss a proposed question/topic\nAttending a geography colloquium (write a paragraph description)\nCompleting the python primer (3 tokens)"
  },
  {
    "objectID": "syllabus.html#policies",
    "href": "syllabus.html#policies",
    "title": "Geography 385 Spatial Data Analysis",
    "section": "Policies",
    "text": "Policies\n\nAccommodations\nIf you are a student with a disability and are in need of accommodations for this class, please contact Student Ability Success Center at (619) 594-6473 as soon as possible. Please know accommodations are not retroactive, and I cannot provide accommodations based upon disability until I have received an accommodation letter from Student Ability Success Center.\n\n\nPrivacy and Intellectual Property\nStudent Privacy and Intellectual Property: The Family Educational Rights and Privacy Act (FERPA) mandates the protection of student information, including contact information, grades, and graded assignments. I will use Canvas to communicate with you, and I will not post grades or leave graded assignments in public places. Students will be notified at the time of an assignment if copies of student work will be retained beyond the end of the semester or used as examples for future students or the wider public. Students maintain intellectual property rights to work products they create as part of this course unless they are formally notified otherwise.\n\n\nAcademic Integrity\nThe SDSU student academic integrity policy lists violations in detail. These violations fall into eight broad areas that include but are not limited to: cheating, fabrication, plagiarism, facilitating academic misconduct, unauthorized collaboration, interference or sabotage, non-compliance with research regulations and retaliation. For more information about the SDSU student academic integrity policy, please see the following: https://sacd.sdsu.edu/student-rights/academic-dishonesty.\n\n\nCode of Conduct\nAs course instructor, I am dedicated to providing a harassment-free learning experience for all students, regardless of gender, sexual orientation, disability, physical appearance, body size, race, religion, or choice of operating system. All course participants are expected to show respect and courtesy to other students throughout the semester. As a learning community we do not tolerate harassment of participants in any form.\n\nAll communication should be appropriate for a professional audience including people of many different backgrounds. Sexual language and imagery are not appropriate in this course.\nBe kind to others. Do not insult or put down other students. Behave professionally. Remember that harassment and sexist, racist, or exclusionary jokes are not appropriate for this course.\nStudents violating these rules may be asked to leave the course, and their violations will be reported to the SDSU administration.\n\nThis code of conduct is an adaptation of the SciPy 2018 Code of Conduct."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Home",
    "section": "",
    "text": "This course will take you through 15 weeks of engaging lectures and hands-on studios, designed to give you practical experience in Spatial Data Analysis .\nUse the sidebar to navigate through the weekly content.\n\n\nPlease refer to the course syllabus for detailed information on course structure, grading, and policies."
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Course Home",
    "section": "",
    "text": "Please refer to the course syllabus for detailed information on course structure, grading, and policies."
  },
  {
    "objectID": "lectures/week01/studio.html",
    "href": "lectures/week01/studio.html",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2\n\n\n\n\n[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week01/studio.html#objectives",
    "href": "lectures/week01/studio.html#objectives",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "lectures/week01/studio.html#instructions",
    "href": "lectures/week01/studio.html#instructions",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week01/lecture.html#syllabus",
    "href": "lectures/week01/lecture.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus"
  },
  {
    "objectID": "lectures/week01/lecture.html#spatial-data-analysis",
    "href": "lectures/week01/lecture.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#data-definitions",
    "href": "lectures/week04/04-spatial-data.html#data-definitions",
    "title": "Spatial Data",
    "section": "Data Definitions",
    "text": "Data Definitions\n\nfacts and statistics collected together for reference or analysis\n\n\nthe quantities, characters, or symbols on which operations are performed by a computer, being stored and transmitted in the form of electrical signals and recorded on magnetic, optical, or mechanical recording media.\n\n\nthings known or assumed as facts, making the basis of reasoning or calculate\n\nSource: Oxford languages"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#datas-place",
    "href": "lectures/week04/04-spatial-data.html#datas-place",
    "title": "Spatial Data",
    "section": "Data’s Place",
    "text": "Data’s Place\n\n\n\n\n\nDIKW Pyramid\n\n\n\n\ndata: discrete facts, unorganized and lacking context or information\ninformation: data imbued with meaning - what is in the data\nknowledge: perception of the world seen through information synthesis\nwisdom: “knowing the right things to do”"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#data-sets",
    "href": "lectures/week04/04-spatial-data.html#data-sets",
    "title": "Spatial Data",
    "section": "Data Sets",
    "text": "Data Sets\nA data set is a collection of observations recorded for individual units on a set of variables.\nVariables are sometimes referred to as attributes or features (in machine learning parlance)."
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#measurement-scales",
    "href": "lectures/week04/04-spatial-data.html#measurement-scales",
    "title": "Spatial Data",
    "section": "Measurement Scales",
    "text": "Measurement Scales\n\n\n\nScale\nOperations\nExample\n\n\n\n\nnominal\nmode, frequencies\nZip Code\n\n\nordinal\nA &gt; B\nRanks, Primary, Intermediate\n\n\ninterval\n+ -\nTime\n\n\nratio\n+ - * /\nWeight, Kelvin"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-data-is-special",
    "href": "lectures/week04/04-spatial-data.html#spatial-data-is-special",
    "title": "Spatial Data",
    "section": "Spatial Data is Special",
    "text": "Spatial Data is Special\n\nSpatial data comes in many varieties and it is not easy to arrive at a system of classification that is simultaneously exclusive, exhaustive, imaginative, and satisfying.\n\n– G. Upton & B. Fingleton"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#what-is-special-about-spatial-data-1",
    "href": "lectures/week04/04-spatial-data.html#what-is-special-about-spatial-data-1",
    "title": "Spatial Data",
    "section": "What is special about spatial data?",
    "text": "What is special about spatial data?\nLocation, Location, Location\nwhere matters\nDependence is the rule, not the exception\n\nspatial interaction, contagion, spill-overs\nspatial externalities\n\nSpatial Scale\n\nInference can change with scale"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#nature-of-spatial-data",
    "href": "lectures/week04/04-spatial-data.html#nature-of-spatial-data",
    "title": "Spatial Data",
    "section": "Nature of Spatial Data",
    "text": "Nature of Spatial Data\nGeoreferences\nattribute data together with location\nGeocoding\n\nassociate observations with location\npoint: latitude-longtitude (GPS)\nareal unit: spatial reference"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geocoding-on-line",
    "href": "lectures/week04/04-spatial-data.html#geocoding-on-line",
    "title": "Spatial Data",
    "section": "Geocoding on-line",
    "text": "Geocoding on-line\n\nGeocode Input"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geocoding-on-line-1",
    "href": "lectures/week04/04-spatial-data.html#geocoding-on-line-1",
    "title": "Spatial Data",
    "section": "Geocoding on-line",
    "text": "Geocoding on-line\n\nGeocode Output"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#on-the-map",
    "href": "lectures/week04/04-spatial-data.html#on-the-map",
    "title": "Spatial Data",
    "section": "On the Map?",
    "text": "On the Map?\n\nMap of Geocode Output"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#on-the-map-1",
    "href": "lectures/week04/04-spatial-data.html#on-the-map-1",
    "title": "Spatial Data",
    "section": "On the Map?",
    "text": "On the Map?\n\nErrors in Geocode Output"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#location",
    "href": "lectures/week04/04-spatial-data.html#location",
    "title": "Spatial Data",
    "section": "Location",
    "text": "Location\n\nGiven: in most spatial data analysis, no choice in location\nNo sampling in the usual sense\nData = attributes augmented with locational information"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-effects",
    "href": "lectures/week04/04-spatial-data.html#spatial-effects",
    "title": "Spatial Data",
    "section": "Spatial Effects",
    "text": "Spatial Effects\nThe Trilogy\n\nSpatial Dependence\nSpatial Heterogeneity\nSpatial Scale"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-dependence",
    "href": "lectures/week04/04-spatial-data.html#spatial-dependence",
    "title": "Spatial Data",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\nTobler’s First Law of Geography\n\n“everything depends on everything else, but closer things more so”\n\n\nStructure of spatial dependence\nDistance Decay\nCloseness = Similarity"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-heterogenety",
    "href": "lectures/week04/04-spatial-data.html#spatial-heterogenety",
    "title": "Spatial Data",
    "section": "Spatial Heterogenety",
    "text": "Spatial Heterogenety\nSpatial Instability\n\nProcess varies in some way over spatial units\nMultiple forms\n\nDiscrete = regimes\nContinuous = expansion method, GWR\n\nTrade-off\n\nSpatial homogeneity = stationary process\nUniqueness = extreme heterogeneity"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-scale-1",
    "href": "lectures/week04/04-spatial-data.html#spatial-scale-1",
    "title": "Spatial Data",
    "section": "Spatial Scale",
    "text": "Spatial Scale\nMismatch\n\nSpatial scale of the process\nSpatial scale of our measurement\n\nIssues\n\npoints too far apart = miss small distance variation\narea aggregates cannot provide information on individual behavior\nEcological Fallacy"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week04/04-spatial-data.html#modifiable-areal-unit-problem-maup",
    "title": "Spatial Data",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\nAggregation Problem\n\nspecial case of ecological fallacy\na million correlation coefficients\n\nZonation Problem\n\nsize\narangement\nHow many ways could you partition the coterminous US land area into 48 polygons?"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#maup-zonation-problem",
    "href": "lectures/week04/04-spatial-data.html#maup-zonation-problem",
    "title": "Spatial Data",
    "section": "MAUP Zonation Problem",
    "text": "MAUP Zonation Problem\n\nhttp://en.wikipedia.org/wiki/Modifiable_areal_unit_problem"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#maup-aggregation-problem",
    "href": "lectures/week04/04-spatial-data.html#maup-aggregation-problem",
    "title": "Spatial Data",
    "section": "MAUP Aggregation Problem",
    "text": "MAUP Aggregation Problem\n\n\n\n\n\nhttp://en.wikipedia.org/wiki/Modifiable_areal_unit_problem\n\n\n\n\nTrue rate = 1/3 = 33%\nA’s rate = (0 +1/2) /2 = 25%\nA’s weighted rate = 1/3 * 0 + 2/3 * 50 = 33%\nB’s rate = (0 + 100) /2 = 50%\nB’s weighted rate = 2/3 * 0 + 1/3 * 100 = 33%"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#spatial-process",
    "href": "lectures/week04/04-spatial-data.html#spatial-process",
    "title": "Spatial Data",
    "section": "Spatial Process",
    "text": "Spatial Process\nSpatial Random Field\na mathemtical construct to capture randomness of values distributed over space\n\\[\\{Z(s):s \\in D \\} \\]\n\n\\(s \\in R^d:\\) location (e.g., lat-lon)\n\\(D \\in R^d:\\) index set = possible locations\n\\(Z(s):\\) random variable at location \\(s\\)"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#types-of-spatial-data-1",
    "href": "lectures/week04/04-spatial-data.html#types-of-spatial-data-1",
    "title": "Spatial Data",
    "section": "Types of Spatial Data",
    "text": "Types of Spatial Data\n\nEvents\n\naddresses of crimes\n\nDiscrete Spatial Objects\n\ncounty crime rates\n\nContinuous surfaces\n\nair quality\nrainfall"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-pattern-analysis",
    "href": "lectures/week04/04-spatial-data.html#point-pattern-analysis",
    "title": "Spatial Data",
    "section": "Point Pattern Analysis",
    "text": "Point Pattern Analysis\nData\n\nmapped pattern = all the values\nnot a sample in the usual sense\n\nSpatial Process\n\nobservations as a realization of a random point process\npoints occur in space according to a mathematical model"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-patterns",
    "href": "lectures/week04/04-spatial-data.html#point-patterns",
    "title": "Spatial Data",
    "section": "Point Patterns",
    "text": "Point Patterns\nUnmarked Point Pattern\n\nonly location is recorded\nno other attribute information\n\nMarked Point Pattern\n\nLocation is recorded\nStochastic attributes are also recorded\ne.g., sales price at address, DBH of a tree"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-pattern-analysis-quadrat-methods",
    "href": "lectures/week04/04-spatial-data.html#point-pattern-analysis-quadrat-methods",
    "title": "Spatial Data",
    "section": "Point Pattern Analysis: Quadrat Methods",
    "text": "Point Pattern Analysis: Quadrat Methods\n\nQuadrat Analysis"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#point-pattern-analysis-distance-based-methods",
    "href": "lectures/week04/04-spatial-data.html#point-pattern-analysis-distance-based-methods",
    "title": "Spatial Data",
    "section": "Point Pattern Analysis: Distance Based Methods",
    "text": "Point Pattern Analysis: Distance Based Methods\n\nDistance Distributions"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#areal-unit-data-lattice",
    "href": "lectures/week04/04-spatial-data.html#areal-unit-data-lattice",
    "title": "Spatial Data",
    "section": "Areal Unit Data (Lattice)",
    "text": "Areal Unit Data (Lattice)\n\nSpatial Domain: \\(D\\)\n\nDiscrete and fixed\nLocations nonrandom\nLocations countable\n\n\n\nExamples of lattice data\n\nAttributes collected by ZIP code\ncensus tract"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#lattice-data-indexing",
    "href": "lectures/week04/04-spatial-data.html#lattice-data-indexing",
    "title": "Spatial Data",
    "section": "Lattice Data: Indexing",
    "text": "Lattice Data: Indexing\n\nSite\n\nEach location is now an area or site\nOne observation on \\(Z\\) for each site\nNeed a spatial index: \\(Z(s_i)\\)\n\n\n\n\\(Z(s_i)\\)\n\n\\(s_i\\) is a representative location within the site\ne.g., centroid, largest city\nAllows for measuring distances between sites"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#lattice-data-county-per-capita-incomes",
    "href": "lectures/week04/04-spatial-data.html#lattice-data-county-per-capita-incomes",
    "title": "Spatial Data",
    "section": "Lattice Data: County Per Capita Incomes",
    "text": "Lattice Data: County Per Capita Incomes\n\n1969"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-analysis",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-analysis",
    "title": "Spatial Data",
    "section": "Geostatistical Analysis",
    "text": "Geostatistical Analysis\n\nSpatial Domain: \\(D\\)\n\nA continuous and fixed set.\nMeaning \\(Z(s)\\) can be observed everywhere within \\(D\\).\nBetween any two sample locations \\(s_i\\) and \\(s_j\\) you can theoretically place an infinite number of other samples.\nBy fixed: the points in \\(D\\) are non-stochastic"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data",
    "title": "Spatial Data",
    "section": "Geostatistical Data",
    "text": "Geostatistical Data\n\nContinuous Variation\n\nBecause of the continuity of \\(D\\)\nGeostatistical data is referred to as “spatial data with continuous variation.”\nContinuity is associated with \\(D\\).\nAttribute \\(Z\\) may, or may not, be continuous."
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-monitoring-sites",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-monitoring-sites",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Monitoring Sites",
    "text": "Geostatistical Data: Monitoring Sites\n\nSites"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Surface Reconstruction",
    "text": "Geostatistical Data: Surface Reconstruction\n\nTessellation"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-1",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-1",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Surface Reconstruction",
    "text": "Geostatistical Data: Surface Reconstruction\n\nInterpolation"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-2",
    "href": "lectures/week04/04-spatial-data.html#geostatistical-data-surface-reconstruction-2",
    "title": "Spatial Data",
    "section": "Geostatistical Data: Surface Reconstruction",
    "text": "Geostatistical Data: Surface Reconstruction\n\nKriging"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#network-data",
    "href": "lectures/week04/04-spatial-data.html#network-data",
    "title": "Spatial Data",
    "section": "Network Data",
    "text": "Network Data\n\n\nA network is a system of linear features connected at intersections and interchanges.\nThese intersections and interchanges are called nodes.\nThe linear feature connecting any given pair of nodes is called an arc.\nFormally, a network is defined as a directed graph \\(G = (N,\n      A)\\) consisting of an indexed set of nodes \\(N\\) with \\(n = |N|\\) and a spanning set of directed arcs \\(A\\) with \\(m = |A|\\), where \\(n\\) is the number of nodes and \\(m\\) is the number of arcs.\nEach arc on a network is represented as an ordered pair of nodes, in the form from node \\(i\\) to node \\(j\\), denoted by \\((i, j)\\)."
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#network-data-1",
    "href": "lectures/week04/04-spatial-data.html#network-data-1",
    "title": "Spatial Data",
    "section": "Network Data",
    "text": "Network Data\n\nStreet Network"
  },
  {
    "objectID": "lectures/week04/04-spatial-data.html#flow-data",
    "href": "lectures/week04/04-spatial-data.html#flow-data",
    "title": "Spatial Data",
    "section": "Flow Data",
    "text": "Flow Data\n\nFlows"
  },
  {
    "objectID": "lectures/week04/lecture_area.html#what-is-area-unit-data",
    "href": "lectures/week04/lecture_area.html#what-is-area-unit-data",
    "title": "Methods for Area Unit Data",
    "section": "What is Area Unit Data?",
    "text": "What is Area Unit Data?\n\nAnalysis of data associated with spatial zones or areas\nAreas may be regular in shape and size, or irregular",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#focus-in-area-unit-data-analysis",
    "href": "lectures/week04/lecture_area.html#focus-in-area-unit-data-analysis",
    "title": "Methods for Area Unit Data",
    "section": "Focus in Area Unit Data Analysis",
    "text": "Focus in Area Unit Data Analysis\n\nVariation in an attribute across our spatial units\nThe spatial variation is not continuous\nSpatial units are polygons\n\nvariation across polygons\nno variation within polygons",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#notation",
    "href": "lectures/week04/lecture_area.html#notation",
    "title": "Methods for Area Unit Data",
    "section": "Notation",
    "text": "Notation\nOur substantive attribute of interest is \\(Y\\).\nOur process is represented as:\n\\[\n\\{ Y(A_i), \\ A_i \\in A_1, A_2, \\ldots, A_n \\}\n\\]\n\\[\nA_1 \\cup A_2 \\cup \\ldots \\cup A_n = {R}\n\\]\n\n\\(Y(A_i)\\) is a set of random variables indexed by sub-regions\n\\(A_1, A_2, \\ldots , A_n\\) are sub-regions of \\({R}\\)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#areal-unit-data-lattice",
    "href": "lectures/week04/lecture_area.html#areal-unit-data-lattice",
    "title": "Methods for Area Unit Data",
    "section": "Areal Unit Data (Lattice)",
    "text": "Areal Unit Data (Lattice)\n\nSpatial Domain: \\({R}\\)\n\nDiscrete and fixed\nLocations nonrandom\nLocations countable\n\n\n\nExamples of lattice data\n\nAttributes collected by ZIP code\ncensus tract",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#lattice-data-indexing",
    "href": "lectures/week04/lecture_area.html#lattice-data-indexing",
    "title": "Methods for Area Unit Data",
    "section": "Lattice Data: Indexing",
    "text": "Lattice Data: Indexing\n\nSite\n\nEach location is now an area or site\nOne observation on \\(Y\\) for each site\nNeed a spatial index: \\(Y(s_i)\\)\n\n\n\n\\(Y(s_i)\\)\n\n\\(s_i\\) is a representative location within the site\ne.g., centroid, largest city\nAllows for measuring distances between sites",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#lattice-data-county-per-capita-incomes",
    "href": "lectures/week04/lecture_area.html#lattice-data-county-per-capita-incomes",
    "title": "Methods for Area Unit Data",
    "section": "Lattice Data: County Per Capita Incomes",
    "text": "Lattice Data: County Per Capita Incomes\n\n1969",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#objectives",
    "href": "lectures/week04/lecture_area.html#objectives",
    "title": "Methods for Area Unit Data",
    "section": "Objectives",
    "text": "Objectives\n\nInfer whether there are a spatial trend or pattern in the attribute values recorded over the sub-regions\nFirst order variation: Trend in the mean\nSecond order variation: Spatial dependence",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#choropleths",
    "href": "lectures/week04/lecture_area.html#choropleths",
    "title": "Methods for Area Unit Data",
    "section": "Choropleths",
    "text": "Choropleths",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#interactivity",
    "href": "lectures/week04/lecture_area.html#interactivity",
    "title": "Methods for Area Unit Data",
    "section": "Interactivity",
    "text": "Interactivity",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#spatial-dependence",
    "href": "lectures/week04/lecture_area.html#spatial-dependence",
    "title": "Methods for Area Unit Data",
    "section": "Spatial Dependence",
    "text": "Spatial Dependence\n\nHell might be a world without spatial dependence since it would be impossible to live there in any practical and meaningful way.\n\nLongley and Cheshire (2017)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#spatial-autocorrelation",
    "href": "lectures/week04/lecture_area.html#spatial-autocorrelation",
    "title": "Methods for Area Unit Data",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C.",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#spatial-autocorrelation-homicide-rates-1969",
    "href": "lectures/week04/lecture_area.html#spatial-autocorrelation-homicide-rates-1969",
    "title": "Methods for Area Unit Data",
    "section": "Spatial Autocorrelation (Homicide Rates 1969)",
    "text": "Spatial Autocorrelation (Homicide Rates 1969)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#imports",
    "href": "lectures/week04/lecture_area.html#imports",
    "title": "Methods for Area Unit Data",
    "section": "Imports",
    "text": "Imports\n\nimport geopandas\nimport libpysal",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#loading-an-example-data-set",
    "href": "lectures/week04/lecture_area.html#loading-an-example-data-set",
    "title": "Methods for Area Unit Data",
    "section": "Loading an example data set",
    "text": "Loading an example data set\n\nsouth = libpysal.examples.load_example('South')",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#finding-out-about-the-example",
    "href": "lectures/week04/lecture_area.html#finding-out-about-the-example",
    "title": "Methods for Area Unit Data",
    "section": "Finding out about the example",
    "text": "Finding out about the example\n\nlibpysal.examples.explain('South')",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#creating-a-geodataframe-from-a-file",
    "href": "lectures/week04/lecture_area.html#creating-a-geodataframe-from-a-file",
    "title": "Methods for Area Unit Data",
    "section": "Creating a GeoDataFrame from a file",
    "text": "Creating a GeoDataFrame from a file\n\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#plotting-the-geometries",
    "href": "lectures/week04/lecture_area.html#plotting-the-geometries",
    "title": "Methods for Area Unit Data",
    "section": "Plotting the geometries",
    "text": "Plotting the geometries\n\nsouth_gdf.plot()",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#checking-the-coordinate-reference-system",
    "href": "lectures/week04/lecture_area.html#checking-the-coordinate-reference-system",
    "title": "Methods for Area Unit Data",
    "section": "Checking the Coordinate Reference System",
    "text": "Checking the Coordinate Reference System\n\nsouth_gdf.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#turning-of-the-axis",
    "href": "lectures/week04/lecture_area.html#turning-of-the-axis",
    "title": "Methods for Area Unit Data",
    "section": "Turning of the axis",
    "text": "Turning of the axis\n\nax = south_gdf.plot()\nax.set_axis_off();",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#inspecting-the-gdf",
    "href": "lectures/week04/lecture_area.html#inspecting-the-gdf",
    "title": "Methods for Area Unit Data",
    "section": "Inspecting the GDF",
    "text": "Inspecting the GDF\n\nsouth_gdf.shape\n\n(1412, 70)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#inspecting-the-geoseries",
    "href": "lectures/week04/lecture_area.html#inspecting-the-geoseries",
    "title": "Methods for Area Unit Data",
    "section": "Inspecting the GeoSeries",
    "text": "Inspecting the GeoSeries\n\nsouth_gdf.geometry\n\n0       POLYGON ((-80.62805 40.39816, -80.60204 40.480...\n1       POLYGON ((-80.52625 40.16245, -80.5876 40.1750...\n2       POLYGON ((-80.52517 40.02275, -80.73843 40.035...\n3       POLYGON ((-80.52447 39.72113, -80.83248 39.718...\n4       POLYGON ((-75.7727 39.38301, -75.79144 39.7237...\n                              ...                        \n1407    POLYGON ((-79.14433 36.54606, -79.21706 36.549...\n1408    POLYGON ((-79.43775 37.61596, -79.45834 37.603...\n1409    POLYGON ((-80.12475 37.1251, -80.14045 37.1283...\n1410    POLYGON ((-76.39569 37.10771, -76.4027 37.0905...\n1411    POLYGON ((-77.53178 38.56506, -77.72094 38.840...\nName: geometry, Length: 1412, dtype: geometry",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#inspecting-the-columns",
    "href": "lectures/week04/lecture_area.html#inspecting-the-columns",
    "title": "Methods for Area Unit Data",
    "section": "Inspecting the Columns",
    "text": "Inspecting the Columns\n\nsouth_gdf.columns\n\nIndex(['NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'STFIPS',\n       'COFIPS', 'FIPSNO', 'SOUTH', 'HR60', 'HR70', 'HR80', 'HR90', 'HC60',\n       'HC70', 'HC80', 'HC90', 'PO60', 'PO70', 'PO80', 'PO90', 'RD60', 'RD70',\n       'RD80', 'RD90', 'PS60', 'PS70', 'PS80', 'PS90', 'UE60', 'UE70', 'UE80',\n       'UE90', 'DV60', 'DV70', 'DV80', 'DV90', 'MA60', 'MA70', 'MA80', 'MA90',\n       'POL60', 'POL70', 'POL80', 'POL90', 'DNL60', 'DNL70', 'DNL80', 'DNL90',\n       'MFIL59', 'MFIL69', 'MFIL79', 'MFIL89', 'FP59', 'FP69', 'FP79', 'FP89',\n       'BLK60', 'BLK70', 'BLK80', 'BLK90', 'GI59', 'GI69', 'GI79', 'GI89',\n       'FH60', 'FH70', 'FH80', 'FH90', 'geometry'],\n      dtype='object')",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#interactive-map",
    "href": "lectures/week04/lecture_area.html#interactive-map",
    "title": "Methods for Area Unit Data",
    "section": "Interactive Map",
    "text": "Interactive Map\n\nsouth_gdf.explore(column='HR60')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#describing-a-column",
    "href": "lectures/week04/lecture_area.html#describing-a-column",
    "title": "Methods for Area Unit Data",
    "section": "Describing a column",
    "text": "Describing a column\n\nsouth_gdf.HR60.describe()\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#static-choropleth-hr60",
    "href": "lectures/week04/lecture_area.html#static-choropleth-hr60",
    "title": "Methods for Area Unit Data",
    "section": "Static Choropleth: HR60",
    "text": "Static Choropleth: HR60\n\nax = south_gdf.plot(column='HR60', scheme='Quantiles', k=5,\n                    legend_kwds = {'loc': 'lower center'},\n                    legend=True)\nax.set_axis_off();",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#how-many-states-are-there-in-this-dataset",
    "href": "lectures/week04/lecture_area.html#how-many-states-are-there-in-this-dataset",
    "title": "Methods for Area Unit Data",
    "section": "How many states are there in this dataset",
    "text": "How many states are there in this dataset\n\nsouth_gdf.STATE_NAME.unique().shape\n\n(17,)",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#how-many-counties",
    "href": "lectures/week04/lecture_area.html#how-many-counties",
    "title": "Methods for Area Unit Data",
    "section": "How many counties?",
    "text": "How many counties?\n\nsouth_gdf.shape[0]\n\n1412",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#how-many-counties-in-each-state",
    "href": "lectures/week04/lecture_area.html#how-many-counties-in-each-state",
    "title": "Methods for Area Unit Data",
    "section": "How many counties in each state?",
    "text": "How many counties in each state?\n\nsouth_gdf.groupby(by='STATE_NAME').count()\n\n\n\n\n\n\n\n\nNAME\nSTATE_FIPS\nCNTY_FIPS\nFIPS\nSTFIPS\nCOFIPS\nFIPSNO\nSOUTH\nHR60\nHR70\n...\nBLK90\nGI59\nGI69\nGI79\nGI89\nFH60\nFH70\nFH80\nFH90\ngeometry\n\n\nSTATE_NAME\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nArkansas\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n...\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n\n\nDelaware\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n...\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n\n\nDistrict of Columbia\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\nFlorida\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nGeorgia\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n...\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n\n\nKentucky\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n...\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n\n\nLouisiana\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n...\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n\n\nMaryland\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n...\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n\n\nMississippi\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n...\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n\n\nNorth Carolina\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n...\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n\n\nOklahoma\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n...\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n\n\nSouth Carolina\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n...\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n\n\nTennessee\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n...\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n\n\nTexas\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n...\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n\n\nVirginia\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n...\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n\n\nWest Virginia\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n...\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n\n\n\n\n17 rows × 69 columns",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#which-county-had-the-highest-median-homicide-rate-in-1960",
    "href": "lectures/week04/lecture_area.html#which-county-had-the-highest-median-homicide-rate-in-1960",
    "title": "Methods for Area Unit Data",
    "section": "Which county had the highest median homicide rate in 1960?",
    "text": "Which county had the highest median homicide rate in 1960?\n\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').median()\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n9.623977\n\n\nArkansas\n4.704111\n\n\nDelaware\n4.228385\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n9.970306\n\n\nGeorgia\n9.300076\n\n\nKentucky\n5.235436\n\n\nLouisiana\n6.840286\n\n\nMaryland\n5.335208\n\n\nMississippi\n8.919274\n\n\nNorth Carolina\n7.633043\n\n\nOklahoma\n4.269126\n\n\nSouth Carolina\n7.509437\n\n\nTennessee\n4.877751\n\n\nTexas\n4.326215\n\n\nVirginia\n6.672004\n\n\nWest Virginia\n2.623226",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#which-county-had-the-highest-maximum-homicide-rate-in-1960",
    "href": "lectures/week04/lecture_area.html#which-county-had-the-highest-maximum-homicide-rate-in-1960",
    "title": "Methods for Area Unit Data",
    "section": "Which county had the highest maximum homicide rate in 1960?",
    "text": "Which county had the highest maximum homicide rate in 1960?\n\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').max()\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n24.903499\n\n\nArkansas\n21.154427\n\n\nDelaware\n7.286472\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n40.744262\n\n\nGeorgia\n53.304904\n\n\nKentucky\n37.250885\n\n\nLouisiana\n18.243736\n\n\nMaryland\n14.327234\n\n\nMississippi\n24.833923\n\n\nNorth Carolina\n25.660127\n\n\nOklahoma\n17.088175\n\n\nSouth Carolina\n23.345940\n\n\nTennessee\n20.894275\n\n\nTexas\n92.936803\n\n\nVirginia\n23.575639\n\n\nWest Virginia\n11.482375",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#intra-state-dispersion",
    "href": "lectures/week04/lecture_area.html#intra-state-dispersion",
    "title": "Methods for Area Unit Data",
    "section": "Intra-state dispersion",
    "text": "Intra-state dispersion\n\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n4.742337\n\n\nArkansas\n4.574625\n\n\nDelaware\n1.815562\n\n\nDistrict of Columbia\nNaN\n\n\nFlorida\n7.990692\n\n\nGeorgia\n7.906488\n\n\nKentucky\n6.354316\n\n\nLouisiana\n4.189146\n\n\nMaryland\n4.064360\n\n\nMississippi\n4.972698\n\n\nNorth Carolina\n4.596952\n\n\nOklahoma\n4.231132\n\n\nSouth Carolina\n4.018644\n\n\nTennessee\n4.354979\n\n\nTexas\n8.223844\n\n\nVirginia\n4.826707\n\n\nWest Virginia\n2.773659\n\n\n\n\n\n\n\n\nsgdf = south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\ncv = sgdf / south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').mean() * 100\n\n\ncv.sort_values(by='HR60', ascending=False)\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nTexas\n144.992919\n\n\nKentucky\n96.815524\n\n\nWest Virginia\n93.234007\n\n\nArkansas\n81.223752\n\n\nOklahoma\n81.114430\n\n\nTennessee\n75.426226\n\n\nGeorgia\n73.774440\n\n\nMaryland\n71.898559\n\n\nFlorida\n68.252692\n\n\nVirginia\n66.924041\n\n\nLouisiana\n59.994571\n\n\nMississippi\n57.457024\n\n\nNorth Carolina\n57.013871\n\n\nAlabama\n49.070812\n\n\nSouth Carolina\n48.083524\n\n\nDelaware\n34.966796\n\n\nDistrict of Columbia\nNaN",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#recap-of-key-points",
    "href": "lectures/week04/lecture_area.html#recap-of-key-points",
    "title": "Methods for Area Unit Data",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinition of Area Unit Data\nObjectives of Area Unit Data Analysis\nArea Unit Data in Python",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#questions",
    "href": "lectures/week04/lecture_area.html#questions",
    "title": "Methods for Area Unit Data",
    "section": "Questions",
    "text": "Questions",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_area.html#references",
    "href": "lectures/week04/lecture_area.html#references",
    "title": "Methods for Area Unit Data",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nLongley, Paul A, and James A Cheshire. 2017. “Geographical Information Systems.” In The Routledge Handbook of Mapping and Cartography, 251–58. Routledge.",
    "crumbs": [
      "Home",
      "09-16 Area Unit Data"
    ]
  },
  {
    "objectID": "lectures/week03/studio.html",
    "href": "lectures/week03/studio.html",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2\n\n\n\n\n[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week03/studio.html#objectives",
    "href": "lectures/week03/studio.html#objectives",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "Objective 1\nObjective 2"
  },
  {
    "objectID": "lectures/week03/studio.html#instructions",
    "href": "lectures/week03/studio.html#instructions",
    "title": "Week 1 Studio: Jupyter",
    "section": "",
    "text": "[Studio module instructions go here…]"
  },
  {
    "objectID": "lectures/week03/lecture.html#syllabus",
    "href": "lectures/week03/lecture.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus"
  },
  {
    "objectID": "lectures/week03/lecture.html#spatial-data-analysis",
    "href": "lectures/week03/lecture.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture"
  },
  {
    "objectID": "studio/meet.html",
    "href": "studio/meet.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "studio/meet.html#overview",
    "href": "studio/meet.html#overview",
    "title": "",
    "section": "Overview",
    "text": "Overview\nIn this activity, you’ll work in small groups to collaborate on a task. To facilitate your work, each group will create a Google Meet meeting where you can share your screens and discuss the activity in real-time."
  },
  {
    "objectID": "studio/meet.html#steps-to-create-a-google-meet-meeting",
    "href": "studio/meet.html#steps-to-create-a-google-meet-meeting",
    "title": "",
    "section": "Steps to Create a Google Meet Meeting",
    "text": "Steps to Create a Google Meet Meeting\n\n1. Choose a Group Leader\n\nSelect one person in your group to create the Google Meet meeting. This person will be responsible for sharing the meeting link with the rest of the group.\n\n\n\n2. Create the Google Meet Meeting\n\nThe group leader should follow these steps:\n\nOpen Google Meet:\n\nGo to Google Meet in your web browser.\n\nStart a New Meeting:\n\nClick on the New meeting button.\nSelect Start an instant meeting.\n\nCopy the Meeting Link:\n\nOnce the meeting is created, a window will pop up with the meeting link.\nClick on Copy meeting link to copy the URL to your clipboard.\n\n\n\n\n\n3. Share the Meeting Link with Your Group\n\nThe group leader should share the copied meeting link with the rest of the group members. This can be done via:\n\nClass communication platform (chat)\nDirect message or text\n\n\n\n\n4. Join the Google Meet Meeting\n\nEach group member should click on the link provided by the group leader to join the meeting.\n\n\n\n5. Share Your Screen\n\nTo share your screen during the meeting:\n\nClick on the Present Now button:\n\nThis button is located at the bottom of the Google Meet window.\n\nChoose What to Share:\n\nYou can select to share your entire screen, a specific window, or a specific browser tab.\n\nClick on Share:\n\nOnce you’ve selected what to share, click Share to start presenting to the group.\n\n\n\n\n\n6. Collaborate on the Activity\n\nUse the screen sharing feature to work together on the assigned activity. Discuss, brainstorm, and contribute as a team.\n\n\n\n7. Wrap Up\n\nWhen your group has completed the activity, you can leave the Google Meet meeting by clicking the Leave call button."
  },
  {
    "objectID": "studio/meet.html#troubleshooting-tips",
    "href": "studio/meet.html#troubleshooting-tips",
    "title": "",
    "section": "Troubleshooting Tips",
    "text": "Troubleshooting Tips\n\nAudio Issues: If you’re having trouble hearing others, make sure your microphone and speakers are properly connected and not muted.\nScreen Sharing Not Working: Ensure that you have granted the necessary permissions for screen sharing in your browser.\nInternet Connection: If your connection is unstable, try moving closer to your Wi-Fi router or switching to a wired connection if possible."
  },
  {
    "objectID": "studio/meet.html#additional-resources",
    "href": "studio/meet.html#additional-resources",
    "title": "",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nGoogle Meet Help Center\n\nGood luck with your activity, and make the most of your collaborative time!"
  },
  {
    "objectID": "studio/week01/meet.html",
    "href": "studio/week01/meet.html",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "",
    "text": "This handout provides instructions on how to use Google Meet for small group work, including creating a meeting, sharing screens (with sound off), and using the chat feature to collaborate on in-class studios."
  },
  {
    "objectID": "studio/week01/meet.html#purpose",
    "href": "studio/week01/meet.html#purpose",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "",
    "text": "This handout provides instructions on how to use Google Meet for small group work, including creating a meeting, sharing screens (with sound off), and using the chat feature to collaborate on in-class studios."
  },
  {
    "objectID": "studio/week01/meet.html#find-your-team",
    "href": "studio/week01/meet.html#find-your-team",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Find Your Team",
    "text": "Find Your Team\nTeams are randomly constructed. To find your team:\n\nVisit the link for the team assignments for Studio 1.\nThe first person listed is the group leader. If the first person is not present, the first person next on the list who is present is the group leader for the studio."
  },
  {
    "objectID": "studio/week01/meet.html#getting-started-with-google-meet",
    "href": "studio/week01/meet.html#getting-started-with-google-meet",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Getting Started with Google Meet",
    "text": "Getting Started with Google Meet\n\nGroup Leader\n\nThe group leader will be responsible for creating the Google Meet session.\n\nCreating a Google Meet Session\n\nThe group leader should sign in to their Google account.\nUsing the Team Meeting link at the bottom of the Studio 1 Team listing, the Group Leader should start the meeting..\n\nJoining the Google Meet Session\n\nEach group member should click the link provided by the group leader to join the session.\nAllow Google Meet to access your microphone and camera if prompted.\nMute your microphone by clicking the microphone icon at the bottom of the screen to reduce background noise."
  },
  {
    "objectID": "studio/week01/meet.html#sharing-your-screen",
    "href": "studio/week01/meet.html#sharing-your-screen",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Sharing Your Screen",
    "text": "Sharing Your Screen\nScreen sharing helps all group members see the same content, making collaboration easier.\n\nHow to Share Your Screen\n\nOnce in the Google Meet, click on the “Present Now” button at the bottom right of the screen.\nSelect “Your Entire Screen” or “A Window,” depending on what you want to share.\nClick “Share” to start sharing your screen.\n\nKeeping Your Microphone Off\n\nKeep your microphone muted while sharing your screen to avoid feedback or echo. Use the chat for communication or unmute only when necessary."
  },
  {
    "objectID": "studio/week01/meet.html#using-the-chat-feature",
    "href": "studio/week01/meet.html#using-the-chat-feature",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Using the Chat Feature",
    "text": "Using the Chat Feature\nThe chat feature is useful for collaboration without speaking out loud.\n\nOpen the Chat\n\nClick on the chat icon (speech bubble) in the top right corner of the screen to open the chat window.\n\nCommunicate Effectively\n\nUse the chat to ask questions, share links, and discuss the studio.\nKeep your messages clear and concise to avoid misunderstandings."
  },
  {
    "objectID": "studio/week01/meet.html#best-practices-for-google-meet-collaboration",
    "href": "studio/week01/meet.html#best-practices-for-google-meet-collaboration",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Best Practices for Google Meet Collaboration",
    "text": "Best Practices for Google Meet Collaboration\n\nStay Muted When Not Speaking: We will be in person, so no need to use your microphone in class.\nUse the Chat to Communicate: Share your thoughts and questions in the chat to maintain a smooth flow of discussion.\nKeep Your Camera On: This helps the group stay engaged and allows for better non-verbal communication.\nBe Respectful: Listen to others, avoid interrupting, and provide constructive feedback.\nEnsure Only One Person Shares at a Time: This helps avoid confusion and keeps the focus on the task at hand."
  },
  {
    "objectID": "studio/week01/meet.html#troubleshooting-tips",
    "href": "studio/week01/meet.html#troubleshooting-tips",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Troubleshooting Tips",
    "text": "Troubleshooting Tips\n\nAudio Issues: If others cannot hear you, check that your microphone is not muted and that Google Meet is using the correct microphone in the settings.\nScreen Sharing Problems: Ensure that your browser has permission to share your screen.\nConnectivity Issues: If you experience lag or get disconnected, try refreshing your browser or checking your internet connection."
  },
  {
    "objectID": "studio/week01/meet.html#wrapping-up",
    "href": "studio/week01/meet.html#wrapping-up",
    "title": "Studio 1: Google Meet for Studio Collaboration",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nAt the end of the studio, the group leader should summarize the group’s discussion and findings. The leader will hand in the summary on Canvas.\nFor additional assistance, refer to the Google Meet Help Center or contact your instructor.\nHappy collaborating!"
  },
  {
    "objectID": "studio/week01/intro.html",
    "href": "studio/week01/intro.html",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "",
    "text": "In this Session we introduce the computational environment for the course."
  },
  {
    "objectID": "studio/week01/intro.html#logging-on-to-jupyter-hub",
    "href": "studio/week01/intro.html#logging-on-to-jupyter-hub",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Logging on to Jupyter Hub",
    "text": "Logging on to Jupyter Hub\nEach registered student is given an account on our course Jupyter Hub installation.\nIf you are on campus, and using a campus IP, go to http://130.191.118.182/hub/login\n\n\n\nlogon\n\n\nYour Username is the prefix of your SDSU email (the part before the @).\nFor the Password, you set that the first time you log on. It can be anything you choose, but you must remember it.\nIf you are off-campus, you must first connect to the university’s Virtual Private Network."
  },
  {
    "objectID": "studio/week01/intro.html#interface",
    "href": "studio/week01/intro.html#interface",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Interface",
    "text": "Interface\nWe will be exploring the components of the Jupyter Lab Interface.\n\nMain work area\nleft sidebar\nmenu bar\nfile browser\n\n\n\n\nlogon\n\n\n\nMain work area\nThe main work area arranges activities and documents into panels of tabs.\nDocuments can be notebooks, text files, while activities can be terminals or code consoles.\nIt currently has a single tab entitled Launcher which contains a set of, well, launchers.\n\n\nLeft sidebar\nThe left sidebar contains a file browser (next to the main work area). The thin panel to the left of the file browser has three icons for:\n\ncommand pallet\ntable of contents\nextension manager"
  },
  {
    "objectID": "studio/week01/intro.html#notebooks",
    "href": "studio/week01/intro.html#notebooks",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Notebooks",
    "text": "Notebooks\nLet’s open our first document.\nDouble-click the Square icon under Notebook in the Launcher tab.\nThis will result in:\n\n\n\nnotebook\n\n\nNow, the main work area has a single tab with the title Untitled.ipynb. This is our first jupyter notebook.\nThe extension ipynb tells us so.\nWe also see that the filename is showing up in the file browser.\nIt is good practice to give your notebooks (and files) meaningful names. To do so you can right click on the tab or in the file browser and give it a new name introduction.ipynb.\n\n\n\nnotebook renamed"
  },
  {
    "objectID": "studio/week01/intro.html#cell-types",
    "href": "studio/week01/intro.html#cell-types",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Cell Types",
    "text": "Cell Types\nA notebook is composed of cells. Currently, our notebook as a single cell.\nCells can be of different types. There are three possible types:\n\nCode\nMarkdown\nRaw\n\nWhat happens with the contents of a cell depends upon its type. We can have cells of different types in the same notebook - in other words, all the cells in a notebook do not have to be of the same type. This opens up rich possibilities for creating computational documents.\n\nCode\nThe type of a cell is indicated in the dropdown of the tabs icon bar. Our current cell is of type Code.\nA code cell should contain, well, code. By this we mean, a set of statements that the kernel for our language can understand. Think of the kernel as a machine that is going to take our code and convert it into some type of result or action.\nIn our case, the kernel is Python. This is indicated in the upper right portion of the notebook tab.\nLet’s enter some code in our code cell:\n\nEnter 3**2\nShift-return\n\n\n\n\nRunning a code cell\n\n\nWhen we used the key-chord Shift-return (while holding the shift key down also hit return) from inside the code cell, this took the contents of the cell 3**2 and passed it off to the Python interpreter. Since this was legit Python code, we got a result of 9 in an output cell.\nThen the interface gives us a new empty code cell, so we can continue if we wish.\nBut, instead of continuing, let’s say we wanted a different calculation. Put the cursor back in the first code cell and change this to 10 * 3**2 and rerun the cell.\n\n\n\nRe-running a code cell\n\n\nAgain, this is legit Python code so we get a new result. The other things that have changed are the numbers on the left of the cells. Now we have a [2] in front of the code cell and its output cell. This indicates that we have run 2 code cells in this session.\nThe current cell is indicated by the blue vertical bar. This is where we would enter new code as we progress.\nLet’s progress.\nIn the current cell, enter x = 10 * 3**2 and run the cell.\n\n\n\nRunning a code cell with an assignment\n\n\nWe don’t get an output cell in this case. This is because our code is an assignment statement. This means we assign the value of the statement on the right of the = into the variable x on the left side.\nTo see the value of x, enter x in the next code cell and run the cell:\n\n\n\nRunning a code cell with an output\n\n\nWith this, we have the basics of entering Python code and running it. Let’s turn our attention to the next type of cell: Markdown.\n\n\nMarkdown\nMarkdown is a markup language invented by John Gruber to make it easier for humans to write web pages.\nLet’s change the type of the current cell. There are two ways to do this.\nThe first way is to click on the cell type dropdown (currently set to Code) and select Markdown. This results in:\n\n\n\nChanging to Markdown\n\n\nWe still have the blue indicator to the left of the current cell. But we no longer of the [ ]: next to the cell.\nTo enter some Markdown, put the cursor in the cell and enter:\nThis next word will be **bold**.\n\n\n\nEditing Markdown\n\n\nThen run the Markdown cell with Shift-return:\n\n\n\n“Running” Markdown\n\n\nThis is a bit different from what we saw when we ran a code cell. In the case of a Markdown cell, what happens is that when we “run” the cell, the contents of the cell gets handed off to a different kernel, one that knows the Markdown markup. The kernel then translate from the markdown input and returns actual html that gets rendered in the same cell.\nWe can change our cell by double-clicking in it. Let’s add some more Markdown by changing the cell contents to:\n## Markdown Cells\n\nHere we are demonstrating `Markdown`.\n\nThe next word will be in **bold**.\n\nThe next word will be in *italics*.\n\n### Lists\n\nWe can do unordered lists:\n\n- dog\n- cat\n- monkey\n\nAs well as ordered lists\n\n1. dogs\n1. monkey\n1. cat\n\n\n\nMore Markdown\n\n\nOnce we have entered this, “run” the cell with Shift-return:\n\n\n\nMore Rendered Markdown\n\n\nBefore we do more with Markdown, let’s learn a bit about our last cell type Raw.\n\n\nRaw\nTo see the utility of the Raw cell type, double-click into the Markdown cell. In the cell, copy all the contents of the cell (click and drag with the mouse, then Control-C (Linux/Windows) Command-C (Mac) ).\nMove the cursor into the next cell and paste (Control-V (Linux/Windows), Command-V (Mac)).\nThen, in this last cell change the cell type to Raw so your screen should look like:\n\n\n\nRaw Cell Type\n\n\nNext, jump up to the Markdown cell, and run that cell to render it. Then, render the Raw cell:\n\n\n\nRaw Cell As Reference\n\n\nThis shows us that we can use Raw cells to display the syntax used to get a rendered cell. This can be helpful to document how things were done."
  },
  {
    "objectID": "studio/week01/intro.html#cell-modes",
    "href": "studio/week01/intro.html#cell-modes",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Cell Modes",
    "text": "Cell Modes\nIn addition to having different cell types, cells have two modes.\n\nCommand Mode\nEdit Mode\n\nThese are mutually exclusive modes - only one is active. In other words, you a cell is either in command mode or edit mode.\n\nCommand Mode (Running Cells)\nIn command mode we can, not suprsingly, run cells. We already know how to do this. Make the cell active (by moving the cursor to the cell), then use Ctrl-return.\nHow do we know we are in command mode? A couple of ways.\nIf you are in a code cell, if the cell does not have a blue border, you are in command mode:\n\n\n\nCode cell in Command mode\n\n\nIf the code cell has a blue border you are in edit mode:\n\n\n\nCode cell in Edit mode\n\n\nIf you are in edit mode and want to switch to command mode, use the Esc key.\nIf you are in command mode and want to switch to edit mode, simply click in the cell to start editing.\nIn addition to letting us run cells, command mode also allows us to manipulate cells. The two sets of most common manipulations we do in command mode are:\n\nCut and paste cells (move)\nSplit and merge cells\n\nTo demonstrate the first, recall the figure that had the Raw cell below the Markdown cell. It might be more helpful to have the Raw cell before (above) the Markdown cell.\nTo do this.\nFrom the empty code cell:\n\nEnter command mode (Esc)\nHit the k key. This moves the cursor up into the raw cell.\nHit the x key. This will cut the current cell.\nMove up two cells by repeating k k\nPaste the cut cell with v\n\nYour notebook should now look something like:\n\n\n\nCode cell in Edit mode\n\n\nTo demonstrate splitting cells, let’s say we want to break our Markdown cell into two separate Markdown cells such that the Lists subsection is in its own cell.\nTo do this,\n\nMake the Markdown cell active by moving down one with j.\nOnce the Markdown cell is active, get into edit mode (click into the cell).\nMove the cursor to the empty ilne before Lists.\nCtrl-Shift-- (That’s the Ctrl key held down, with the Shift key followed by -).\n\nThe result should be:\n\n\n\nSpliltting a cell\n\n\nTo merge cells together.\n\nEnter command mode\nShift-k to select the current cell and the cell above it.\nShift-m to merge the two cells.\n\n\n\n\nMerging two cells\n\n\n\n\nEdit Mode\nLet’s create an empty cell and edit it. Assume we want to add a new cell above the current cell. This is done with a.\n\n\n\nCreating a new cell above the current cell\n\n\nLet’s make this a Markdown cell, using the second approach I hinted at above.\n\nEnter command mode\nm\n\nNote that it is lower-case m here. Now we can enter Markdown by clicking in the new cell and filling it in with whatever we want. For example:\n### Using Raw and Markdown cells\nThe cell below will be the rendered markdown. The cell above is the raw markdown in a raw cell for reference\nRendering the cell should give:\n\n\n\nRendered new cell\n\n\nAs our notebooks grow, it would be nice to be able to jump around without endlessly scrolling. Remember the table of contents that lives in the Left sidebar? This can come in handy when you have a long Markdown document and can use the TOC to jump around quickly.\nTo see this work, let’s first go to the top of the notebook by scrolling up. Then, 1. Add a new cell above the current cell. 2. Make it a Markdown Cell 3. Enter ## Python code cells 4. Render the cell\nAfter rendering, the cell, click the table of contents icon in the left sidebar:\n\n\n\nTable of Contents\n\n\nYou can now click on the entries in the table of contents to jump to that section/subsection in the notebook."
  },
  {
    "objectID": "studio/week01/intro.html#saving-and-exporting",
    "href": "studio/week01/intro.html#saving-and-exporting",
    "title": "Studio 1: Introduction to Jupyter Hub",
    "section": "Saving and Exporting",
    "text": "Saving and Exporting\nIt is good practice to save your notebook as you go. Use Ctrl-s to do so or Command-s (mac).\nIf there are any unsaved changes, the little black dot in the notebook tab will be visible:\n\n\n\nUnsaved changes\n\n\nAfter saving your notebook, it will live on the course server, so you can come back to it later (see logging off below). Sometimes, you will need to export or download a copy of your notebook to hand in for credit. To do this:\n\nMake sure the notebook you want to save is the active tab in the main work area\nClick on the file browser icon in the left side bar.\nFrom the Menu bar: File-Save and Export Notebook As-pdf\n\nThis should create a pdf file on your local computer that you can hand in.\nIf you get an error that looks like:\n\n\n\nSaving error\n\n\nThis is due to having the Raw cell in the notebook. To fix it, simply delete the Raw cell and try to export again. We won’t be using Raw cells in the assignments so this won’t be an issue moving forward."
  },
  {
    "objectID": "studio/week04/studio.html",
    "href": "studio/week04/studio.html",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 25, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week04/studio.html#instructions",
    "href": "studio/week04/studio.html#instructions",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 25, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week04/studio.html#input-files",
    "href": "studio/week04/studio.html#input-files",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Input Files",
    "text": "Input Files\nNone. You will collect all data from geosnap"
  },
  {
    "objectID": "studio/week04/studio.html#reading-the-spatial-data-files",
    "href": "studio/week04/studio.html#reading-the-spatial-data-files",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Reading the spatial data files",
    "text": "Reading the spatial data files\nUse geosnap to collect 2017 environmental justice screening data for the San Francisco metropolitan region\n(hint: the MSA fips code for the Bay Area is 41860)\n\nfrom geosnap import DataStore\n\ndatasets = DataStore(\"/srv/data/geosnap\")\n\n# uncomment the following line and complete the code\n#bay_ejscreen = gio.get_ejscreen(datasets, msa_fips=\"????\", years=????)"
  },
  {
    "objectID": "studio/week04/studio.html#report-whether-the-current-coordinate-reference-system-is-currently-projected",
    "href": "studio/week04/studio.html#report-whether-the-current-coordinate-reference-system-is-currently-projected",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Report whether the current coordinate reference system is currently projected",
    "text": "Report whether the current coordinate reference system is currently projected\n\n#bay_ejscreen.????.is_projected"
  },
  {
    "objectID": "studio/week04/studio.html#convert-the-geodataframe-into-a-geographic-coordinate-system",
    "href": "studio/week04/studio.html#convert-the-geodataframe-into-a-geographic-coordinate-system",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Convert the GeoDataFrame into a geographic coordinate system",
    "text": "Convert the GeoDataFrame into a geographic coordinate system\nhint: a the standard GCS is 4326\n\n#bay_ejscreen = bay_ejscreen.to_crs(????)"
  },
  {
    "objectID": "studio/week04/studio.html#collect-highway-data-in-the-bay-area-from-open-street-map",
    "href": "studio/week04/studio.html#collect-highway-data-in-the-bay-area-from-open-street-map",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Collect highway data in the Bay Area from Open street map",
    "text": "Collect highway data in the Bay Area from Open street map\n(hint: first take the union of the Bay Area geometries)\n\n#bay_union = bay_ejscreen.???_all()\n\n#highways = ox.features_from_polygon(bay_union, tags={\"highway\": \"????\"})"
  },
  {
    "objectID": "studio/week04/studio.html#convert-the-bay-area-geodataframe-into-an-appropriate-coordinate-system",
    "href": "studio/week04/studio.html#convert-the-bay-area-geodataframe-into-an-appropriate-coordinate-system",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Convert the Bay Area GeoDataFrame into an appropriate coordinate system",
    "text": "Convert the Bay Area GeoDataFrame into an appropriate coordinate system\nhint: a reasonable coordinate system for the Bay Area is EPSG 6419\n\n#bay_ejscreen = bay_ejscreen.to_crs(????)"
  },
  {
    "objectID": "studio/week04/studio.html#select-the-bay-area-census-blockgroups-that-are-within-2000-meters-of-a-highway",
    "href": "studio/week04/studio.html#select-the-bay-area-census-blockgroups-that-are-within-2000-meters-of-a-highway",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "Select the Bay Area Census Blockgroups that are within 2000 meters of a highway",
    "text": "Select the Bay Area Census Blockgroups that are within 2000 meters of a highway\nhint: first buffer the highway then take the intersection (ensure your geodataframes share a coordinate system before taking the intersection)"
  },
  {
    "objectID": "studio/week04/studio.html#what-is-the-median-of-the-variable-pm25-for-the-blockgroups-in-the-highway-zone",
    "href": "studio/week04/studio.html#what-is-the-median-of-the-variable-pm25-for-the-blockgroups-in-the-highway-zone",
    "title": "Studio 04 Geosnap and Geoprocessing",
    "section": "what is the median of the variable PM25 for the blockgroups in the highway zone?",
    "text": "what is the median of the variable PM25 for the blockgroups in the highway zone?"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html",
    "href": "studio/week04/studio4_geosnap.html",
    "title": "geosnap and geoprocessing",
    "section": "",
    "text": "geosnap - the geospatial neighborhood analysis package - provides a suite of tools for understanding the composition and extent of [endogenous] neighborhoods and regions in a study area. It provides:\n\nsimple access to commonly-used datasets in urban and regional analyses:\n\ndemographic data (Census/ACS)\nemployment (LEHD)\nenvironment (EPA)\ntravel infrastructure (OSM)\npublic education systems (NCES)\n\nan easy interface to build geodemographic typologies\n\nclassic aspatial typologies\nconstrained homogenous regions\n\nbuilt-in functionality to facilitate spatiotemporal analysis\n\nwithin time-period standardization\nboundary harmonization\ninflation adjustment\n\nbespoke plotting tools to help visualize neighborhood dynamics\n\ntemporally-static choropleth mapping\nanimated mapping\n\nstate-of-the-art techniques for modeling neighborhood change over time\n\nspatial Markov transition models\nsequence analysis\n\n\nToday, we want to focus on getting data from geosnap. This involves two basic steps: instantiate a DataStore class which points to datasets installed on the 385 course server, then querying the new DataStore object using functions from the geosnap io (for input-ouput) module\n\nimport geopandas as gpd\nimport pandas as pd\nimport geosnap\ngeosnap.__version__\n\n'0.14.0'\n\n\n\nfrom geosnap import DataStore\n\nAll of the datasets available in geosnap can be streamed from the cloud or installed on a local machine for analysis. In many cases, streaming works fine, but for repeated use of the same datasets, it is easier to install the data permanently. We have already done that on the course server. To ensure geosnap can access that data, we instantiate a new DataStore object pointing to the location of the data\n\ndatasets = DataStore(\"/srv/data/geosnap\")\n\nThe datasets object can now be used to read and write data from the \"/srv/data/geosnap/\" folder, which is where the course data lives).\nAs a quick shorthand to see the available datasets, you can use the dir function to peek inside the datasets object\n\ndir(datasets)\n\n['acs',\n 'bea_regions',\n 'blocks_2000',\n 'blocks_2010',\n 'blocks_2020',\n 'codebook',\n 'counties',\n 'ejscreen',\n 'lodes_codebook',\n 'ltdb',\n 'msa_definitions',\n 'msas',\n 'ncdb',\n 'nces',\n 'seda',\n 'show_data_dir',\n 'states',\n 'tracts_1990',\n 'tracts_2000',\n 'tracts_2010',\n 'tracts_2020']\n\n\nEach of these is a dataset that can be accessed. For more information on the datasets, see the geosnap datasets page.\nAs one example, we can collect data from the U.S. Census American Community Survey (5-year survey estimates) using the get_acs function in geosnap’s io module.\n\nfrom geosnap import io as gio\n\nFirst we import the io module, aliased as gio, then we query the DataStore (called datasets) for ACS data at the tract level for state 06 (which is California) and year 2016 (which is the 2012-2016 ACS).\n\n\n\nfrom geosnap.io import get_acs\n\nca = get_acs(datasets, state_fips=['06'], level='tract', years=[2016])\n\n/home/serge/miniforge3/envs/385f24/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_acs()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nThe ca variable now holds a geodataframe of California census data at the tract level. To get a different year or a different geographic level, we could specify different input parameters to the get_acs function\n\nca.head()\n\n\n\n\n\n\n\n\ngeoid\nn_mexican_pop\nn_cuban_pop\nn_puerto_rican_pop\nn_russian_pop\nn_italian_pop\nn_german_pop\nn_irish_pop\nn_scandaniavian_pop\nn_foreign_born_pop\n...\np_poverty_rate\np_poverty_rate_over_65\np_poverty_rate_children\np_poverty_rate_white\np_poverty_rate_black\np_poverty_rate_hispanic\np_poverty_rate_native\np_poverty_rate_asian\ngeometry\nyear\n\n\n\n\n0\n06001400100\n55.0\n0.0\n13.0\n49.0\n62.0\n147.0\n13.0\n8.0\n843.0\n...\n3.752906\n0.531385\n0.631020\n3.055463\n0.000000\n0.000000\n0.0\n0.000000\nMULTIPOLYGON (((-122.24692 37.88544, -122.2466...\n2016\n\n\n1\n06001400200\n118.0\n0.0\n25.0\n17.0\n39.0\n57.0\n26.0\n6.0\n243.0\n...\n5.430328\n1.946721\n0.000000\n4.047131\n0.000000\n0.563525\n0.0\n0.000000\nMULTIPOLYGON (((-122.25792 37.84261, -122.2577...\n2016\n\n\n2\n06001400300\n171.0\n0.0\n0.0\n0.0\n154.0\n81.0\n75.0\n0.0\n857.0\n...\n8.732777\n1.765962\n0.329905\n3.299049\n3.648360\n0.426936\n0.0\n0.000000\nMULTIPOLYGON (((-122.26563 37.83764, -122.2655...\n2016\n\n\n3\n06001400400\n127.0\n9.0\n0.0\n56.0\n55.0\n84.0\n37.0\n0.0\n471.0\n...\n6.445406\n0.721501\n0.000000\n3.799904\n0.673401\n0.553151\n0.0\n0.000000\nMULTIPOLYGON (((-122.26183 37.84162, -122.2618...\n2016\n\n\n4\n06001400500\n282.0\n29.0\n11.0\n10.0\n7.0\n103.0\n51.0\n0.0\n635.0\n...\n9.081168\n0.375033\n0.000000\n4.178945\n3.375301\n3.402089\n0.0\n0.642915\nMULTIPOLYGON (((-122.26951 37.84858, -122.2693...\n2016\n\n\n\n\n5 rows × 158 columns\n\n\n\n\nca.plot()\n\n\n\n\n\n\n\n\nTo trim down the existing dataset, for example to “slice out” the tracts in San Diego county, we use pandas dataframe operations. Here we use the geoid column to select tracts that begin with “06073”, which is the county FIPS code for San Diego\n\nsd = ca[ca.geoid.str.startswith('06073')]\n\n\nsd.plot()\n\n\n\n\n\n\n\n\n\n\n\nThe Environmental Protection Agency (EPA)’s envrironmental justice screening tool (EJSCREEN) is a national dataset that provides a wealth of environmental (and some demographic) data at a blockgroup level. For a full list of indicators and their metadata, see the EPA page, but this dataset includes important variables like air toxics cancer risk,ozone concentration in the air, particulate matter, and proximity to superfund sites.\nThe EJSCREEN data can be queried similarly to the ACS data. For example to get blockgroup-level data for the Seattle metropolitan region in 2019, we would use the following\n\nsea_ejscreen = gio.get_ejscreen(datasets, msa_fips=\"42660\", years=2019).to_crs(4326)\n\n/home/serge/miniforge3/envs/385f24/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_ejscreen()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nA description of the variables in the EJSCREEN data is available here. A subset of the interesting variables we might examine is provided in the table below\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nDSLPM\nDiesel particulate matter level in air\n\n\nCANCER\nAir toxics cancer risk\n\n\nRESP\nAir toxics respiratory hazard index\n\n\nPTRAF\nTraffic proximity and volume\n\n\nPWDIS\nIndicator for major direct dischargers to water\n\n\nPNPL\nProximity to National Priorities List (NPL) sites\n\n\nPRMP\nProximity to Risk Management Plan (RMP) facilities\n\n\nPTSDF\nProximity to Treatment Storage and Disposal (TSDF) facilities\n\n\nOZONE\nOzone level in air\n\n\nPM25\nPM2.5 level in air\n\n\n\n\nsea_ejscreen.plot()"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#census-data",
    "href": "studio/week04/studio4_geosnap.html#census-data",
    "title": "geosnap and geoprocessing",
    "section": "",
    "text": "from geosnap.io import get_acs\n\nca = get_acs(datasets, state_fips=['06'], level='tract', years=[2016])\n\n/home/serge/miniforge3/envs/385f24/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_acs()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nThe ca variable now holds a geodataframe of California census data at the tract level. To get a different year or a different geographic level, we could specify different input parameters to the get_acs function\n\nca.head()\n\n\n\n\n\n\n\n\ngeoid\nn_mexican_pop\nn_cuban_pop\nn_puerto_rican_pop\nn_russian_pop\nn_italian_pop\nn_german_pop\nn_irish_pop\nn_scandaniavian_pop\nn_foreign_born_pop\n...\np_poverty_rate\np_poverty_rate_over_65\np_poverty_rate_children\np_poverty_rate_white\np_poverty_rate_black\np_poverty_rate_hispanic\np_poverty_rate_native\np_poverty_rate_asian\ngeometry\nyear\n\n\n\n\n0\n06001400100\n55.0\n0.0\n13.0\n49.0\n62.0\n147.0\n13.0\n8.0\n843.0\n...\n3.752906\n0.531385\n0.631020\n3.055463\n0.000000\n0.000000\n0.0\n0.000000\nMULTIPOLYGON (((-122.24692 37.88544, -122.2466...\n2016\n\n\n1\n06001400200\n118.0\n0.0\n25.0\n17.0\n39.0\n57.0\n26.0\n6.0\n243.0\n...\n5.430328\n1.946721\n0.000000\n4.047131\n0.000000\n0.563525\n0.0\n0.000000\nMULTIPOLYGON (((-122.25792 37.84261, -122.2577...\n2016\n\n\n2\n06001400300\n171.0\n0.0\n0.0\n0.0\n154.0\n81.0\n75.0\n0.0\n857.0\n...\n8.732777\n1.765962\n0.329905\n3.299049\n3.648360\n0.426936\n0.0\n0.000000\nMULTIPOLYGON (((-122.26563 37.83764, -122.2655...\n2016\n\n\n3\n06001400400\n127.0\n9.0\n0.0\n56.0\n55.0\n84.0\n37.0\n0.0\n471.0\n...\n6.445406\n0.721501\n0.000000\n3.799904\n0.673401\n0.553151\n0.0\n0.000000\nMULTIPOLYGON (((-122.26183 37.84162, -122.2618...\n2016\n\n\n4\n06001400500\n282.0\n29.0\n11.0\n10.0\n7.0\n103.0\n51.0\n0.0\n635.0\n...\n9.081168\n0.375033\n0.000000\n4.178945\n3.375301\n3.402089\n0.0\n0.642915\nMULTIPOLYGON (((-122.26951 37.84858, -122.2693...\n2016\n\n\n\n\n5 rows × 158 columns\n\n\n\n\nca.plot()\n\n\n\n\n\n\n\n\nTo trim down the existing dataset, for example to “slice out” the tracts in San Diego county, we use pandas dataframe operations. Here we use the geoid column to select tracts that begin with “06073”, which is the county FIPS code for San Diego\n\nsd = ca[ca.geoid.str.startswith('06073')]\n\n\nsd.plot()"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#epa-environmental-justice-screening-data",
    "href": "studio/week04/studio4_geosnap.html#epa-environmental-justice-screening-data",
    "title": "geosnap and geoprocessing",
    "section": "",
    "text": "The Environmental Protection Agency (EPA)’s envrironmental justice screening tool (EJSCREEN) is a national dataset that provides a wealth of environmental (and some demographic) data at a blockgroup level. For a full list of indicators and their metadata, see the EPA page, but this dataset includes important variables like air toxics cancer risk,ozone concentration in the air, particulate matter, and proximity to superfund sites.\nThe EJSCREEN data can be queried similarly to the ACS data. For example to get blockgroup-level data for the Seattle metropolitan region in 2019, we would use the following\n\nsea_ejscreen = gio.get_ejscreen(datasets, msa_fips=\"42660\", years=2019).to_crs(4326)\n\n/home/serge/miniforge3/envs/385f24/lib/python3.10/site-packages/geosnap/_data.py:16: UserWarning: Streaming data from S3. Use `geosnap.io.store_ejscreen()` to store the data locally for better performance\n  warn(warning_msg)\n\n\nA description of the variables in the EJSCREEN data is available here. A subset of the interesting variables we might examine is provided in the table below\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nDSLPM\nDiesel particulate matter level in air\n\n\nCANCER\nAir toxics cancer risk\n\n\nRESP\nAir toxics respiratory hazard index\n\n\nPTRAF\nTraffic proximity and volume\n\n\nPWDIS\nIndicator for major direct dischargers to water\n\n\nPNPL\nProximity to National Priorities List (NPL) sites\n\n\nPRMP\nProximity to Risk Management Plan (RMP) facilities\n\n\nPTSDF\nProximity to Treatment Storage and Disposal (TSDF) facilities\n\n\nOZONE\nOzone level in air\n\n\nPM25\nPM2.5 level in air\n\n\n\n\nsea_ejscreen.plot()"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#geospatial-operations",
    "href": "studio/week04/studio4_geosnap.html#geospatial-operations",
    "title": "geosnap and geoprocessing",
    "section": "Geospatial Operations",
    "text": "Geospatial Operations\nGeopandas can carry out all standard GIS operations using methods implemented on a GeoDataFrame, for example\n\nclip: “cut” the extent of one dataset using the boundaries of another\ndissolve: aggregate geometries using a common value from an attribute (e.g. remove interior boundaries from larger container polygons, e.g. counties within a state)\nsimplify: remove vertices from the input geometries\nbuffer: extend the boundaries of input geometries by a fixed distance (always returns polygons)\ncentroid: compute the geometric center of input geometries (always returns points)\nconvex/concave hull: compute the most efficient convex/convave polygon that contains vertices from all input geometries\n\nBy combining these operations along with spatial predicates, we can create queries based on the topological relationships between two sets of geographic units, which is often critical for creating variables of interest.\nTo demonstrate, we will first collect data from OpenStreetMap (OSM), specifically highways in the Seattle metro. In OSM parlance, this means we’re querying for “highways” with the “motorway” tag (which means “the highest-performance roads within a territory. It should be used only on roads with control of access, or selected roads with limited access depending on the local context and prevailing convention. Those roads are generally referred to as motorways, freeways or expressways in English.”)\n\nimport osmnx as ox\n\n\nhighways = ox.features_from_polygon(\n    sea_ejscreen.union_all(), tags={\"highway\": \"motorway\"}\n)\n\nThis returns a new GeoDataFrame storing each highway as a line feature.\n\nhighways.head()\n\n\n\n\n\n\n\n\n\ngeometry\nhighway\nref\nfixme\npayment:good_to_go\nsource\nname\nlit\nbus:lanes\nhgv\n...\nmotorcycle:lanes:conditional\nsidewalk\nhov:lanes:backward\nhov:lanes:forward\nhazmat\nstart_date\nsidewalk:left\nsidewalk:right\nbridge:movable\nwikidata\n\n\nelement\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nway\n4634293\nLINESTRING (-122.31862 47.64265, -122.3177 47....\nmotorway\nWA 520\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4644156\nLINESTRING (-122.32264 47.65701, -122.3226 47....\nmotorway\nI 5\nNaN\nNaN\nNaN\nShip Canal Bridge\nyes\nNaN\ndesignated\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4644167\nLINESTRING (-122.32242 47.6467, -122.3224 47.6...\nmotorway\nI 5\nNaN\nNaN\nNaN\nShip Canal Bridge\nyes\nNaN\ndesignated\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4644173\nLINESTRING (-122.32265 47.6467, -122.32258 47....\nmotorway\nI 5 Express\nNaN\nNaN\nNaN\nShip Canal Bridge\nyes\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4709507\nLINESTRING (-122.32598 47.73592, -122.32558 47...\nmotorway\nI 5\nNaN\nNaN\nNaN\nNaN\nNaN\ndesignated|||\ndesignated\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 104 columns\n\n\n\n\nhighways.plot()\n\n\n\n\n\n\n\n\nNotice in the call to features_from_polygon above, we used the unary_union operator on the Seattle tracts dataframe. This effectively combines all the tracts into a single polygon so we are querying anything that intersects any tract, rather than querying intersections with each tract individually. We can do the same thing on the highway GeoDataFrame to see the effect\n\n# note in geopandas &lt;1.0 this is `highways.unary_union`\n\nhw_union = highways.union_all()\n\n\nhw_union\n\n\n\n\n\n\n\n\nNow hw_union is a single shapely.Polygon with no attribute information\n\ngpd.GeoDataFrame(geometry=[hw_union], crs=4326).explore(tiles='CartoDB Positron')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "studio/week04/studio4_geosnap.html#integrating-spatial-datasets",
    "href": "studio/week04/studio4_geosnap.html#integrating-spatial-datasets",
    "title": "geosnap and geoprocessing",
    "section": "Integrating Spatial Datasets",
    "text": "Integrating Spatial Datasets\nLet’s assume the role of a public health epidemiologist who is interested in equity issues surrounding exposure to highways and automobile emissions. We may be interested in who lives near the highway and whether the population nearby experiences a heightened exposure to toxic emissions.\n\nSelect by Location\nOne simple question would be, which tracts have a highway run through them? We can formalize that by asking which tracts intersect the highway system.\n\nhighway_blockgroups = sea_ejscreen[sea_ejscreen.intersects(hw_union)]\nhighway_blockgroups.plot()\n\n\n\n\n\n\n\n\nA more complicated question is, which tracts are within 1.5km of a road? This is ‘complicated’ because it forces us to formalize an ill-defined relationship: the distance between a polygon and the nearest point on a line. What does it mean for the polygon to be ‘within’ 1.5km? Does that mean the whole tract? most of it? any part of it?\nIf we can define a most suitable distance measure, the technical selection is easy to execute using an intermediate geometry.\n\nroad_buffer = highways.to_crs(highways.estimate_utm_crs()).buffer(1500)\n\n\ngpd.GeoDataFrame(geometry=[road_buffer.union_all()], crs=road_buffer.crs).explore(tiles='CartoDB Positron')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nsea_ejscreen.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsea_ejscreen[sea_ejscreen.intersects(road_buffer.union_all())]\n\n\n\n\n\n\n\n\ngeoid\nACSTOTPOP\nACSIPOVBAS\nACSEDUCBAS\nACSTOTHH\nACSTOTHU\nMINORPOP\nMINORPCT\nLOWINCOME\nLOWINCPCT\n...\nT_PM25_P2\nT_PM25_P6\nAREALAND\nAREAWATER\nNPL_CNT\nTSDF_CNT\nShape_Length\nShape_Area\ngeometry\nyear\n\n\n\n\n\n\n0 rows × 368 columns\n\n\n\nThis gives us back nothing… There is no intersection because the EJSCREEN data is still stored in Lat/Long, but we reprojected the road buffer into UTM\n\nsea_ejscreen = sea_ejscreen.to_crs(road_buffer.crs)\n\nBy selecting the tracts that intersect with the interstate buffer, we are codifying the tracts as ‘near the highway’ if any portion of a tract is within 1.5km. This can be an awkard choice when polygons are irregularly shaped or heteogeneously sized (Census tracts are both). This means large tracts get included as ‘near’, even when a small portion of the polygon is within the 1.5km threshold (like the tract on the far Eastern edge).\n\nsea_ejscreen[sea_ejscreen.intersects(road_buffer.union_all())].plot()\n\n\n\n\n\n\n\n\nAlternatively, we might ask, which tracts have their center within 1.5km of a highway? Or more formally, which tracts have their centroids intersect with the 1500m buffer.\n\nsea_ejscreen[sea_ejscreen.centroid.intersects(road_buffer.union_all())].plot()\n\n\n\n\n\n\n\n\nIf we are happy with that definition of proximity, we can use the spatial selection to create and update a new attribute on the dataframe. Here, we will select the tracts whose centroids are within the threshold distance, then create a new column called “highway_buffer”, set to “inside” (using the indices of the spatial selection to define which rows are being set).\n\n# get the dataframe index of the tracts intersecting the buffer\n\ninside_idx = sea_ejscreen[\n    sea_ejscreen.centroid.intersects(road_buffer.union_all())\n].index\n\n\n# set the 'highway_buffer' attribute to 'inside' for the indices within\nsea_ejscreen.loc[inside_idx, \"highway_buffer\"] = \"inside\"\n\n# fill all NaN values in the column with 'outside'\nsea_ejscreen[\"highway_buffer\"] = sea_ejscreen[\"highway_buffer\"].fillna(\"outside\").astype('category')\n\nNow ‘highway_buffer’ is a binary variable defining whether a tract is “near” a highway or not. We could have set these values to one and zero, but setting them as a categorical variable means that the geopandas plot method uses a different kind of coloring scheme that matches the data more appropriately.\n\nsea_ejscreen[['highway_buffer', 'geometry']].explore(\"highway_buffer\", legend=True, tiles='CartoDB Positron')\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nThen, we can use this spatial distinction as a grouping variable to look at average values inside versus outside the threshold zone.\n\nsea_ejscreen.groupby(\"highway_buffer\")[[\"PM25\", \"DSLPM\", \"MINORPCT\"]].mean()\n\n/tmp/ipykernel_162753/860608503.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  sea_ejscreen.groupby(\"highway_buffer\")[[\"PM25\", \"DSLPM\", \"MINORPCT\"]].mean()\n\n\n\n\n\n\n\n\n\nPM25\nDSLPM\nMINORPCT\n\n\nhighway_buffer\n\n\n\n\n\n\n\ninside\n6.298818\n1.043487\n0.404843\n\n\noutside\n6.061902\n0.723160\n0.283832\n\n\n\n\n\n\n\nOn average, both PM2.5 and Disel Particulate Matter levels are higher for tracts located within 1.5km of an OSM ‘motorway’ (what we think is probably an interstate highway). The share of residents identifying as a racial or ethnic miority is also 12% higher on average.\n\n\nSpatial Join\nIn the example above, we use only the geometric relationship between observations to make selections from one dataset. In other cases, we need to attach attribute data from one dataset to the other using spatial relationships. For example we might want to count the number of health clinics that fall inside each census tract. This actually entails two operations: attaching census tract identifiers to each clinic, then aggregating by tract identifier and counting all clinics within\nOnce again we will query OSM, this time looking for an amenity with the ‘clinic’ tag\n\nclinics = ox.features_from_polygon(\n    sea_ejscreen.to_crs(4326).union_all(), tags={\"amenity\": \"clinic\"}\n)\nclinics = clinics.reset_index().set_index(\"id\")\n\n\nclinics.head()\n\n\n\n\n\n\n\n\nelement\ngeometry\namenity\nhealthcare\nname\nbrand\nbrand:wikidata\nhealthcare:counselling\noperator\noperator:wikidata\n...\nstart_date\nele\ngnis:feature_id\nref\nbuilding:material\nwaste_disposal\nwikidata\nowner\nlayer\ntype\n\n\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1242268219\nnode\nPOINT (-122.11025 47.67027)\nclinic\nclinic\nOverlake Clinics - Urgent Care\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1248759443\nnode\nPOINT (-122.35027 47.64978)\nclinic\nclinic\nZoomCare\nZoomCare\nQ64120374\nNaN\nZoomCare\nQ64120374\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1273816342\nnode\nPOINT (-122.18631 47.62807)\nclinic\nclinic\nEvergreen Integrative Medicine L.L.P.\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1273816350\nnode\nPOINT (-122.186 47.62807)\nclinic\nclinic\nRomanick MD PLLC\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1381933749\nnode\nPOINT (-122.18496 47.62548)\nclinic\nclinic\nMedical Arts Associates\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 110 columns\n\n\n\nThe clinics dataset now has manuy types of clinics, and also has a mixed geometry type; some clinics are stored as polygons (where the building footprint has been digitized) whereas others are simply stored as points. Lets filter the dataset to include only those defined as clinic (e.g. not counseling) and only points (not polygons)\nWe can do this in two steps like\n\nclinics = clinics[(clinics.healthcare == \"clinic\") & (clinics.element == \"node\")]\n\n\nclinics.explore(tiles='CartoDB Positron', tooltip=['name', 'healthcare'])\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nclinics = clinics.to_crs(sea_ejscreen.crs)\n\n\nclinics_geoid = clinics.sjoin(sea_ejscreen[[\"geoid\", \"geometry\"]])\n\n\nclinics_geoid.head()\n\n\n\n\n\n\n\n\nelement\ngeometry\namenity\nhealthcare\nname\nbrand\nbrand:wikidata\nhealthcare:counselling\noperator\noperator:wikidata\n...\ngnis:feature_id\nref\nbuilding:material\nwaste_disposal\nwikidata\nowner\nlayer\ntype\nindex_right\ngeoid\n\n\nid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1242268219\nnode\nPOINT (566792.704 5280036.188)\nclinic\nclinic\nOverlake Clinics - Urgent Care\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n1326\n530330323092\n\n\n1248759443\nnode\nPOINT (548794.035 5277580.42)\nclinic\nclinic\nZoomCare\nZoomCare\nQ64120374\nNaN\nZoomCare\nQ64120374\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n172\n530330049002\n\n\n1273816342\nnode\nPOINT (561132.643 5275283.673)\nclinic\nclinic\nEvergreen Integrative Medicine L.L.P.\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n699\n530330237003\n\n\n1273816350\nnode\nPOINT (561155.932 5275284.017)\nclinic\nclinic\nRomanick MD PLLC\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n699\n530330237003\n\n\n1381933749\nnode\nPOINT (561236.936 5274997.501)\nclinic\nclinic\nMedical Arts Associates\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n699\n530330237003\n\n\n\n\n5 rows × 112 columns\n\n\n\nNow we want to count clinics in each geoid. Since we know osmid uniquely identifies each clinic, we can reset the index, then groupby the ‘geoid’ variable, counting the unique ’osmid’s in each one\n\nclinic_count = clinics_geoid.reset_index().groupby(\"geoid\").count()[\"id\"]\n\n\nclinic_count\n\ngeoid\n530330001003    1\n530330002002    1\n530330006004    2\n530330012004    1\n530330013003    1\n               ..\n530610519252    1\n530610527072    1\n530610535093    1\n530610538023    1\n530610538024    1\nName: id, Length: 177, dtype: int64\n\n\nclinic_count is now a pandas series where the index refers to the census tract of interest and the value corresponds to the number of clinics that fall inside.\n\nsea_ejscreen = sea_ejscreen.merge(\n    clinic_count.rename(\"clinic_count\"), left_on=\"geoid\", right_index=True, how=\"left\"\n)\n\n\nsea_ejscreen.clinic_count\n\n0       NaN\n1       NaN\n2       1.0\n3       NaN\n4       NaN\n       ... \n2478    NaN\n2479    NaN\n2480    NaN\n2481    NaN\n2482    NaN\nName: clinic_count, Length: 2483, dtype: float64\n\n\nNow the sea_ejscreen GeoDataFrame has a new column called ‘clinic_count’ that holds the number of clinics inside. Since we know that NaN (Not a number) refers to zero in this case, we can go ahead and fill the missing data.\n\nsea_ejscreen[\"clinic_count\"] = sea_ejscreen[\"clinic_count\"].fillna(0)\n\n\nsea_ejscreen[['clinic_count', 'geometry']].explore(\n    \"clinic_count\", scheme='fisher_jenks', cmap='Reds', tiles='CartoDB DarkMatter', style_kwds=dict(weight=0.2)\n)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "studio/week03/studio.html",
    "href": "studio/week03/studio.html",
    "title": "Studio 03 GeoPandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 18, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week03/studio.html#instructions",
    "href": "studio/week03/studio.html#instructions",
    "title": "Studio 03 GeoPandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 18, 2024 3:30pm\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week03/studio.html#input-files",
    "href": "studio/week03/studio.html#input-files",
    "title": "Studio 03 GeoPandas",
    "section": "Input Files",
    "text": "Input Files\nThe files you will read are:\n~/data/385/studio03/schools.geojson\n~/data/385/studio03/streets.geojson\n~/data/385/studio03/catchments.geojson"
  },
  {
    "objectID": "studio/week03/studio.html#reading-the-spatial-data-files",
    "href": "studio/week03/studio.html#reading-the-spatial-data-files",
    "title": "Studio 03 GeoPandas",
    "section": "Reading the spatial data files",
    "text": "Reading the spatial data files\nRead in each of three data files to create three geodataframes: schools, catchments, streets\n\nimport geopandas as gpd\n\n# uncomment the following line and complete the code\n# schools = gpd.read_file(\"???\")"
  },
  {
    "objectID": "studio/week03/studio.html#report-the-number-of-rows-in-each-geodataframe",
    "href": "studio/week03/studio.html#report-the-number-of-rows-in-each-geodataframe",
    "title": "Studio 03 GeoPandas",
    "section": "Report the number of rows in each GeoDataFrame",
    "text": "Report the number of rows in each GeoDataFrame"
  },
  {
    "objectID": "studio/week03/studio.html#determine-the-datatype-of-the-geoseries-for-each-geodataframe",
    "href": "studio/week03/studio.html#determine-the-datatype-of-the-geoseries-for-each-geodataframe",
    "title": "Studio 03 GeoPandas",
    "section": "Determine the datatype of the geoseries for each GeoDataFrame",
    "text": "Determine the datatype of the geoseries for each GeoDataFrame"
  },
  {
    "objectID": "studio/week03/studio.html#determine-the-student-density-in-each-catchment",
    "href": "studio/week03/studio.html#determine-the-student-density-in-each-catchment",
    "title": "Studio 03 GeoPandas",
    "section": "Determine the student density in each catchment",
    "text": "Determine the student density in each catchment\nAssuming that the catchment student populations are 140, 200, 75, create a new variable that is called sdensity that is defined as the ratio of the number of students per unit area of the catchment."
  },
  {
    "objectID": "studio/week03/studio.html#plot-the-sdensity-variable",
    "href": "studio/week03/studio.html#plot-the-sdensity-variable",
    "title": "Studio 03 GeoPandas",
    "section": "Plot the sdensity variable",
    "text": "Plot the sdensity variable"
  },
  {
    "objectID": "studio/week03/studio.html#plotting-multiple-layers",
    "href": "studio/week03/studio.html#plotting-multiple-layers",
    "title": "Studio 03 GeoPandas",
    "section": "Plotting multiple layers",
    "text": "Plotting multiple layers\nRead the guide on Control the order of multiple layers in a plot and plot the three layers together on one plot with the catchments below the streets and schools.\nEnsure that the different geometries are visually distinguishable."
  },
  {
    "objectID": "studio/week02/pandas.html",
    "href": "studio/week02/pandas.html",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "In this notebook we introduce pandas (McKinney 2010) which is the main package for working with data in Python."
  },
  {
    "objectID": "studio/week02/pandas.html#introduction",
    "href": "studio/week02/pandas.html#introduction",
    "title": "Introduction to Pandas",
    "section": "",
    "text": "In this notebook we introduce pandas (McKinney 2010) which is the main package for working with data in Python."
  },
  {
    "objectID": "studio/week02/pandas.html#import",
    "href": "studio/week02/pandas.html#import",
    "title": "Introduction to Pandas",
    "section": "Import",
    "text": "Import\nWe start by importing the package, and aliasing it as pd\n\nimport pandas as pd\n\nAliasing allows us to use pd in place of having to type out pandas in what follows."
  },
  {
    "objectID": "studio/week02/pandas.html#dataframe-creation",
    "href": "studio/week02/pandas.html#dataframe-creation",
    "title": "Introduction to Pandas",
    "section": "DataFrame Creation",
    "text": "DataFrame Creation\nPandas main data structure is called a DataFrame. We will create our first DataFrame by reading a csv file.\n\n1home = \"/home/serge\"\ncities_df = pd.read_csv(f\"{home}/data/385/studio02/cities.csv\")\n\n\n1\n\nChange the value home to be equal to jupyter-student where student is your id.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nBe sure to reread the instructions to change the path in the previous cell if you wish to follow along in your own notebook.\n\n\nAsking for the values of the cities_df give us:\n\ncities_df\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\n\n\n\n\n\n\n\nThis data set is composed of the capital cities for the 50 states.\nWe can see what type of object cities_df is using type:\n\ntype(cities_df)\n\npandas.core.frame.DataFrame\n\n\nAs an analogy, you can think of a DataFrame as a spreadsheet with rows and columns. This mental model will help to orient you. We will see that the DataFrame extends spreadsheets in powerful ways for data analysis.\nA DataFrame, like most Python objects, has a number of attributes and methods.\nIts shape attribute tells us how many observations and variables we have.\n\ncities_df.shape\n\n(50, 4)\n\n\nIn this case our data set has 50 observations on 4 variables."
  },
  {
    "objectID": "studio/week02/pandas.html#series",
    "href": "studio/week02/pandas.html#series",
    "title": "Introduction to Pandas",
    "section": "Series",
    "text": "Series\nEach variable is stored as a Series:\n\ntype(cities_df.longitude)\n\npandas.core.series.Series\n\n\n\ncities_df.longitude\n\n0     -86.300568\n1    -134.420212\n2    -112.096962\n3     -92.288986\n4    -121.493629\n5    -104.984856\n6     -72.682198\n7     -75.519722\n8    -157.857376\n9     -84.281296\n10    -84.388229\n11   -116.199722\n12    -89.654961\n13    -86.162643\n14    -93.603729\n15    -95.677956\n16    -84.875374\n17    -91.187393\n18    -69.781693\n19    -76.490936\n20    -71.063698\n21    -84.555328\n22    -93.102211\n23    -90.182106\n24    -92.172935\n25   -112.018417\n26    -96.699654\n27   -119.766121\n28    -71.537994\n29    -74.769913\n30   -105.939728\n31    -78.639099\n32   -100.783318\n33    -73.757874\n34    -82.999069\n35    -97.503342\n36   -123.030403\n37    -76.883598\n38    -71.414963\n39    -81.033211\n40   -100.346405\n41    -86.784241\n42    -97.740349\n43   -111.888237\n44    -72.580536\n45    -77.433640\n46   -122.905014\n47    -81.612328\n48    -89.384445\n49   -104.820236\nName: longitude, dtype: float64\n\n\nWhen we ask for the contents of the series, we see two columns of numbers. The first is a set of integers which is the index. Each value in the index locates the particular observation in the series.\nThe next column of values stores the values of the series. Here the values are decimal degrees of longitude for the capital cities."
  },
  {
    "objectID": "studio/week02/pandas.html#data-types",
    "href": "studio/week02/pandas.html#data-types",
    "title": "Introduction to Pandas",
    "section": "Data Types",
    "text": "Data Types\nThe info method of the DataFrame will summarize information about our DataFrame\n\ncities_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50 entries, 0 to 49\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   name         50 non-null     object \n 1   description  50 non-null     object \n 2   latitude     50 non-null     float64\n 3   longitude    50 non-null     float64\ndtypes: float64(2), object(2)\nmemory usage: 1.7+ KB\n\n\nWe have four columns, the first two of which are of type object and the last two are of type float64.\nThe names of our variables in the DataFrame are stored in the columns attribute:\n\ncities_df.columns\n\nIndex(['name', 'description', 'latitude', 'longitude'], dtype='object')\n\n\nWe can use the column name to access the particular series:\n\ncities_df.longitude\n\n0     -86.300568\n1    -134.420212\n2    -112.096962\n3     -92.288986\n4    -121.493629\n5    -104.984856\n6     -72.682198\n7     -75.519722\n8    -157.857376\n9     -84.281296\n10    -84.388229\n11   -116.199722\n12    -89.654961\n13    -86.162643\n14    -93.603729\n15    -95.677956\n16    -84.875374\n17    -91.187393\n18    -69.781693\n19    -76.490936\n20    -71.063698\n21    -84.555328\n22    -93.102211\n23    -90.182106\n24    -92.172935\n25   -112.018417\n26    -96.699654\n27   -119.766121\n28    -71.537994\n29    -74.769913\n30   -105.939728\n31    -78.639099\n32   -100.783318\n33    -73.757874\n34    -82.999069\n35    -97.503342\n36   -123.030403\n37    -76.883598\n38    -71.414963\n39    -81.033211\n40   -100.346405\n41    -86.784241\n42    -97.740349\n43   -111.888237\n44    -72.580536\n45    -77.433640\n46   -122.905014\n47    -81.612328\n48    -89.384445\n49   -104.820236\nName: longitude, dtype: float64\n\n\n\ncities_df.name\n\n0            Alabama\n1             Alaska\n2            Arizona\n3           Arkansas\n4         California\n5           Colorado\n6        Connecticut\n7           Delaware\n8             Hawaii\n9            Florida\n10           Georgia\n11             Idaho\n12          Illinois\n13           Indiana\n14              Iowa\n15            Kansas\n16          Kentucky\n17         Louisiana\n18             Maine\n19          Maryland\n20     Massachusetts\n21          Michigan\n22         Minnesota\n23       Mississippi\n24          Missouri\n25           Montana\n26          Nebraska\n27            Nevada\n28     New Hampshire\n29        New Jersey\n30        New Mexico\n31    North Carolina\n32      North Dakota\n33          New York\n34              Ohio\n35          Oklahoma\n36            Oregon\n37      Pennsylvania\n38      Rhode Island\n39    South Carolina\n40      South Dakota\n41         Tennessee\n42             Texas\n43              Utah\n44           Vermont\n45          Virginia\n46        Washington\n47     West Virginia\n48         Wisconsin\n49           Wyoming\nName: name, dtype: object\n\n\nAs each series is an object, it too comes with attributes and methods:\n\ncities_df.longitude.max()\n\n-69.781693\n\n\n\ncities_df.name.max()\n\n'Wyoming'\n\n\n\ncities_df.longitude.mean()\n\n-93.46593707999999\n\n\n\ncities_df.name.min()\n\n'Alabama'\n\n\n\ncities_df.longitude.describe()\n\ncount     50.000000\nmean     -93.465937\nstd       18.669710\nmin     -157.857376\n25%     -103.811006\n50%      -89.918533\n75%      -79.237627\nmax      -69.781693\nName: longitude, dtype: float64\n\n\n\ncities_df.name.describe()\n\ncount          50\nunique         50\ntop       Alabama\nfreq            1\nName: name, dtype: object\n\n\nNote how the same method behaves for series of different types."
  },
  {
    "objectID": "studio/week02/pandas.html#creating-new-series",
    "href": "studio/week02/pandas.html#creating-new-series",
    "title": "Introduction to Pandas",
    "section": "Creating new series",
    "text": "Creating new series\nA common workflow in data analysis is to create, or derive, new variables based upon existing variables. For example, let’s define a variable that will denote whether a capital city is in the east or west of the country. Here we will use the median longitude as the comparison point:\n\ncities_df.longitude.median()\n\n-89.9185335\n\n\n\ncities_df.longitude &lt; cities_df.longitude.median()\n\n0     False\n1      True\n2      True\n3      True\n4      True\n5      True\n6     False\n7     False\n8      True\n9     False\n10    False\n11     True\n12    False\n13    False\n14     True\n15     True\n16    False\n17     True\n18    False\n19    False\n20    False\n21    False\n22     True\n23     True\n24     True\n25     True\n26     True\n27     True\n28    False\n29    False\n30     True\n31    False\n32     True\n33    False\n34    False\n35     True\n36     True\n37    False\n38    False\n39    False\n40     True\n41    False\n42     True\n43     True\n44    False\n45    False\n46     True\n47    False\n48    False\n49     True\nName: longitude, dtype: bool\n\n\nThis creates a series that has data type bool, meaning True if the city is at a longitude less than that of the median longitude. False if it is east of that value. We can use this information to create a new series on the DataFrame called east:\n\ncities_df['east'] = cities_df.longitude &gt; cities_df.longitude.median()\n\nAnd, we can do this for a second variable south:\n\ncities_df['south'] = cities_df.latitude &lt; cities_df.latitude.median()\n\nBased on those two Boolean variables we can create an additional variable called region that tells us which of four regions the capital city is located in.\n\ncities_df['region'] = 4 * cities_df.east * cities_df.south + 3 * (1 - cities_df.east) * cities_df.south \\\n                      + 2 * (1-cities_df.east) * (1-cities_df.south) + cities_df.east * (1-cities_df.south)\n\nregion takes on four values, 1 if the city is in the North East, 2 North West, 3 South West, and 4 South East.\n\ncities_df.head(20)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\n4\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\n2\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\n3\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\n3\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\n3\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\n3\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\n1\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\n4\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\n3\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\n4\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\n4\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\n2\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\n1\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\n4\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\n2\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\n3\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\n4\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\n3\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\n1\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\n4"
  },
  {
    "objectID": "studio/week02/pandas.html#plotting",
    "href": "studio/week02/pandas.html#plotting",
    "title": "Introduction to Pandas",
    "section": "Plotting",
    "text": "Plotting\nPandas comes with built-in plotting facilities. We can try out the default plot method:\n\ncities_df.plot('longitude', 'latitude')\n\n\n\n\n\n\n\n\nThis isn’t quite what we want as the default is to plot the first series and the second series together with line segments connecting each pair of sequential observations.\nBut we can try a different method to get what we want:\n\ncities_df.plot.scatter('longitude', 'latitude')\n\n\n\n\n\n\n\n\nThat’s better as now we see the cities represented as points.\n\n\n\n\n\n\nWarning\n\n\n\nWe are treating longitude and latitude as Cartesian coordinates in the plots. This is technically not correct as they are spherical coordinates. We will correct this later on in the course when we get to spatial data analysis proper.\n\n\nThere are a number of powerful visualization packages in Python that allow us to go beyond what is available in Pandas. To see one of them here, we import seaborn\n\nimport seaborn as sbn\n\nand redo our plot:\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude');\n\n\n\n\n\n\n\n\nSo far, not much difference from what we did with pandas. But we can specify a hue variable to distinguish what region the cities are in:\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude', hue='region');\n\n\n\n\n\n\n\n\nGreat. But the numbers on the legend are not that informative. Let’s change them:\n\ncities_df.region.map({1:'NE', 2:'NW', 3:'SW', 4:'SE'})\n\n0     SE\n1     NW\n2     SW\n3     SW\n4     SW\n5     SW\n6     NE\n7     SE\n8     SW\n9     SE\n10    SE\n11    NW\n12    NE\n13    SE\n14    NW\n15    SW\n16    SE\n17    SW\n18    NE\n19    SE\n20    NE\n21    NE\n22    NW\n23    SW\n24    SW\n25    NW\n26    NW\n27    SW\n28    NE\n29    NE\n30    SW\n31    SE\n32    NW\n33    NE\n34    NE\n35    SW\n36    NW\n37    NE\n38    NE\n39    SE\n40    NW\n41    SE\n42    SW\n43    NW\n44    NE\n45    SE\n46    NW\n47    SE\n48    NE\n49    NW\nName: region, dtype: object\n\n\n\ncities_df['region'] = cities_df.region.map({1:'NE', 2:'NW', 3:'SW', 4:'SE'})\n\n\nsbn.scatterplot(cities_df, x='longitude', y='latitude', hue='region');\n\n\n\n\n\n\n\n\nMuch better.\n\ncities_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW"
  },
  {
    "objectID": "studio/week02/pandas.html#dataframe-operations",
    "href": "studio/week02/pandas.html#dataframe-operations",
    "title": "Introduction to Pandas",
    "section": "DataFrame Operations",
    "text": "DataFrame Operations\nPandas has a number of powerful methods that allow us to manipulate the DataFrame in interesting ways. Here we look at three:\n\nsorting\ngrouping\nfiltering\n\n\nSorting\nWe can sort the DataFrame by the values of a given column. For example, to find the southern-most capital city:\n\ncities_df.sort_values(by='latitude')\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n\n\n\n\n\nTo find the northern-most city:\n\ncities_df.sort_values(by='latitude', ascending=False)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n\n\n\n\n\n\n\nIf we don’t want to see all the other columns, we can subset the dataframe first:\n\ncities_df[['name', 'description', 'latitude']].sort_values(by='latitude', ascending=False)\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n\n\n46\nWashington\nOlympia\n47.035805\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n\n\n25\nMontana\nHelena\n46.585709\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n\n\n36\nOregon\nSalem\n44.938461\n\n\n40\nSouth Dakota\nPierre\n44.367031\n\n\n18\nMaine\nAugusta\n44.307167\n\n\n44\nVermont\nMontpelier\n44.262436\n\n\n11\nIdaho\nBoise\n43.617775\n\n\n28\nNew Hampshire\nConcord\n43.206898\n\n\n48\nWisconsin\nMadison\n43.074684\n\n\n21\nMichigan\nLansing\n42.733635\n\n\n33\nNew York\nAlbany\n42.652843\n\n\n20\nMassachusetts\nBoston\n42.358162\n\n\n38\nRhode Island\nProvidence\n41.830914\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n\n\n14\nIowa\nDes Moines\n41.591087\n\n\n49\nWyoming\nCheyenne\n41.140259\n\n\n26\nNebraska\nLincoln\n40.808075\n\n\n43\nUtah\nSalt Lake City\n40.777477\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n\n\n29\nNew Jersey\nTrenton\n40.220596\n\n\n34\nOhio\nColumbus\n39.961346\n\n\n12\nIllinois\nSpringfield\n39.798363\n\n\n13\nIndiana\nIndianapolis\n39.768623\n\n\n5\nColorado\nDenver\n39.739227\n\n\n27\nNevada\nCarson City\n39.163914\n\n\n7\nDelaware\nDover\n39.157307\n\n\n15\nKansas\nTopeka\n39.048191\n\n\n19\nMaryland\nAnnapolis\n38.978764\n\n\n24\nMissouri\nJefferson City\n38.579201\n\n\n4\nCalifornia\nSacramento\n38.576668\n\n\n47\nWest Virginia\nCharleston\n38.336246\n\n\n16\nKentucky\nFrankfort\n38.186722\n\n\n45\nVirginia\nRichmond\n37.538857\n\n\n41\nTennessee\nNashville\n36.165810\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n\n\n3\nArkansas\nLittle Rock\n34.746613\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n\n\n2\nArizona\nPhoenix\n33.448143\n\n\n0\nAlabama\nMontgomery\n32.377716\n\n\n23\nMississippi\nJackson\n32.303848\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n\n\n9\nFlorida\nTallahassee\n30.438118\n\n\n42\nTexas\nAustin\n30.274670\n\n\n8\nHawaii\nHonolulu\n21.307442\n\n\n\n\n\n\n\n\n\nGrouping\nThe groupby method of the DataFrame allows us to split the dataframe, apply a function, and combine the results. This allows us to group data in interesting ways.\nSuppose we wanted to know how many cities were in the east and west?\n\ncities_df.groupby(by='east').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\nsouth\nregion\n\n\neast\n\n\n\n\n\n\n\n\n\n\nFalse\n25\n25\n25\n25\n25\n25\n\n\nTrue\n25\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\nAnd for south and north:\n\ncities_df.groupby(by='south').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nregion\n\n\nsouth\n\n\n\n\n\n\n\n\n\n\nFalse\n25\n25\n25\n25\n25\n25\n\n\nTrue\n25\n25\n25\n25\n25\n25\n\n\n\n\n\n\n\nHow about by region?\n\ncities_df.groupby(by='region').count()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\n\n\nregion\n\n\n\n\n\n\n\n\n\n\nNE\n13\n13\n13\n13\n13\n13\n\n\nNW\n12\n12\n12\n12\n12\n12\n\n\nSE\n12\n12\n12\n12\n12\n12\n\n\nSW\n13\n13\n13\n13\n13\n13\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs we will see later in the course, there are different notions of a spatial median. This will unravel the mystery of why we have equal numbers of cities in the north and south, and east and west, but not in the four regions.\n\n\nIn addition to applying the count method on the groubby object, we could use other functions. For example, we may want to know the median coordinate values in each of the four regions:\n\ncities_df[['region', 'longitude', 'latitude']].groupby(by='region').median()\n\n\n\n\n\n\n\n\nlongitude\nlatitude\n\n\nregion\n\n\n\n\n\n\nNE\n-73.757874\n42.358162\n\n\nNW\n-108.354236\n44.652746\n\n\nSE\n-82.946812\n36.852334\n\n\nSW\n-97.740349\n35.492207\n\n\n\n\n\n\n\n\n\nFiltering\nFiltering allows us to subset the DataFrame based on some conditions. For example, what if we wanted to create a new DataFrame that only contained the southern capital cities:\n\nsouth_df = cities_df[cities_df.south]\n\n\nsouth_df.shape\n\n(25, 7)\n\n\n\nsouth_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n\n\n\n\n\n\n\nAnd to get a DataFrame for the northern cities, we could use a complement filter:\n\nnorth_df = cities_df[~cities_df.south]\n\nThe ~ operator can be thought of flipping the boolean condition.\n\nnorth_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n\n\n\n\n\n\n\nWe could combine these to get the DataFrame for cities in the North East region:\n\nne_df = cities_df[~cities_df.south & cities_df.east]\n\n\nne_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n\n\n\n\n\n\n\nLike most things we will want to do, there are typically multiple ways to accomplish this in Python. Here we can get a set of regional DataFrames in one shot:\n\ndfs = {r:data for r, data in cities_df.groupby('region')}\n\n\ndfs\n\n{'NE':              name   description   latitude  longitude  east  south region\n 6     Connecticut  Hartford&lt;br&gt;  41.764046 -72.682198  True  False     NE\n 12       Illinois   Springfield  39.798363 -89.654961  True  False     NE\n 18          Maine       Augusta  44.307167 -69.781693  True  False     NE\n 20  Massachusetts        Boston  42.358162 -71.063698  True  False     NE\n 21       Michigan       Lansing  42.733635 -84.555328  True  False     NE\n 28  New Hampshire       Concord  43.206898 -71.537994  True  False     NE\n 29     New Jersey       Trenton  40.220596 -74.769913  True  False     NE\n 33       New York        Albany  42.652843 -73.757874  True  False     NE\n 34           Ohio      Columbus  39.961346 -82.999069  True  False     NE\n 37   Pennsylvania    Harrisburg  40.264378 -76.883598  True  False     NE\n 38   Rhode Island    Providence  41.830914 -71.414963  True  False     NE\n 44        Vermont    Montpelier  44.262436 -72.580536  True  False     NE\n 48      Wisconsin       Madison  43.074684 -89.384445  True  False     NE,\n 'NW':             name     description   latitude   longitude   east  south region\n 1         Alaska          Juneau  58.301598 -134.420212  False  False     NW\n 11         Idaho           Boise  43.617775 -116.199722  False  False     NW\n 14          Iowa      Des Moines  41.591087  -93.603729  False  False     NW\n 22     Minnesota        St. Paul  44.955097  -93.102211  False  False     NW\n 25       Montana          Helena  46.585709 -112.018417  False  False     NW\n 26      Nebraska         Lincoln  40.808075  -96.699654  False  False     NW\n 32  North Dakota        Bismarck  46.820850 -100.783318  False  False     NW\n 36        Oregon           Salem  44.938461 -123.030403  False  False     NW\n 40  South Dakota          Pierre  44.367031 -100.346405  False  False     NW\n 43          Utah  Salt Lake City  40.777477 -111.888237  False  False     NW\n 46    Washington         Olympia  47.035805 -122.905014  False  False     NW\n 49       Wyoming        Cheyenne  41.140259 -104.820236  False  False     NW,\n 'SE':               name   description   latitude  longitude  east  south region\n 0          Alabama    Montgomery  32.377716 -86.300568  True   True     SE\n 7         Delaware         Dover  39.157307 -75.519722  True   True     SE\n 9          Florida   Tallahassee  30.438118 -84.281296  True   True     SE\n 10         Georgia   Atlanta&lt;br&gt;  33.749027 -84.388229  True   True     SE\n 13         Indiana  Indianapolis  39.768623 -86.162643  True   True     SE\n 16        Kentucky     Frankfort  38.186722 -84.875374  True   True     SE\n 19        Maryland     Annapolis  38.978764 -76.490936  True   True     SE\n 31  North Carolina       Raleigh  35.780430 -78.639099  True   True     SE\n 39  South Carolina      Columbia  34.000343 -81.033211  True   True     SE\n 41       Tennessee     Nashville  36.165810 -86.784241  True   True     SE\n 45        Virginia      Richmond  37.538857 -77.433640  True   True     SE\n 47   West Virginia    Charleston  38.336246 -81.612328  True   True     SE,\n 'SW':            name     description   latitude   longitude   east  south region\n 2       Arizona         Phoenix  33.448143 -112.096962  False   True     SW\n 3      Arkansas     Little Rock  34.746613  -92.288986  False   True     SW\n 4    California      Sacramento  38.576668 -121.493629  False   True     SW\n 5      Colorado          Denver  39.739227 -104.984856  False   True     SW\n 8        Hawaii        Honolulu  21.307442 -157.857376  False   True     SW\n 15       Kansas          Topeka  39.048191  -95.677956  False   True     SW\n 17    Louisiana     Baton Rouge  30.457069  -91.187393  False   True     SW\n 23  Mississippi         Jackson  32.303848  -90.182106  False   True     SW\n 24     Missouri  Jefferson City  38.579201  -92.172935  False   True     SW\n 27       Nevada     Carson City  39.163914 -119.766121  False   True     SW\n 30   New Mexico        Santa Fe  35.682240 -105.939728  False   True     SW\n 35     Oklahoma   Oklahoma City  35.492207  -97.503342  False   True     SW\n 42        Texas          Austin  30.274670  -97.740349  False   True     SW}\n\n\nThey are stored in a dictionary, so we could access each one using the region ‘key’.\n\ndfs['NE'].head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\n\n\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE"
  },
  {
    "objectID": "studio/week02/pandas.html#merge",
    "href": "studio/week02/pandas.html#merge",
    "title": "Introduction to Pandas",
    "section": "Merge",
    "text": "Merge\nA common workflow in spatial analysis is combining different data sets. Often we will have information on the locations or geographical coordinates in one data set, but that data set may not include any substantive attribute information. We may have a second data set that has the attribute information we are interested in, but this second data set lacks geographical coordinates. So we will have cause to merge the two data sets\n\npopulation_df = pd.read_csv(f\"{home}/data/385/studio02/captial_population.csv\")\n\n\npopulation_df.head()\n\n\n\n\n\n\n\n\nState\nCapital\nSince\nArea\nCityPop\nMSAPop\nCSAPop\nrank_in_state\narea\n\n\n\n\n0\nAlabama\nMontgomery\n1846\n159.8 sq mi (414 km2)\n200603\n386047\n476207.0\n3\n159.8\n\n\n1\nAlaska\nJuneau\n1906\n2,716.7 sq mi (7,036 km2)\n32255\n32255\nNaN\n3\n2716.7\n\n\n2\nArizona\nPhoenix\n1889\n517.6 sq mi (1,341 km2)\n1608139\n4845832\n4899104.0\n1\n517.6\n\n\n3\nArkansas\nLittle Rock\n1821\n116.2 sq mi (301 km2)\n202591\n748031\n912604.0\n1\n116.2\n\n\n4\nCalifornia\nSacramento\n1854\n97.9 sq mi (254 km2)\n524943\n2397382\n2680831.0\n6\n97.9\n\n\n\n\n\n\n\n\nmerged = pd.merge(cities_df, population_df, left_on='name', right_on='State')\n\n\nmerged.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nState\nCapital\nSince\nArea\nCityPop\nMSAPop\nCSAPop\nrank_in_state\narea\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\nAlabama\nMontgomery\n1846\n159.8 sq mi (414 km2)\n200603\n386047\n476207.0\n3\n159.8\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\nAlaska\nJuneau\n1906\n2,716.7 sq mi (7,036 km2)\n32255\n32255\nNaN\n3\n2716.7\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\nArizona\nPhoenix\n1889\n517.6 sq mi (1,341 km2)\n1608139\n4845832\n4899104.0\n1\n517.6\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\nArkansas\nLittle Rock\n1821\n116.2 sq mi (301 km2)\n202591\n748031\n912604.0\n1\n116.2\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\nCalifornia\nSacramento\n1854\n97.9 sq mi (254 km2)\n524943\n2397382\n2680831.0\n6\n97.9\n\n\n\n\n\n\n\n\nmerged.shape\n\n(50, 16)\n\n\n\nmerged = pd.merge(cities_df, population_df[['CityPop', 'rank_in_state', 'area', 'State']], left_on='name', right_on='State')\n\n\nmerged.shape\n\n(50, 11)"
  },
  {
    "objectID": "studio/week02/pandas.html#saving-files",
    "href": "studio/week02/pandas.html#saving-files",
    "title": "Introduction to Pandas",
    "section": "Saving Files",
    "text": "Saving Files\nIn addition to reading data files, as we did at the beginning of this session, pandas can also create files to save to disk. It is very useful to separate your more complicated data analysis workflows into stages. Typically, the earlier stages will involve data reading, creation of new variables, and or merging different data sets. Much like we have done here. Subsequent steps would be analyzing the data that we have just constructed.\nWe do not want to have to repeat the data processing steps each time we need to carry out the analysis. To avoid this, we have our data processing notebooks save the newly created data to external files. This way the analysis notebooks only have to read these newly created files - we do not have to recreate them.\nLet’s save our latest DataFrame to a csv so we can use it again later.\n\nmerged.to_csv(\"merged.csv\", index=False)\n\nWe can show that the merge above will work irrespective of order.\n\nmerged.sort_values(by='description')\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n33\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n99224\n6\n21.40\nNew York\n\n\n19\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n40812\n7\n6.73\nMaryland\n\n\n10\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n498715\n1\n133.50\nGeorgia\n\n\n18\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n18899\n10\n55.40\nMaine\n\n\n42\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n961855\n4\n305.10\nTexas\n\n\n17\nLouisiana\nBaton Rouge\n30.457069\n-91.187393\nFalse\nTrue\nSW\n227470\n2\n76.80\nLouisiana\n\n\n32\nNorth Dakota\nBismarck\n46.820850\n-100.783318\nFalse\nFalse\nNW\n73622\n2\n26.90\nNorth Dakota\n\n\n11\nIdaho\nBoise\n43.617775\n-116.199722\nFalse\nFalse\nNW\n235684\n1\n63.80\nIdaho\n\n\n20\nMassachusetts\nBoston\n42.358162\n-71.063698\nTrue\nFalse\nNE\n675647\n1\n89.60\nMassachusetts\n\n\n27\nNevada\nCarson City\n39.163914\n-119.766121\nFalse\nTrue\nSW\n58639\n6\n143.40\nNevada\n\n\n47\nWest Virginia\nCharleston\n38.336246\n-81.612328\nTrue\nTrue\nSE\n48864\n1\n31.60\nWest Virginia\n\n\n49\nWyoming\nCheyenne\n41.140259\n-104.820236\nFalse\nFalse\nNW\n65132\n1\n21.10\nWyoming\n\n\n39\nSouth Carolina\nColumbia\n34.000343\n-81.033211\nTrue\nTrue\nSE\n136632\n2\n125.20\nSouth Carolina\n\n\n34\nOhio\nColumbus\n39.961346\n-82.999069\nTrue\nFalse\nNE\n905748\n1\n210.30\nOhio\n\n\n28\nNew Hampshire\nConcord\n43.206898\n-71.537994\nTrue\nFalse\nNE\n43976\n3\n64.30\nNew Hampshire\n\n\n5\nColorado\nDenver\n39.739227\n-104.984856\nFalse\nTrue\nSW\n715522\n1\n153.30\nColorado\n\n\n14\nIowa\nDes Moines\n41.591087\n-93.603729\nFalse\nFalse\nNW\n214133\n1\n75.80\nIowa\n\n\n7\nDelaware\nDover\n39.157307\n-75.519722\nTrue\nTrue\nSE\n39403\n2\n22.40\nDelaware\n\n\n16\nKentucky\nFrankfort\n38.186722\n-84.875374\nTrue\nTrue\nSE\n28602\n15\n14.70\nKentucky\n\n\n37\nPennsylvania\nHarrisburg\n40.264378\n-76.883598\nTrue\nFalse\nNE\n50099\n9\n8.11\nPennsylvania\n\n\n6\nConnecticut\nHartford&lt;br&gt;\n41.764046\n-72.682198\nTrue\nFalse\nNE\n121054\n4\n17.30\nConnecticut\n\n\n25\nMontana\nHelena\n46.585709\n-112.018417\nFalse\nFalse\nNW\n32091\n6\n14.00\nMontana\n\n\n8\nHawaii\nHonolulu\n21.307442\n-157.857376\nFalse\nTrue\nSW\n350964\n1\n68.40\nHawaii\n\n\n13\nIndiana\nIndianapolis\n39.768623\n-86.162643\nTrue\nTrue\nSE\n887642\n1\n361.50\nIndiana\n\n\n23\nMississippi\nJackson\n32.303848\n-90.182106\nFalse\nTrue\nSW\n153701\n1\n104.90\nMississippi\n\n\n24\nMissouri\nJefferson City\n38.579201\n-92.172935\nFalse\nTrue\nSW\n43228\n15\n27.30\nMissouri\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.70\nAlaska\n\n\n21\nMichigan\nLansing\n42.733635\n-84.555328\nTrue\nFalse\nNE\n112644\n5\n35.00\nMichigan\n\n\n26\nNebraska\nLincoln\n40.808075\n-96.699654\nFalse\nFalse\nNW\n291082\n2\n74.60\nNebraska\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.20\nArkansas\n\n\n48\nWisconsin\nMadison\n43.074684\n-89.384445\nTrue\nFalse\nNE\n269840\n2\n68.70\nWisconsin\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.80\nAlabama\n\n\n44\nVermont\nMontpelier\n44.262436\n-72.580536\nTrue\nFalse\nNE\n8074\n6\n10.20\nVermont\n\n\n41\nTennessee\nNashville\n36.165810\n-86.784241\nTrue\nTrue\nSE\n689447\n1\n525.90\nTennessee\n\n\n35\nOklahoma\nOklahoma City\n35.492207\n-97.503342\nFalse\nTrue\nSW\n681054\n1\n620.30\nOklahoma\n\n\n46\nWashington\nOlympia\n47.035805\n-122.905014\nFalse\nFalse\nNW\n55605\n23\n16.70\nWashington\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.60\nArizona\n\n\n40\nSouth Dakota\nPierre\n44.367031\n-100.346405\nFalse\nFalse\nNW\n14091\n9\n13.00\nSouth Dakota\n\n\n38\nRhode Island\nProvidence\n41.830914\n-71.414963\nTrue\nFalse\nNE\n190934\n1\n18.50\nRhode Island\n\n\n31\nNorth Carolina\nRaleigh\n35.780430\n-78.639099\nTrue\nTrue\nSE\n467665\n2\n114.60\nNorth Carolina\n\n\n45\nVirginia\nRichmond\n37.538857\n-77.433640\nTrue\nTrue\nSE\n226610\n4\n60.10\nVirginia\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.90\nCalifornia\n\n\n36\nOregon\nSalem\n44.938461\n-123.030403\nFalse\nFalse\nNW\n175535\n3\n45.70\nOregon\n\n\n43\nUtah\nSalt Lake City\n40.777477\n-111.888237\nFalse\nFalse\nNW\n199723\n1\n109.10\nUtah\n\n\n30\nNew Mexico\nSanta Fe\n35.682240\n-105.939728\nFalse\nTrue\nSW\n87505\n4\n37.30\nNew Mexico\n\n\n12\nIllinois\nSpringfield\n39.798363\n-89.654961\nTrue\nFalse\nNE\n114394\n7\n54.00\nIllinois\n\n\n22\nMinnesota\nSt. Paul\n44.955097\n-93.102211\nFalse\nFalse\nNW\n311527\n2\n52.80\nMinnesota\n\n\n9\nFlorida\nTallahassee\n30.438118\n-84.281296\nTrue\nTrue\nSE\n196169\n8\n95.70\nFlorida\n\n\n15\nKansas\nTopeka\n39.048191\n-95.677956\nFalse\nTrue\nSW\n126587\n5\n56.00\nKansas\n\n\n29\nNew Jersey\nTrenton\n40.220596\n-74.769913\nTrue\nFalse\nNE\n90871\n10\n7.66\nNew Jersey\n\n\n\n\n\n\n\nLet’s write this out to a second new file:\n\nmerged.sort_values(by='description').to_csv('merged1.csv', index=False)\n\nNow read it in and redo a merge to compare to what we did above\n\npop_df = pd.read_csv('merged1.csv')\n\n\npop_df.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nNew York\nAlbany\n42.652843\n-73.757874\nTrue\nFalse\nNE\n99224\n6\n21.40\nNew York\n\n\n1\nMaryland\nAnnapolis\n38.978764\n-76.490936\nTrue\nTrue\nSE\n40812\n7\n6.73\nMaryland\n\n\n2\nGeorgia\nAtlanta&lt;br&gt;\n33.749027\n-84.388229\nTrue\nTrue\nSE\n498715\n1\n133.50\nGeorgia\n\n\n3\nMaine\nAugusta\n44.307167\n-69.781693\nTrue\nFalse\nNE\n18899\n10\n55.40\nMaine\n\n\n4\nTexas\nAustin\n30.274670\n-97.740349\nFalse\nTrue\nSW\n961855\n4\n305.10\nTexas\n\n\n\n\n\n\n\n\nmerged1 = pd.merge(cities_df, pop_df[['CityPop', 'rank_in_state', 'area', 'State']], left_on='name', right_on='State')\n\n\nmerged1.shape\n\n(50, 11)\n\n\n\nmerged1.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.8\nAlabama\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.7\nAlaska\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.6\nArizona\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.2\nArkansas\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.9\nCalifornia\n\n\n\n\n\n\n\n\nmerged.head()\n\n\n\n\n\n\n\n\nname\ndescription\nlatitude\nlongitude\neast\nsouth\nregion\nCityPop\nrank_in_state\narea\nState\n\n\n\n\n0\nAlabama\nMontgomery\n32.377716\n-86.300568\nTrue\nTrue\nSE\n200603\n3\n159.8\nAlabama\n\n\n1\nAlaska\nJuneau\n58.301598\n-134.420212\nFalse\nFalse\nNW\n32255\n3\n2716.7\nAlaska\n\n\n2\nArizona\nPhoenix\n33.448143\n-112.096962\nFalse\nTrue\nSW\n1608139\n1\n517.6\nArizona\n\n\n3\nArkansas\nLittle Rock\n34.746613\n-92.288986\nFalse\nTrue\nSW\n202591\n1\n116.2\nArkansas\n\n\n4\nCalifornia\nSacramento\n38.576668\n-121.493629\nFalse\nTrue\nSW\n524943\n6\n97.9\nCalifornia"
  },
  {
    "objectID": "studio/week02/index.html",
    "href": "studio/week02/index.html",
    "title": "Week 2 Studio: Pandas",
    "section": "",
    "text": "This week we introduce Pandas:\n\nIntroduction to Pandas\nStudio exercise",
    "crumbs": [
      "Home",
      "09-04 Studio 2: Pandas"
    ]
  },
  {
    "objectID": "studio/week02/key.html",
    "href": "studio/week02/key.html",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Using the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/key.html#instructions",
    "href": "studio/week02/key.html#instructions",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Using the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/key.html#setup",
    "href": "studio/week02/key.html#setup",
    "title": "Studio 02 Pandas",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\n\ndf = pd.read_csv(\"merged.csv\")"
  },
  {
    "objectID": "studio/week02/key.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "href": "studio/week02/key.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital city with the largest population of all capital cities?",
    "text": "Which region has the capital city with the largest population of all capital cities?\n\ndf[['region', 'CityPop', 'description']].sort_values(by='CityPop', ascending=False)\n\n\n\n\n\n\n\n\nregion\nCityPop\ndescription\n\n\n\n\n2\nSW\n1608139\nPhoenix\n\n\n42\nSW\n961855\nAustin\n\n\n34\nNE\n905748\nColumbus\n\n\n13\nSE\n887642\nIndianapolis\n\n\n5\nSW\n715522\nDenver\n\n\n41\nSE\n689447\nNashville\n\n\n35\nSW\n681054\nOklahoma City\n\n\n20\nNE\n675647\nBoston\n\n\n4\nSW\n524943\nSacramento\n\n\n10\nSE\n498715\nAtlanta&lt;br&gt;\n\n\n31\nSE\n467665\nRaleigh\n\n\n8\nSW\n350964\nHonolulu\n\n\n22\nNW\n311527\nSt. Paul\n\n\n26\nNW\n291082\nLincoln\n\n\n48\nNE\n269840\nMadison\n\n\n11\nNW\n235684\nBoise\n\n\n17\nSW\n227470\nBaton Rouge\n\n\n45\nSE\n226610\nRichmond\n\n\n14\nNW\n214133\nDes Moines\n\n\n3\nSW\n202591\nLittle Rock\n\n\n0\nSE\n200603\nMontgomery\n\n\n43\nNW\n199723\nSalt Lake City\n\n\n9\nSE\n196169\nTallahassee\n\n\n38\nNE\n190934\nProvidence\n\n\n36\nNW\n175535\nSalem\n\n\n23\nSW\n153701\nJackson\n\n\n39\nSE\n136632\nColumbia\n\n\n15\nSW\n126587\nTopeka\n\n\n6\nNE\n121054\nHartford&lt;br&gt;\n\n\n12\nNE\n114394\nSpringfield\n\n\n21\nNE\n112644\nLansing\n\n\n33\nNE\n99224\nAlbany\n\n\n29\nNE\n90871\nTrenton\n\n\n30\nSW\n87505\nSanta Fe\n\n\n32\nNW\n73622\nBismarck\n\n\n49\nNW\n65132\nCheyenne\n\n\n27\nSW\n58639\nCarson City\n\n\n46\nNW\n55605\nOlympia\n\n\n37\nNE\n50099\nHarrisburg\n\n\n47\nSE\n48864\nCharleston\n\n\n28\nNE\n43976\nConcord\n\n\n24\nSW\n43228\nJefferson City\n\n\n19\nSE\n40812\nAnnapolis\n\n\n7\nSE\n39403\nDover\n\n\n1\nNW\n32255\nJuneau\n\n\n25\nNW\n32091\nHelena\n\n\n16\nSE\n28602\nFrankfort\n\n\n18\nNE\n18899\nAugusta\n\n\n40\nNW\n14091\nPierre\n\n\n44\nNE\n8074\nMontpelier"
  },
  {
    "objectID": "studio/week02/key.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "href": "studio/week02/key.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region contains the largest number of people living in its capital cities?",
    "text": "Which region contains the largest number of people living in its capital cities?\n\ndf[['region', 'CityPop']].groupby(by='region').sum()\n\n\n\n\n\n\n\n\nCityPop\n\n\nregion\n\n\n\n\n\nNE\n2701404\n\n\nNW\n1700480\n\n\nSE\n3461164\n\n\nSW\n5742198"
  },
  {
    "objectID": "studio/week02/key.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "href": "studio/week02/key.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital cities with the highest population density (median)?",
    "text": "Which region has the capital cities with the highest population density (median)?\n\ndf['density'] = df.CityPop / df.area\ndf[['density', 'region']].groupby(by='region').median()\n\n\n\n\n\n\n\n\ndensity\n\n\nregion\n\n\n\n\n\nNE\n4306.932953\n\n\nNW\n2955.899130\n\n\nSE\n1997.773548\n\n\nSW\n2345.978552"
  },
  {
    "objectID": "studio/week02/studio.html",
    "href": "studio/week02/studio.html",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 11, 2024 3:30pm\nUsing the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/studio.html#instructions",
    "href": "studio/week02/studio.html#instructions",
    "title": "Studio 02 Pandas",
    "section": "",
    "text": "Teams\nDUE: Wednesday, September 11, 2024 3:30pm\nUsing the merged.csv file you created in the studio, answer the following questions.\nThe team leader will submit a pdf version of the notebook showing all the work to answer the questions.\nThe first cell of the notebook should have a list of the team members (first and last names) with the team leader in bold. (Hint: Markdown cell)."
  },
  {
    "objectID": "studio/week02/studio.html#setup",
    "href": "studio/week02/studio.html#setup",
    "title": "Studio 02 Pandas",
    "section": "Setup",
    "text": "Setup\n\nimport pandas as pd\n\ndf = pd.read_csv(\"merged.csv\")"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "href": "studio/week02/studio.html#which-region-has-the-capital-city-with-the-largest-population-of-all-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital city with the largest population of all capital cities?",
    "text": "Which region has the capital city with the largest population of all capital cities?\n\n# your code here"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "href": "studio/week02/studio.html#which-region-contains-the-largest-number-of-people-living-in-its-capital-cities",
    "title": "Studio 02 Pandas",
    "section": "Which region contains the largest number of people living in its capital cities?",
    "text": "Which region contains the largest number of people living in its capital cities?\n\n# your code here"
  },
  {
    "objectID": "studio/week02/studio.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "href": "studio/week02/studio.html#which-region-has-the-capital-cities-with-the-highest-population-density-median",
    "title": "Studio 02 Pandas",
    "section": "Which region has the capital cities with the highest population density (median)?",
    "text": "Which region has the capital cities with the highest population density (median)?\n\n# your code here"
  },
  {
    "objectID": "studio/week03/index.html",
    "href": "studio/week03/index.html",
    "title": "Week 3 Studio: GeoPandas",
    "section": "",
    "text": "This week we introduce GeoPandas:\n\nIntroduction to GeoPandas\nStudio exercise",
    "crumbs": [
      "Home",
      "09-11 Studio 3: GeoPandas"
    ]
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html",
    "href": "studio/week03/studio3_geopandas.html",
    "title": "GeoPandas",
    "section": "",
    "text": "Earlier in the course we had a figure to illustrate vector spatial data:\n\n\n\nVector GIS\n\n\nThis figure was built with the following code:\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon as MplPolygon\n\n# Data for streets (line strings)\nstreets = [\n    [(0, 0), (1, 2), (3, 3)],\n    [(3, 3), (5, 2), (7, 5)],\n    [(7, 5), (8, 8), (10, 10)],\n    [(1, 2), (2, 5), (4, 6)],\n]\n\n# Data for school catchments (polygons)\ncatchments = [\n    [(0.5, 0.5), (2, 1), (1.5, 3), (0.5, 2)],\n    [(3, 4), (5, 3.5), (6, 6), (4, 6.5)],\n    [(7, 7), (8.5, 7.5), (9, 9), (7.5, 9)],\n]\n\n# Adjusting the data for one school per catchment\nschools = [(1.2, 1.8), (4.7, 5.3), (8.2, 8.2)]\n\n# Plotting the GIS map with one school per catchment\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plotting the streets with one legend entry\nax.plot(*zip(*streets[0]), color='blue', linewidth=2, label=\"Streets\")\nfor street in streets[1:]:\n    street_x, street_y = zip(*street)\n    ax.plot(street_x, street_y, color='blue', linewidth=2)\n\n# Plotting the catchments with legend\nfor i, catchment in enumerate(catchments):\n    polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n    ax.add_patch(polygon)\n    if i == 0:\n        polygon.set_label(\"School Catchments\")\n\n# Plotting the schools (points) with one per catchment\nschool_x, school_y = zip(*schools)\nax.scatter(school_x, school_y, color='green', s=100, label=\"Schools\")\n\n# Set the legend and title\nax.legend()\nax.set_title('Vector GIS: Street Network, School Catchments, and Schools')\nax.set_xlim(-1, 11)\nax.set_ylim(-1, 11)\nax.set_aspect('equal')\n\n# Save the figure to a file\nplt.savefig(\"vector.png\", dpi=300)\n\n# Show the plot\nplt.show()\n\n/tmp/ipykernel_1351698/1512531908.py:33: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n  polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n\n\n\n\n\n\n\n\n\nHere, we are faking it regarding a GIS, as matplotlib is a visualization library and doesn’t actually allow us to do any spatial analysis per se.\nFortunately, there are a number of Python packages that are designed to wrangle spatial data:\n\nshapely\nGeoPandas"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#geometries-for-vector-spatial-data",
    "href": "studio/week03/studio3_geopandas.html#geometries-for-vector-spatial-data",
    "title": "GeoPandas",
    "section": "",
    "text": "Earlier in the course we had a figure to illustrate vector spatial data:\n\n\n\nVector GIS\n\n\nThis figure was built with the following code:\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon as MplPolygon\n\n# Data for streets (line strings)\nstreets = [\n    [(0, 0), (1, 2), (3, 3)],\n    [(3, 3), (5, 2), (7, 5)],\n    [(7, 5), (8, 8), (10, 10)],\n    [(1, 2), (2, 5), (4, 6)],\n]\n\n# Data for school catchments (polygons)\ncatchments = [\n    [(0.5, 0.5), (2, 1), (1.5, 3), (0.5, 2)],\n    [(3, 4), (5, 3.5), (6, 6), (4, 6.5)],\n    [(7, 7), (8.5, 7.5), (9, 9), (7.5, 9)],\n]\n\n# Adjusting the data for one school per catchment\nschools = [(1.2, 1.8), (4.7, 5.3), (8.2, 8.2)]\n\n# Plotting the GIS map with one school per catchment\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Plotting the streets with one legend entry\nax.plot(*zip(*streets[0]), color='blue', linewidth=2, label=\"Streets\")\nfor street in streets[1:]:\n    street_x, street_y = zip(*street)\n    ax.plot(street_x, street_y, color='blue', linewidth=2)\n\n# Plotting the catchments with legend\nfor i, catchment in enumerate(catchments):\n    polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n    ax.add_patch(polygon)\n    if i == 0:\n        polygon.set_label(\"School Catchments\")\n\n# Plotting the schools (points) with one per catchment\nschool_x, school_y = zip(*schools)\nax.scatter(school_x, school_y, color='green', s=100, label=\"Schools\")\n\n# Set the legend and title\nax.legend()\nax.set_title('Vector GIS: Street Network, School Catchments, and Schools')\nax.set_xlim(-1, 11)\nax.set_ylim(-1, 11)\nax.set_aspect('equal')\n\n# Save the figure to a file\nplt.savefig(\"vector.png\", dpi=300)\n\n# Show the plot\nplt.show()\n\n/tmp/ipykernel_1351698/1512531908.py:33: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n  polygon = MplPolygon(catchment, closed=True, color='orange', alpha=0.5, edgecolor='black')\n\n\n\n\n\n\n\n\n\nHere, we are faking it regarding a GIS, as matplotlib is a visualization library and doesn’t actually allow us to do any spatial analysis per se.\nFortunately, there are a number of Python packages that are designed to wrangle spatial data:\n\nshapely\nGeoPandas"
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#shapely",
    "href": "studio/week03/studio3_geopandas.html#shapely",
    "title": "GeoPandas",
    "section": "shapely",
    "text": "shapely\nShapely (Gillies et al. 2007--) is a Python package for the manipulation and analysis of planar geometric objects.\nWe can use shapely to build up our example, starting with its Point class:\n\nfrom shapely import Point\n\nThe Point class can be used to create instances for each of our schools, here using a python list comprehension:\n\nschool_points = [Point(school) for school in schools]\n\nThis results in a python list containing three shapely point objects:\n\nschool_points\n\n[&lt;POINT (1.2 1.8)&gt;, &lt;POINT (4.7 5.3)&gt;, &lt;POINT (8.2 8.2)&gt;]\n\n\nIf we ask for the first point, we get a rendered point.\n\nschool_points[0]\n\n\n\n\n\n\n\n\nAnd, if we unpack the list into individual points, we should see similar behavior.\n\nschool_0, school_1, school_2 = school_points\n\n\nschool_0\n\n\n\n\n\n\n\n\n\nschool_1\n\n\n\n\n\n\n\n\n\nschool_2\n\n\n\n\n\n\n\n\nJust like we did for points, we can rely on shapely for dealing with our catchments, but this time using the Polygon class:\n\nfrom shapely import Polygon\n\n\ncatchment_polygons = [Polygon(catchment) for catchment in catchments]\n\n\ncatchment_0, catchment_1, catchment_2 = catchment_polygons\n\n\ncatchment_0\n\n\n\n\n\n\n\n\n\ncatchment_1\n\n\n\n\n\n\n\n\n\ncatchment_2\n\n\n\n\n\n\n\n\nAnd, finally, we can model the road network using the LineString class:\n\nfrom shapely import LineString\n\n\nstreet_lines = [LineString(street) for street in streets]\n\n\nstreet_0, street_1, street_2, street_3 = street_lines\n\n\nstreet_0\n\n\n\n\n\n\n\n\n\nstreet_1\n\n\n\n\n\n\n\n\n\nstreet_2\n\n\n\n\n\n\n\n\n\nstreet_3\n\n\n\n\n\n\n\n\n\nshapely Geometry Types\n\nschool_0.geom_type\n\n'Point'\n\n\n\nschool_2.geom_type\n\n'Point'\n\n\nPoints are zero-dimensional geometries, and thus have 0 area and 0 length:\n\nschool_0.area\n\n0.0\n\n\n\nschool_0.length\n\n0.0\n\n\n\nlist(school_0.coords)\n\n[(1.2, 1.8)]\n\n\n\nlist(school_2.coords)\n\n[(8.2, 8.2)]\n\n\nLineStrings are one-dimensional geometric objects, having length but 0 area\n\nstreet_1.length\n\n5.841619252963779\n\n\n\nstreet_1.area\n\n0.0\n\n\nFinally, Polygons are two-dimensional geometric objects, having area:\n\ncatchment_1.area\n\n5.5\n\n\nas well as length:\n\ncatchment_1.length\n\n9.508270432752164\n\n\n\n\ngeometry methods and spatial predicates\nThe power of these geometries comes from the functions and abilities to evaluate spatial predicates. These give us the building blocks of GIS operations for vector spatial data:\nTo see this, we can call the distance method of school_0 to determine the distance separating it from school_2:\n\nschool_0.distance(school_2)\n\n9.4847245611035\n\n\nWe can also measure the difference between objects of different geometry types:\n\nstreet_1.geom_type\n\n'LineString'\n\n\n\nschool_0.distance(street_1)\n\n2.1633307652783933\n\n\n\ncatchment_0.geom_type\n\n'Polygon'\n\n\n\ncatchment_0.area\n\n2.375\n\n\n\nlist(catchment_0.exterior.coords)\n\n[(0.5, 0.5), (2.0, 1.0), (1.5, 3.0), (0.5, 2.0), (0.5, 0.5)]\n\n\n\ncatchment_0.bounds\n\n(0.5, 0.5, 2.0, 3.0)\n\n\n\nschool_0.distance(catchment_0)\n\n0.0\n\n\n\ncatchment_0.contains(school_0)\n\nTrue\n\n\n\ncatchment_0.contains(school_1)\n\nFalse\n\n\n\nschool_1.distance(catchment_0)\n\n3.9408120990476063\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll the area, distance, and other measurements done with shapely objects utilize Cartesian coordinates."
  },
  {
    "objectID": "studio/week03/studio3_geopandas.html#geopandas",
    "href": "studio/week03/studio3_geopandas.html#geopandas",
    "title": "GeoPandas",
    "section": "GeoPandas",
    "text": "GeoPandas\nGeoPandas (Jordahl et al. 2020) is a python package that makes working with geospatial data easier. It relies on shapely and other libraries to extend the datatypes used by Pandas to allow spatial operations on geometric types.\nThe two important classes in GeoPandas are:\n\nGeoSeries\nGeoDataFrame\n\nThese are spatial extensions of the Series and DataFrame classes from pandas.\n\nimport and aliasing\n\nimport geopandas as gpd\n\n\n\nGeoSeries\nA GeoSeries is essentially a pandas Series object designed to store shapely geometry types:\n\nstreets = gpd.GeoSeries(street_lines)\n\n\nstreets.plot()\n\n\n\n\n\n\n\n\n\ncatchments = gpd.GeoSeries(catchment_polygons)\n\n\ncatchments.plot()\n\n\n\n\n\n\n\n\n\nschools = gpd.GeoSeries(school_points)\n\n\nschools.plot()\n\n\n\n\n\n\n\n\n\ntype(schools)\n\ngeopandas.geoseries.GeoSeries\n\n\n\n\nGeoDataFrame\nA GeoDataFrame is similar to a pandas DataFrame but includes at least one GeoSeries and supports spatial operations on its data.\n\nschools_gdf = gpd.GeoDataFrame(geometry=schools)\n\n\nschools_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOINT (1.2 1.8)\n\n\n1\nPOINT (4.7 5.3)\n\n\n2\nPOINT (8.2 8.2)\n\n\n\n\n\n\n\n\ntype(schools_gdf)\n\ngeopandas.geodataframe.GeoDataFrame\n\n\n\nschools_gdf['students'] = [124, 94, 100]\n\n\nschools_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\nstudents\n\n\n\n\n0\nPOINT (1.2 1.8)\n124\n\n\n1\nPOINT (4.7 5.3)\n94\n\n\n2\nPOINT (8.2 8.2)\n100\n\n\n\n\n\n\n\n\nschools_gdf.plot()\n\n\n\n\n\n\n\n\n\nschools_gdf.plot(column='students')\n\n\n\n\n\n\n\n\n\nstreets_gdf = gpd.GeoDataFrame(geometry=streets)\n\n\nstreets_gdf.plot()\n\n\n\n\n\n\n\n\n\nstreets_gdf['length'] = streets_gdf.length\n\n\nstreets_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\nlength\n\n\n\n\n0\nLINESTRING (0 0, 1 2, 3 3)\n4.472136\n\n\n1\nLINESTRING (3 3, 5 2, 7 5)\n5.841619\n\n\n2\nLINESTRING (7 5, 8 8, 10 10)\n5.990705\n\n\n3\nLINESTRING (1 2, 2 5, 4 6)\n5.398346\n\n\n\n\n\n\n\n\nstreets_gdf.plot(column='length', legend=True)\n\n\n\n\n\n\n\n\n\ncatchments_gdf = gpd.GeoDataFrame(geometry=catchment_polygons)\n\n\ncatchments_gdf['area'] = catchments_gdf.area\ncatchments_gdf.plot(column='area', legend=True)\n\n\n\n\n\n\n\n\n\n\nThe geometry of a GeoDataFrame\nOne of the key differences between a GeoDataFrame and a pandas DataFrame is that the former will have a geometry column that holds a GeoSeries:\n\ncatchments_gdf.geometry\n\n0    POLYGON ((0.5 0.5, 2 1, 1.5 3, 0.5 2, 0.5 0.5))\n1            POLYGON ((3 4, 5 3.5, 6 6, 4 6.5, 3 4))\n2          POLYGON ((7 7, 8.5 7.5, 9 9, 7.5 9, 7 7))\nName: geometry, dtype: geometry\n\n\n\ncatchments_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\narea\n\n\n\n\n0\nPOLYGON ((0.5 0.5, 2 1, 1.5 3, 0.5 2, 0.5 0.5))\n2.375\n\n\n1\nPOLYGON ((3 4, 5 3.5, 6 6, 4 6.5, 3 4))\n5.500\n\n\n2\nPOLYGON ((7 7, 8.5 7.5, 9 9, 7.5 9, 7 7))\n2.500\n\n\n\n\n\n\n\nA GeoDataFrame can contained more than a single GeoSeries but only one can be operative as far as the geometry attribute is concerned. To see this, let’s add a second GeoSeries to the catchments GeoDataFrame:\n\ncatchments_gdf.centroid\n\n0    POINT (1.17544 1.60526)\n1              POINT (4.5 5)\n2    POINT (7.96667 8.13333)\ndtype: geometry\n\n\n\ncatchments_gdf['centroid_point'] = catchments_gdf.centroid\ncatchments_gdf.head()\n\n\n\n\n\n\n\n\ngeometry\narea\ncentroid_point\n\n\n\n\n0\nPOLYGON ((0.5 0.5, 2 1, 1.5 3, 0.5 2, 0.5 0.5))\n2.375\nPOINT (1.17544 1.60526)\n\n\n1\nPOLYGON ((3 4, 5 3.5, 6 6, 4 6.5, 3 4))\n5.500\nPOINT (4.5 5)\n\n\n2\nPOLYGON ((7 7, 8.5 7.5, 9 9, 7.5 9, 7 7))\n2.500\nPOINT (7.96667 8.13333)\n\n\n\n\n\n\n\nNow we can set the geometry to be the centroid_point GeoSeries:\n\ncatchments_gdf.set_geometry('centroid_point', inplace=True)\ncatchments_gdf.plot()\n\n\n\n\n\n\n\n\nAnd we could return to the polygons with:\n\ncatchments_gdf.set_geometry('geometry', inplace=True)\ncatchments_gdf.plot()"
  },
  {
    "objectID": "studio/week04/index.html",
    "href": "studio/week04/index.html",
    "title": "Week 4 Studio: geosnap",
    "section": "",
    "text": "This week we introduce geosnap:\n\nIntroduction to geosnap and geoprocessing\nStudio exercise"
  },
  {
    "objectID": "studio/week01/jupyter.html",
    "href": "studio/week01/jupyter.html",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "",
    "text": "In this exercise, you will practice basic operations in Jupyter notebooks, including writing and running Python code, working with Markdown cells, and performing simple data operations."
  },
  {
    "objectID": "studio/week01/jupyter.html#setting-up-the-notebook",
    "href": "studio/week01/jupyter.html#setting-up-the-notebook",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "1. Setting Up the Notebook",
    "text": "1. Setting Up the Notebook\n\nCreate a new notebook.\nRename it to GroupX.ipynb where X is your group number.\n\nAdd some structure at the top cells:\n# Group Exercise 1\n\nThis notebook is for practicing basic operations in Jupyter notebooks. It includes examples of using Python code and Markdown cells to document the work.\nAdd a subsection with the name Team and underneath the subsection add a bulleted list with the names of the team members.\nPut the leader’s name in bold.\nAdd a second subsection that contains a second bulleted list. Give the subsection the title Links In this list add a link to a site that each group member suggests as interesting to the class."
  },
  {
    "objectID": "studio/week01/jupyter.html#basic-code-operations",
    "href": "studio/week01/jupyter.html#basic-code-operations",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "2. Basic Code Operations",
    "text": "2. Basic Code Operations\nIn this section, you’ll write and run some simple Python code.\n# Task 1: Print a welcome message\nprint(\"Welcome to JupyterHub!\")\n# Task 2: Perform a simple arithmetic operation\n10 * 3\nprint(f'The value 10 * 3 is equal to {10 * 3}')\nRun these cells, and explore what happens as you change some of the values.\nCreate some new code cells that extend on these ideas."
  },
  {
    "objectID": "studio/week01/jupyter.html#working-with-data",
    "href": "studio/week01/jupyter.html#working-with-data",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "3. Working with Data",
    "text": "3. Working with Data\nIn this section, you’ll work with a small dataset.\n\nLoad and Display the Dataset\ndata = [100, 20, 90, 40, 50, 30, 10]\n\n# Display the dataset\ndata\n\n\nPerform a Basic Analysis\n# Task: Calculate the sum of the numbers in the dataset\nsum(data)\n# Task: Calculate the mean of the numbers in the dataset\nmean_value = sum(data) / len(data)\nmean_value\nHow would you sort the data using python? Show your answer in a code cell.\nAs a group, come up with an answer to the questions: Is the data skewed? If so, in what way? Add Markdown cells that describe your reasoning used to come up with your answers."
  },
  {
    "objectID": "studio/week01/jupyter.html#documenting-the-analysis",
    "href": "studio/week01/jupyter.html#documenting-the-analysis",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "4. Documenting the Analysis",
    "text": "4. Documenting the Analysis\nUse Markdown cells to document your code and results. For example:\n## Dataset Analysis\n\nWe loaded a dataset containing the numbers 10, 20, 30, 40, 50, 90, 100. Below is the sum and mean of these numbers.\n\nWith regard to skewness, we find ...."
  },
  {
    "objectID": "studio/week01/jupyter.html#final-touches-and-submission",
    "href": "studio/week01/jupyter.html#final-touches-and-submission",
    "title": "Studio 1: Working with Jupyter Notebooks on JupyterHub",
    "section": "5. Final Touches and Submission",
    "text": "5. Final Touches and Submission\nReview your notebook as a group. Ensure that it is well-organized and the code is properly documented. Use the ability to move cells around to reorganize as needed.\nOnce done, save your notebook as a pdf.\nHave the group leader turn the pdf in on canvas."
  },
  {
    "objectID": "studio/week01/index.html",
    "href": "studio/week01/index.html",
    "title": "Studio 1: Jupyter Hub",
    "section": "",
    "text": "In this first studio session, we will do three things:\n\nGet started with Jupyter Hub\nSet up collaboration in studios\nCollaborate on our first studio activity",
    "crumbs": [
      "Home",
      "08-28 Studio 1: Jupyter Hub"
    ]
  },
  {
    "objectID": "studio/python_course.html",
    "href": "studio/python_course.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "studio/python_course.html#instructions",
    "href": "studio/python_course.html#instructions",
    "title": "",
    "section": "Instructions",
    "text": "Instructions\n\nGo to http://www.codeacademy.com and create a free account, or sign in with a social media or GitHub account.\nTake the self-paced entry-level minicourse on Python 2.3\nThe minicourse has 12 units, each with 1-2 lessons to be done in a browser. Complete the first 9 units of the course, up to and including “Exam Statistics.”\n\n\n\n\n\n\n\nTime Requirements\n\n\n\nCompleting this primer should take between 6-8 hours. You should spread out your effort in 30-minute chunks over a few weeks."
  },
  {
    "objectID": "studio/python_course.html#submission-due-september-23-330-pm",
    "href": "studio/python_course.html#submission-due-september-23-330-pm",
    "title": "",
    "section": "Submission (Due: September 23, 3:30 PM)",
    "text": "Submission (Due: September 23, 3:30 PM)\nWhen you have completed the nine units, take a screenshot that shows your name on the screen as well as all the checks. Upload the screenshot to Canvas."
  },
  {
    "objectID": "studio/python_course.html#footnotes",
    "href": "studio/python_course.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe Python Primer is inspired by and modeled after the work of Robert Talbert.↩︎\nIf you are interested in further exploring Python for geography, an excellent course is Geog 383.↩︎\nDo not sign up for the Python 3 course as it is not free. We will cover the main differences between Python 2 and Python 3 in the studio sessions.↩︎"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week03/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week03/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#eda-approach",
    "href": "lectures/week03/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week03/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week03/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#historical-context",
    "href": "lectures/week03/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#snow-map",
    "href": "lectures/week03/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#snow-map-1",
    "href": "lectures/week03/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week03/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#vector-data",
    "href": "lectures/week03/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#vector-data-1",
    "href": "lectures/week03/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#raster-data",
    "href": "lectures/week03/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#raster-data-1",
    "href": "lectures/week03/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#attribute-data",
    "href": "lectures/week03/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#attribute-data-1",
    "href": "lectures/week03/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week03/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week03/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#remote-sensing",
    "href": "lectures/week03/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week03/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week03/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week03/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week03/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week03/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week03/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week03/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week03/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week03/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week03/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#questions",
    "href": "lectures/week03/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week03/lecture_sda.html#references",
    "href": "lectures/week03/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "lectures/week03/index.html",
    "href": "lectures/week03/index.html",
    "title": "Week 3 Lecture: Spatial Data Analysis",
    "section": "",
    "text": "lecture",
    "crumbs": [
      "Home",
      "09-09 Spatial Data Analysis"
    ]
  },
  {
    "objectID": "lectures/week03/index.html#spatial-data-analysis",
    "href": "lectures/week03/index.html#spatial-data-analysis",
    "title": "Week 3 Lecture: Spatial Data Analysis",
    "section": "",
    "text": "lecture",
    "crumbs": [
      "Home",
      "09-09 Spatial Data Analysis"
    ]
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week04/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week04/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#eda-approach",
    "href": "lectures/week04/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week04/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week04/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#historical-context",
    "href": "lectures/week04/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#snow-map",
    "href": "lectures/week04/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#snow-map-1",
    "href": "lectures/week04/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week04/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#vector-data",
    "href": "lectures/week04/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#vector-data-1",
    "href": "lectures/week04/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#raster-data",
    "href": "lectures/week04/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#raster-data-1",
    "href": "lectures/week04/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#attribute-data",
    "href": "lectures/week04/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#attribute-data-1",
    "href": "lectures/week04/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week04/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week04/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#remote-sensing",
    "href": "lectures/week04/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week04/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week04/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week04/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week04/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week04/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week04/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week04/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week04/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week04/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week04/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#questions",
    "href": "lectures/week04/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week04/lecture_sda.html#references",
    "href": "lectures/week04/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "lectures/week04/0221_area_1.html",
    "href": "lectures/week04/0221_area_1.html",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nimport geopandas\nimport libpysal\n\n\n\n\nCode\nsouth = libpysal.examples.load_example('South')\n\n\n\n\nCode\nlibpysal.examples.explain('South')\n\n\n\n        \n        \n\n\n\n\n\n\nCode\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))\n\n\n\n\n\n\n\nCode\nsouth_gdf.plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf.crs\n\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\n\n\n\nCode\nax = south_gdf.plot()\nax.set_axis_off();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf.shape\n\n\n(1412, 70)\n\n\n\n\nCode\nsouth_gdf.geometry\n\n\n0       POLYGON ((-80.62805 40.39816, -80.60204 40.480...\n1       POLYGON ((-80.52625 40.16245, -80.5876 40.1750...\n2       POLYGON ((-80.52517 40.02275, -80.73843 40.035...\n3       POLYGON ((-80.52447 39.72113, -80.83248 39.718...\n4       POLYGON ((-75.7727 39.38301, -75.79144 39.7237...\n                              ...                        \n1407    POLYGON ((-79.14433 36.54606, -79.21706 36.549...\n1408    POLYGON ((-79.43775 37.61596, -79.45834 37.603...\n1409    POLYGON ((-80.12475 37.1251, -80.14045 37.1283...\n1410    POLYGON ((-76.39569 37.10771, -76.4027 37.0905...\n1411    POLYGON ((-77.53178 38.56506, -77.72094 38.840...\nName: geometry, Length: 1412, dtype: geometry\n\n\n\n\nCode\nsouth_gdf.columns\n\n\nIndex(['NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'STFIPS',\n       'COFIPS', 'FIPSNO', 'SOUTH', 'HR60', 'HR70', 'HR80', 'HR90', 'HC60',\n       'HC70', 'HC80', 'HC90', 'PO60', 'PO70', 'PO80', 'PO90', 'RD60', 'RD70',\n       'RD80', 'RD90', 'PS60', 'PS70', 'PS80', 'PS90', 'UE60', 'UE70', 'UE80',\n       'UE90', 'DV60', 'DV70', 'DV80', 'DV90', 'MA60', 'MA70', 'MA80', 'MA90',\n       'POL60', 'POL70', 'POL80', 'POL90', 'DNL60', 'DNL70', 'DNL80', 'DNL90',\n       'MFIL59', 'MFIL69', 'MFIL79', 'MFIL89', 'FP59', 'FP69', 'FP79', 'FP89',\n       'BLK60', 'BLK70', 'BLK80', 'BLK90', 'GI59', 'GI69', 'GI79', 'GI89',\n       'FH60', 'FH70', 'FH80', 'FH90', 'geometry'],\n      dtype='object')\n\n\n\n\nCode\nsouth_gdf.explore(column='HR60')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nsouth_gdf.HR60.describe()\n\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64\n\n\n\n\nCode\nax = south_gdf.plot(column='HR60')\nax.set_axis_off();\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf.STATE_NAME.unique().shape\n\n\n(17,)\n\n\n\n\n\n\n\nCode\nsouth_gdf.shape[0]\n\n\n1412\n\n\n\n\n\n\n\nCode\nsouth_gdf.groupby(by='STATE_NAME').count()\n\n\n\n\n\n\n\n\n\nNAME\nSTATE_FIPS\nCNTY_FIPS\nFIPS\nSTFIPS\nCOFIPS\nFIPSNO\nSOUTH\nHR60\nHR70\n...\nBLK90\nGI59\nGI69\nGI79\nGI89\nFH60\nFH70\nFH80\nFH90\ngeometry\n\n\nSTATE_NAME\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nArkansas\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n...\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n\n\nDelaware\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n...\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n\n\nDistrict of Columbia\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\nFlorida\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nGeorgia\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n...\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n\n\nKentucky\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n...\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n\n\nLouisiana\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n...\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n\n\nMaryland\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n...\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n\n\nMississippi\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n...\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n\n\nNorth Carolina\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n...\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n\n\nOklahoma\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n...\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n\n\nSouth Carolina\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n...\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n\n\nTennessee\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n...\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n\n\nTexas\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n...\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n\n\nVirginia\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n...\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n\n\nWest Virginia\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n...\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n\n\n\n\n17 rows × 69 columns\n\n\n\n\n\n\n\n\nCode\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').median()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n9.623977\n\n\nArkansas\n4.704111\n\n\nDelaware\n4.228385\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n9.970306\n\n\nGeorgia\n9.300076\n\n\nKentucky\n5.235436\n\n\nLouisiana\n6.840286\n\n\nMaryland\n5.335208\n\n\nMississippi\n8.919274\n\n\nNorth Carolina\n7.633043\n\n\nOklahoma\n4.269126\n\n\nSouth Carolina\n7.509437\n\n\nTennessee\n4.877751\n\n\nTexas\n4.326215\n\n\nVirginia\n6.672004\n\n\nWest Virginia\n2.623226\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').max()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n24.903499\n\n\nArkansas\n21.154427\n\n\nDelaware\n7.286472\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n40.744262\n\n\nGeorgia\n53.304904\n\n\nKentucky\n37.250885\n\n\nLouisiana\n18.243736\n\n\nMaryland\n14.327234\n\n\nMississippi\n24.833923\n\n\nNorth Carolina\n25.660127\n\n\nOklahoma\n17.088175\n\n\nSouth Carolina\n23.345940\n\n\nTennessee\n20.894275\n\n\nTexas\n92.936803\n\n\nVirginia\n23.575639\n\n\nWest Virginia\n11.482375\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n4.742337\n\n\nArkansas\n4.574625\n\n\nDelaware\n1.815562\n\n\nDistrict of Columbia\nNaN\n\n\nFlorida\n7.990692\n\n\nGeorgia\n7.906488\n\n\nKentucky\n6.354316\n\n\nLouisiana\n4.189146\n\n\nMaryland\n4.064360\n\n\nMississippi\n4.972698\n\n\nNorth Carolina\n4.596952\n\n\nOklahoma\n4.231132\n\n\nSouth Carolina\n4.018644\n\n\nTennessee\n4.354979\n\n\nTexas\n8.223844\n\n\nVirginia\n4.826707\n\n\nWest Virginia\n2.773659\n\n\n\n\n\n\n\n\n\nCode\nsgdf = south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\nCode\ncv = sgdf / south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').mean() * 100\n\n\n\n\nCode\ncv.sort_values(by='HR60', ascending=False)\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nTexas\n144.992919\n\n\nKentucky\n96.815524\n\n\nWest Virginia\n93.234007\n\n\nArkansas\n81.223752\n\n\nOklahoma\n81.114430\n\n\nTennessee\n75.426226\n\n\nGeorgia\n73.774440\n\n\nMaryland\n71.898559\n\n\nFlorida\n68.252692\n\n\nVirginia\n66.924041\n\n\nLouisiana\n59.994571\n\n\nMississippi\n57.457024\n\n\nNorth Carolina\n57.013871\n\n\nAlabama\n49.070812\n\n\nSouth Carolina\n48.083524\n\n\nDelaware\n34.966796\n\n\nDistrict of Columbia\nNaN"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#loading",
    "href": "lectures/week04/0221_area_1.html#loading",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#plotting-geometries",
    "href": "lectures/week04/0221_area_1.html#plotting-geometries",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.plot()"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#checking-crs",
    "href": "lectures/week04/0221_area_1.html#checking-crs",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.crs\n\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#turning-off-axis",
    "href": "lectures/week04/0221_area_1.html#turning-off-axis",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nax = south_gdf.plot()\nax.set_axis_off();"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#inspecting-the-geodataframe",
    "href": "lectures/week04/0221_area_1.html#inspecting-the-geodataframe",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.shape\n\n\n(1412, 70)\n\n\n\n\nCode\nsouth_gdf.geometry\n\n\n0       POLYGON ((-80.62805 40.39816, -80.60204 40.480...\n1       POLYGON ((-80.52625 40.16245, -80.5876 40.1750...\n2       POLYGON ((-80.52517 40.02275, -80.73843 40.035...\n3       POLYGON ((-80.52447 39.72113, -80.83248 39.718...\n4       POLYGON ((-75.7727 39.38301, -75.79144 39.7237...\n                              ...                        \n1407    POLYGON ((-79.14433 36.54606, -79.21706 36.549...\n1408    POLYGON ((-79.43775 37.61596, -79.45834 37.603...\n1409    POLYGON ((-80.12475 37.1251, -80.14045 37.1283...\n1410    POLYGON ((-76.39569 37.10771, -76.4027 37.0905...\n1411    POLYGON ((-77.53178 38.56506, -77.72094 38.840...\nName: geometry, Length: 1412, dtype: geometry\n\n\n\n\nCode\nsouth_gdf.columns\n\n\nIndex(['NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', 'FIPS', 'STFIPS',\n       'COFIPS', 'FIPSNO', 'SOUTH', 'HR60', 'HR70', 'HR80', 'HR90', 'HC60',\n       'HC70', 'HC80', 'HC90', 'PO60', 'PO70', 'PO80', 'PO90', 'RD60', 'RD70',\n       'RD80', 'RD90', 'PS60', 'PS70', 'PS80', 'PS90', 'UE60', 'UE70', 'UE80',\n       'UE90', 'DV60', 'DV70', 'DV80', 'DV90', 'MA60', 'MA70', 'MA80', 'MA90',\n       'POL60', 'POL70', 'POL80', 'POL90', 'DNL60', 'DNL70', 'DNL80', 'DNL90',\n       'MFIL59', 'MFIL69', 'MFIL79', 'MFIL89', 'FP59', 'FP69', 'FP79', 'FP89',\n       'BLK60', 'BLK70', 'BLK80', 'BLK90', 'GI59', 'GI69', 'GI79', 'GI89',\n       'FH60', 'FH70', 'FH80', 'FH90', 'geometry'],\n      dtype='object')\n\n\n\n\nCode\nsouth_gdf.explore(column='HR60')\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nsouth_gdf.HR60.describe()\n\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64\n\n\n\n\nCode\nax = south_gdf.plot(column='HR60')\nax.set_axis_off();"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#how-many-states-are-there-in-this-dataset",
    "href": "lectures/week04/0221_area_1.html#how-many-states-are-there-in-this-dataset",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.STATE_NAME.unique().shape\n\n\n(17,)"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#how-many-counties",
    "href": "lectures/week04/0221_area_1.html#how-many-counties",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.shape[0]\n\n\n1412"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#how-many-counties-in-each-state",
    "href": "lectures/week04/0221_area_1.html#how-many-counties-in-each-state",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf.groupby(by='STATE_NAME').count()\n\n\n\n\n\n\n\n\n\nNAME\nSTATE_FIPS\nCNTY_FIPS\nFIPS\nSTFIPS\nCOFIPS\nFIPSNO\nSOUTH\nHR60\nHR70\n...\nBLK90\nGI59\nGI69\nGI79\nGI89\nFH60\nFH70\nFH80\nFH90\ngeometry\n\n\nSTATE_NAME\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlabama\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nArkansas\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n...\n75\n75\n75\n75\n75\n75\n75\n75\n75\n75\n\n\nDelaware\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n...\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n\n\nDistrict of Columbia\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n...\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\nFlorida\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n...\n67\n67\n67\n67\n67\n67\n67\n67\n67\n67\n\n\nGeorgia\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n...\n159\n159\n159\n159\n159\n159\n159\n159\n159\n159\n\n\nKentucky\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n...\n120\n120\n120\n120\n120\n120\n120\n120\n120\n120\n\n\nLouisiana\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n...\n64\n64\n64\n64\n64\n64\n64\n64\n64\n64\n\n\nMaryland\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n...\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n\n\nMississippi\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n...\n82\n82\n82\n82\n82\n82\n82\n82\n82\n82\n\n\nNorth Carolina\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n...\n100\n100\n100\n100\n100\n100\n100\n100\n100\n100\n\n\nOklahoma\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n...\n77\n77\n77\n77\n77\n77\n77\n77\n77\n77\n\n\nSouth Carolina\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n...\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n\n\nTennessee\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n...\n95\n95\n95\n95\n95\n95\n95\n95\n95\n95\n\n\nTexas\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n...\n254\n254\n254\n254\n254\n254\n254\n254\n254\n254\n\n\nVirginia\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n...\n123\n123\n123\n123\n123\n123\n123\n123\n123\n123\n\n\nWest Virginia\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n...\n55\n55\n55\n55\n55\n55\n55\n55\n55\n55\n\n\n\n\n17 rows × 69 columns"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#which-county-had-the-highest-median-homicide-rate-in-1960",
    "href": "lectures/week04/0221_area_1.html#which-county-had-the-highest-median-homicide-rate-in-1960",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').median()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n9.623977\n\n\nArkansas\n4.704111\n\n\nDelaware\n4.228385\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n9.970306\n\n\nGeorgia\n9.300076\n\n\nKentucky\n5.235436\n\n\nLouisiana\n6.840286\n\n\nMaryland\n5.335208\n\n\nMississippi\n8.919274\n\n\nNorth Carolina\n7.633043\n\n\nOklahoma\n4.269126\n\n\nSouth Carolina\n7.509437\n\n\nTennessee\n4.877751\n\n\nTexas\n4.326215\n\n\nVirginia\n6.672004\n\n\nWest Virginia\n2.623226"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#which-county-had-the-highest-maximum-homicide-rate-in-1960",
    "href": "lectures/week04/0221_area_1.html#which-county-had-the-highest-maximum-homicide-rate-in-1960",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').max()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n24.903499\n\n\nArkansas\n21.154427\n\n\nDelaware\n7.286472\n\n\nDistrict of Columbia\n10.471807\n\n\nFlorida\n40.744262\n\n\nGeorgia\n53.304904\n\n\nKentucky\n37.250885\n\n\nLouisiana\n18.243736\n\n\nMaryland\n14.327234\n\n\nMississippi\n24.833923\n\n\nNorth Carolina\n25.660127\n\n\nOklahoma\n17.088175\n\n\nSouth Carolina\n23.345940\n\n\nTennessee\n20.894275\n\n\nTexas\n92.936803\n\n\nVirginia\n23.575639\n\n\nWest Virginia\n11.482375"
  },
  {
    "objectID": "lectures/week04/0221_area_1.html#intra-state-dispersion",
    "href": "lectures/week04/0221_area_1.html#intra-state-dispersion",
    "title": "Introduction to Area Unit Data",
    "section": "",
    "text": "Code\nsouth_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nAlabama\n4.742337\n\n\nArkansas\n4.574625\n\n\nDelaware\n1.815562\n\n\nDistrict of Columbia\nNaN\n\n\nFlorida\n7.990692\n\n\nGeorgia\n7.906488\n\n\nKentucky\n6.354316\n\n\nLouisiana\n4.189146\n\n\nMaryland\n4.064360\n\n\nMississippi\n4.972698\n\n\nNorth Carolina\n4.596952\n\n\nOklahoma\n4.231132\n\n\nSouth Carolina\n4.018644\n\n\nTennessee\n4.354979\n\n\nTexas\n8.223844\n\n\nVirginia\n4.826707\n\n\nWest Virginia\n2.773659\n\n\n\n\n\n\n\n\n\nCode\nsgdf = south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').std()\n\n\n\n\nCode\ncv = sgdf / south_gdf[['STATE_NAME', 'HR60']].groupby(by='STATE_NAME').mean() * 100\n\n\n\n\nCode\ncv.sort_values(by='HR60', ascending=False)\n\n\n\n\n\n\n\n\n\nHR60\n\n\nSTATE_NAME\n\n\n\n\n\nTexas\n144.992919\n\n\nKentucky\n96.815524\n\n\nWest Virginia\n93.234007\n\n\nArkansas\n81.223752\n\n\nOklahoma\n81.114430\n\n\nTennessee\n75.426226\n\n\nGeorgia\n73.774440\n\n\nMaryland\n71.898559\n\n\nFlorida\n68.252692\n\n\nVirginia\n66.924041\n\n\nLouisiana\n59.994571\n\n\nMississippi\n57.457024\n\n\nNorth Carolina\n57.013871\n\n\nAlabama\n49.070812\n\n\nSouth Carolina\n48.083524\n\n\nDelaware\n34.966796\n\n\nDistrict of Columbia\nNaN"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#definition-of-spatial-data-analysis",
    "href": "lectures/week01/lecture_sda.html#definition-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-data-analysis-eda",
    "href": "lectures/week01/lecture_sda.html#exploratory-data-analysis-eda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nEDA coined by John Tukey (Tukey 1977)\nSet of statistical tools designed to\n\ndiscover “indications of unexpected phenomena”\n“display the unanticipated”\n“uncover potentially explicable patterns”"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#eda-approach",
    "href": "lectures/week01/lecture_sda.html#eda-approach",
    "title": "Introduction to Spatial Data Analysis",
    "section": "EDA Approach",
    "text": "EDA Approach\n\nAbductive reasoning\nInteraction between data exploration and human perception to\n\ndetect patterns\nformulation of hypotheses"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "href": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nA collection of techniques to describe and visualize spatial distributions, identify atypical locations or spatial outliers, discover patterns of spatial association, clusters or hot spots and suggest spatial regimes or other forms of spatial heterogeneity\n\nAnselin (1999)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "href": "lectures/week01/lecture_sda.html#exploratory-spatial-data-analysis-esda-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Exploratory Spatial Data Analysis (ESDA)",
    "text": "Exploratory Spatial Data Analysis (ESDA)\n\nEDA extended to spatial data\nMaps play a central role, but it doesn’t end with maps\nGeovisualization, geospatial visual analytics\nCombine visualizations with specialized quantitive measures"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#importance-of-spatial-data-analysis",
    "href": "lectures/week01/lecture_sda.html#importance-of-spatial-data-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#historical-context",
    "href": "lectures/week01/lecture_sda.html#historical-context",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#snow-map",
    "href": "lectures/week01/lecture_sda.html#snow-map",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#snow-map-1",
    "href": "lectures/week01/lecture_sda.html#snow-map-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Snow Map",
    "text": "Snow Map\n\n\n\nArribas-Bel, de Graaff, and Rey (2017)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#scope-of-spatial-analysis",
    "href": "lectures/week01/lecture_sda.html#scope-of-spatial-analysis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Scope of Spatial Analysis",
    "text": "Scope of Spatial Analysis\n\n\n\nRey et al. (2022)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#vector-data",
    "href": "lectures/week01/lecture_sda.html#vector-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#vector-data-1",
    "href": "lectures/week01/lecture_sda.html#vector-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#raster-data",
    "href": "lectures/week01/lecture_sda.html#raster-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#raster-data-1",
    "href": "lectures/week01/lecture_sda.html#raster-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Raster Data",
    "text": "Raster Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#attribute-data",
    "href": "lectures/week01/lecture_sda.html#attribute-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#attribute-data-1",
    "href": "lectures/week01/lecture_sda.html#attribute-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatio-temporal-data",
    "href": "lectures/week01/lecture_sda.html#spatio-temporal-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatio-temporal-data-1",
    "href": "lectures/week01/lecture_sda.html#spatio-temporal-data-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatio-Temporal Data",
    "text": "Spatio-Temporal Data\n\n\n\nKnaap et al. (2019)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#remote-sensing",
    "href": "lectures/week01/lecture_sda.html#remote-sensing",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#geographic-information-systems-gis",
    "href": "lectures/week01/lecture_sda.html#geographic-information-systems-gis",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#global-positioning-system-gps",
    "href": "lectures/week01/lecture_sda.html#global-positioning-system-gps",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#crowdsourced-data",
    "href": "lectures/week01/lecture_sda.html#crowdsourced-data",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-autocorrelation",
    "href": "lectures/week01/lecture_sda.html#spatial-autocorrelation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-autocorrelation-1",
    "href": "lectures/week01/lecture_sda.html#spatial-autocorrelation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-scale-and-resolution",
    "href": "lectures/week01/lecture_sda.html#spatial-scale-and-resolution",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "href": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "href": "lectures/week01/lecture_sda.html#modifiable-areal-unit-problem-maup-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-interpolation",
    "href": "lectures/week01/lecture_sda.html#spatial-interpolation",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#spatial-interpolation-1",
    "href": "lectures/week01/lecture_sda.html#spatial-interpolation-1",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#recap-of-key-points",
    "href": "lectures/week01/lecture_sda.html#recap-of-key-points",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nDefinitions of EDA, ESDA\nTypes and Sources of Spatial Data\nKey Concepts in Spatial Data Analysis"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#questions",
    "href": "lectures/week01/lecture_sda.html#questions",
    "title": "Introduction to Spatial Data Analysis",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week01/lecture_sda.html#references",
    "href": "lectures/week01/lecture_sda.html#references",
    "title": "Introduction to Spatial Data Analysis",
    "section": "References",
    "text": "References\n\n\n\n\n\n\n\n\nAnselin, L. 1999. “Interactive Techniques and Exploratory Spatial Data Analysis.” In Geographical Information Systems: Principles, Techniques, Management and Applications, edited by P. A. Longley, M. Goodchild, D. J. Maguire, and D. W. Rhind, 251–64.\n\n\nArribas-Bel, Daniel, Thomas de Graaff, and Sergio J. Rey. 2017. “Looking at John Snow’s Cholera Map from the Twenty First Century: A Practical Primer on Reproducibility and Open Science.” In Regional Research Frontiers - Vol. 2: Methodological Advances, Regional Systems Modeling and Open Sciences, edited by Randall Jackson and Peter Schaeffer, 283–306. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-50590-9_17.\n\n\nKnaap, Elijah, Wei Kang, Sergio Rey, Levi John Wolf, Renan Xavier Cortes, and Su Han. 2019. “Geosnap: The Geospatial Neighborhood Analysis Package.” Zenodo. https://doi.org/10.5281/ZENODO.3526163.\n\n\nRey, Sergio J., Luc Anselin, Pedro Amaral, Dani Arribas-Bel, Renan Xavier Cortes, James David Gaboardi, Wei Kang, et al. 2022. “The PySAL Ecosystem: Philosophy and Implementation.” Geographical Analysis 54 (3): 467–87. https://doi.org/10.1111/gean.12276.\n\n\nTukey, J. W. 1977. Exploratory Data Analysis. New York: Addison-Wesley."
  },
  {
    "objectID": "lectures/week01/index.html",
    "href": "lectures/week01/index.html",
    "title": "Week 1 Lecture: Course Overview",
    "section": "",
    "text": "In this first lecture we will provide an overview of the course.",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/index.html#syllabus",
    "href": "lectures/week01/index.html#syllabus",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Syllabus",
    "text": "Syllabus\nReview Course Syllabus",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week01/index.html#spatial-data-analysis",
    "href": "lectures/week01/index.html#spatial-data-analysis",
    "title": "Week 1 Lecture: Course Overview",
    "section": "Spatial Data Analysis",
    "text": "Spatial Data Analysis\nlecture",
    "crumbs": [
      "Home",
      "08-26 Course Overview"
    ]
  },
  {
    "objectID": "lectures/week05/choro.html#imports",
    "href": "lectures/week05/choro.html#imports",
    "title": "Visualization for Area Unit Data",
    "section": "Imports",
    "text": "Imports\n\nimport geopandas\nimport libpysal"
  },
  {
    "objectID": "lectures/week05/choro.html#example",
    "href": "lectures/week05/choro.html#example",
    "title": "Visualization for Area Unit Data",
    "section": "Example",
    "text": "Example\n\nsouth = libpysal.examples.load_example('South')"
  },
  {
    "objectID": "lectures/week05/choro.html#inspecting-the-example",
    "href": "lectures/week05/choro.html#inspecting-the-example",
    "title": "Visualization for Area Unit Data",
    "section": "Inspecting the example",
    "text": "Inspecting the example\n\nlibpysal.examples.explain('South')"
  },
  {
    "objectID": "lectures/week05/choro.html#reading-the-shapefile",
    "href": "lectures/week05/choro.html#reading-the-shapefile",
    "title": "Visualization for Area Unit Data",
    "section": "Reading the shapefile",
    "text": "Reading the shapefile\n\nsouth_gdf = geopandas.read_file(south.get_path('south.shp'))"
  },
  {
    "objectID": "lectures/week05/choro.html#plotting-the-geometries",
    "href": "lectures/week05/choro.html#plotting-the-geometries",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the Geometries",
    "text": "Plotting the Geometries\n\nsouth_gdf.plot()"
  },
  {
    "objectID": "lectures/week05/choro.html#plotting-the-attribute-distribution",
    "href": "lectures/week05/choro.html#plotting-the-attribute-distribution",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the attribute distribution",
    "text": "Plotting the attribute distribution\n\nimport seaborn"
  },
  {
    "objectID": "lectures/week05/choro.html#plotting-the-attribute-distribution-1",
    "href": "lectures/week05/choro.html#plotting-the-attribute-distribution-1",
    "title": "Visualization for Area Unit Data",
    "section": "Plotting the attribute distribution",
    "text": "Plotting the attribute distribution\n\nseaborn.displot(south_gdf, x='HR60')"
  },
  {
    "objectID": "lectures/week05/choro.html#alternative-view-of-the-attribute-distribution",
    "href": "lectures/week05/choro.html#alternative-view-of-the-attribute-distribution",
    "title": "Visualization for Area Unit Data",
    "section": "Alternative view of the attribute distribution",
    "text": "Alternative view of the attribute distribution\n\nsouth_gdf.HR60.describe()\n\ncount    1412.000000\nmean        7.292144\nstd         6.421018\nmin         0.000000\n25%         3.213471\n50%         6.245125\n75%         9.956272\nmax        92.936803\nName: HR60, dtype: float64"
  },
  {
    "objectID": "lectures/week05/choro.html#spatial-distribution-default-choropleth",
    "href": "lectures/week05/choro.html#spatial-distribution-default-choropleth",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Default Choropleth)",
    "text": "Spatial Distribution (Default Choropleth)\n\nsouth_gdf.plot(column='HR60')"
  },
  {
    "objectID": "lectures/week05/choro.html#spatial-distribution-changing-the-classification",
    "href": "lectures/week05/choro.html#spatial-distribution-changing-the-classification",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Changing the classification)",
    "text": "Spatial Distribution (Changing the classification)\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles')"
  },
  {
    "objectID": "lectures/week05/choro.html#spatial-distribution-adding-a-legend",
    "href": "lectures/week05/choro.html#spatial-distribution-adding-a-legend",
    "title": "Visualization for Area Unit Data",
    "section": "Spatial Distribution (Adding a legend)",
    "text": "Spatial Distribution (Adding a legend)\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True)"
  },
  {
    "objectID": "lectures/week05/choro.html#mapclassify",
    "href": "lectures/week05/choro.html#mapclassify",
    "title": "Visualization for Area Unit Data",
    "section": "Mapclassify",
    "text": "Mapclassify\n\nimport mapclassify"
  },
  {
    "objectID": "lectures/week05/choro.html#quantiles",
    "href": "lectures/week05/choro.html#quantiles",
    "title": "Visualization for Area Unit Data",
    "section": "Quantiles",
    "text": "Quantiles\n\nmapclassify.Quantiles(south_gdf.HR60)\n\nQuantiles\n\n   Interval      Count\n----------------------\n[ 0.00,  2.50] |   283\n( 2.50,  5.10] |   282\n( 5.10,  7.62] |   282\n( 7.62, 10.98] |   282\n(10.98, 92.94] |   283"
  },
  {
    "objectID": "lectures/week05/choro.html#quantiles-changing-the-number-of-classes",
    "href": "lectures/week05/choro.html#quantiles-changing-the-number-of-classes",
    "title": "Visualization for Area Unit Data",
    "section": "Quantiles: Changing the number of classes",
    "text": "Quantiles: Changing the number of classes\n\nmapclassify.Quantiles(south_gdf.HR60, k=10)\n\nQuantiles\n\n   Interval      Count\n----------------------\n[ 0.00,  0.00] |   180\n( 0.00,  2.50] |   103\n( 2.50,  3.93] |   141\n( 3.93,  5.10] |   141\n( 5.10,  6.25] |   141\n( 6.25,  7.62] |   141\n( 7.62,  9.19] |   141\n( 9.19, 10.98] |   141\n(10.98, 14.31] |   141\n(14.31, 92.94] |   142"
  },
  {
    "objectID": "lectures/week05/choro.html#equal-interval",
    "href": "lectures/week05/choro.html#equal-interval",
    "title": "Visualization for Area Unit Data",
    "section": "Equal Interval",
    "text": "Equal Interval\n\nmapclassify.EqualInterval(south_gdf.HR60, k=10)\n\nEqualInterval\n\n   Interval      Count\n----------------------\n[ 0.00,  9.29] |  1000\n( 9.29, 18.59] |   358\n(18.59, 27.88] |    39\n(27.88, 37.17] |     8\n(37.17, 46.47] |     4\n(46.47, 55.76] |     2\n(55.76, 65.06] |     0\n(65.06, 74.35] |     0\n(74.35, 83.64] |     0\n(83.64, 92.94] |     1"
  },
  {
    "objectID": "lectures/week05/choro.html#maximum-breaks",
    "href": "lectures/week05/choro.html#maximum-breaks",
    "title": "Visualization for Area Unit Data",
    "section": "Maximum Breaks",
    "text": "Maximum Breaks\n\nmapclassify.MaximumBreaks(south_gdf.HR60, k=10)\n\nMaximumBreaks\n\n   Interval      Count\n----------------------\n[ 0.00, 29.42] |  1400\n(29.42, 30.74] |     1\n(30.74, 33.40] |     1\n(33.40, 35.94] |     1\n(35.94, 39.00] |     4\n(39.00, 43.29] |     1\n(43.29, 48.96] |     1\n(48.96, 52.69] |     1\n(52.69, 73.12] |     1\n(73.12, 92.94] |     1"
  },
  {
    "objectID": "lectures/week05/choro.html#fisher-jenks",
    "href": "lectures/week05/choro.html#fisher-jenks",
    "title": "Visualization for Area Unit Data",
    "section": "Fisher-Jenks",
    "text": "Fisher-Jenks\n\nmapclassify.FisherJenks(south_gdf.HR60, k=10)\n\nFisherJenks\n\n   Interval      Count\n----------------------\n[ 0.00,  1.71] |   216\n( 1.71,  4.45] |   278\n( 4.45,  7.08] |   287\n( 7.08, 10.02] |   288\n(10.02, 13.59] |   176\n(13.59, 19.60] |   121\n(19.60, 28.77] |    34\n(28.77, 40.74] |     8\n(40.74, 53.30] |     3\n(53.30, 92.94] |     1"
  },
  {
    "objectID": "lectures/week05/choro.html#boxplot",
    "href": "lectures/week05/choro.html#boxplot",
    "title": "Visualization for Area Unit Data",
    "section": "BoxPlot",
    "text": "BoxPlot\n\nmapclassify.BoxPlot(south_gdf.HR60)\n\nBoxPlot\n\n   Interval      Count\n----------------------\n( -inf, -6.90] |     0\n(-6.90,  3.21] |   353\n( 3.21,  6.25] |   353\n( 6.25,  9.96] |   353\n( 9.96, 20.07] |   311\n(20.07, 92.94] |    42"
  },
  {
    "objectID": "lectures/week05/choro.html#head-tail",
    "href": "lectures/week05/choro.html#head-tail",
    "title": "Visualization for Area Unit Data",
    "section": "Head Tail",
    "text": "Head Tail\n\nmapclassify.HeadTailBreaks(south_gdf.HR60)\n\nHeadTailBreaks\n\n   Interval      Count\n----------------------\n[ 0.00,  7.29] |   802\n( 7.29, 12.41] |   405\n(12.41, 18.18] |   147\n(18.18, 26.87] |    40\n(26.87, 38.73] |    13\n(38.73, 56.98] |     4\n(56.98, 92.94] |     1"
  },
  {
    "objectID": "lectures/week05/choro.html#customization",
    "href": "lectures/week05/choro.html#customization",
    "title": "Visualization for Area Unit Data",
    "section": "Customization",
    "text": "Customization\n\nLegends\nColor Schemes"
  },
  {
    "objectID": "lectures/week05/choro.html#legends",
    "href": "lectures/week05/choro.html#legends",
    "title": "Visualization for Area Unit Data",
    "section": "Legends",
    "text": "Legends\n\nsouth_gdf[['STATE_NAME', 'HR60', 'HR90']].head()\n\n\n\n\n\n\n\n\nSTATE_NAME\nHR60\nHR90\n\n\n\n\n0\nWest Virginia\n1.682864\n0.946083\n\n\n1\nWest Virginia\n4.607233\n1.234934\n\n\n2\nWest Virginia\n0.974132\n2.621009\n\n\n3\nWest Virginia\n0.876248\n4.461577\n\n\n4\nDelaware\n4.228385\n6.712736"
  },
  {
    "objectID": "lectures/week05/choro.html#create-a-boolean-variable",
    "href": "lectures/week05/choro.html#create-a-boolean-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Create a Boolean variable",
    "text": "Create a Boolean variable\n\nsouth_gdf['increased' ] =  south_gdf.HR90 &gt; south_gdf.HR60"
  },
  {
    "objectID": "lectures/week05/choro.html#mapping-the-boolean-variable",
    "href": "lectures/week05/choro.html#mapping-the-boolean-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Mapping the Boolean variable",
    "text": "Mapping the Boolean variable\n\nsouth_gdf.plot(column='increased', categorical=True, legend=True);"
  },
  {
    "objectID": "lectures/week05/choro.html#change-the-values",
    "href": "lectures/week05/choro.html#change-the-values",
    "title": "Visualization for Area Unit Data",
    "section": "Change the values",
    "text": "Change the values\n\nv = south_gdf.increased.map({True: 'Increased', False: 'Decreased'})\nsouth_gdf['Increased'] = v"
  },
  {
    "objectID": "lectures/week05/choro.html#map-the-new-variable",
    "href": "lectures/week05/choro.html#map-the-new-variable",
    "title": "Visualization for Area Unit Data",
    "section": "Map the new variable",
    "text": "Map the new variable\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True);"
  },
  {
    "objectID": "lectures/week05/choro.html#legend-positioning",
    "href": "lectures/week05/choro.html#legend-positioning",
    "title": "Visualization for Area Unit Data",
    "section": "Legend Positioning",
    "text": "Legend Positioning\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (1.3, 1)});"
  },
  {
    "objectID": "lectures/week05/choro.html#legend-title",
    "href": "lectures/week05/choro.html#legend-title",
    "title": "Visualization for Area Unit Data",
    "section": "Legend Title",
    "text": "Legend Title\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (1.3, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );"
  },
  {
    "objectID": "lectures/week05/choro.html#more-adjustments",
    "href": "lectures/week05/choro.html#more-adjustments",
    "title": "Visualization for Area Unit Data",
    "section": "More Adjustments",
    "text": "More Adjustments\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );"
  },
  {
    "objectID": "lectures/week05/choro.html#more-adjustments-1",
    "href": "lectures/week05/choro.html#more-adjustments-1",
    "title": "Visualization for Area Unit Data",
    "section": "More Adjustments",
    "text": "More Adjustments\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n           );"
  },
  {
    "objectID": "lectures/week05/choro.html#color-schemes",
    "href": "lectures/week05/choro.html#color-schemes",
    "title": "Visualization for Area Unit Data",
    "section": "Color schemes",
    "text": "Color schemes\n\nmatplotlib (Hunter:2007?)\nColorBrewer (Harrower2003ColorBrewerorg?)"
  },
  {
    "objectID": "lectures/week05/choro.html#sequential-color-schemes",
    "href": "lectures/week05/choro.html#sequential-color-schemes",
    "title": "Visualization for Area Unit Data",
    "section": "Sequential Color Schemes",
    "text": "Sequential Color Schemes\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='Blues');"
  },
  {
    "objectID": "lectures/week05/choro.html#change-the-color-map-single-hue",
    "href": "lectures/week05/choro.html#change-the-color-map-single-hue",
    "title": "Visualization for Area Unit Data",
    "section": "Change the color map: Single Hue",
    "text": "Change the color map: Single Hue\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='Greens');"
  },
  {
    "objectID": "lectures/week05/choro.html#change-the-color-map-multiple-hues",
    "href": "lectures/week05/choro.html#change-the-color-map-multiple-hues",
    "title": "Visualization for Area Unit Data",
    "section": "Change the color map: Multiple Hues",
    "text": "Change the color map: Multiple Hues\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu');"
  },
  {
    "objectID": "lectures/week05/choro.html#diverging-color-map",
    "href": "lectures/week05/choro.html#diverging-color-map",
    "title": "Visualization for Area Unit Data",
    "section": "Diverging Color Map",
    "text": "Diverging Color Map\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n               cmap='coolwarm',\n           );"
  },
  {
    "objectID": "lectures/week05/choro.html#alternative-diverging-color-map",
    "href": "lectures/week05/choro.html#alternative-diverging-color-map",
    "title": "Visualization for Area Unit Data",
    "section": "Alternative Diverging Color Map",
    "text": "Alternative Diverging Color Map\n\nsouth_gdf.plot(column='Increased', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (-0.1, 1),\n                           'title':'Homicide Rates 1960-1990'},\n               cmap='bwr',\n           );"
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme",
    "href": "lectures/week05/choro.html#qualitative-color-scheme",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True)"
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme-1",
    "href": "lectures/week05/choro.html#qualitative-color-scheme-1",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True)"
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme-2",
    "href": "lectures/week05/choro.html#qualitative-color-scheme-2",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1)})"
  },
  {
    "objectID": "lectures/week05/choro.html#qualitative-color-scheme-3",
    "href": "lectures/week05/choro.html#qualitative-color-scheme-3",
    "title": "Visualization for Area Unit Data",
    "section": "Qualitative Color Scheme",
    "text": "Qualitative Color Scheme\n\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nax = fig.add_axes([0, 0, 1, 1])\nax.axis('off')\n\nsouth_gdf.plot(column='STATE_NAME', categorical=True, legend=True,\n               legend_kwds={'bbox_to_anchor': (0, 1)}, ax=ax);"
  },
  {
    "objectID": "lectures/week05/choro.html#comparisons",
    "href": "lectures/week05/choro.html#comparisons",
    "title": "Visualization for Area Unit Data",
    "section": "Comparisons",
    "text": "Comparisons\n\nDeciles\nMaximum Breaks\nFisher Jenks"
  },
  {
    "objectID": "lectures/week05/choro.html#deciles",
    "href": "lectures/week05/choro.html#deciles",
    "title": "Visualization for Area Unit Data",
    "section": "Deciles",
    "text": "Deciles\n\nsouth_gdf.plot(column='HR60', scheme='Quantiles', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);"
  },
  {
    "objectID": "lectures/week05/choro.html#maximum-breaks-1",
    "href": "lectures/week05/choro.html#maximum-breaks-1",
    "title": "Visualization for Area Unit Data",
    "section": "Maximum Breaks",
    "text": "Maximum Breaks\n\nsouth_gdf.plot(column='HR60', scheme='MaximumBreaks', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);"
  },
  {
    "objectID": "lectures/week05/choro.html#fisher-jenks-1",
    "href": "lectures/week05/choro.html#fisher-jenks-1",
    "title": "Visualization for Area Unit Data",
    "section": "Fisher Jenks",
    "text": "Fisher Jenks\n\nsouth_gdf.plot(column='HR60', scheme='FisherJenks', legend=True, \n                legend_kwds={'bbox_to_anchor': (1.3, 1)},\n               cmap='YlGnBu', k=10);"
  },
  {
    "objectID": "lectures/week05/choro.html#statistical-fit",
    "href": "lectures/week05/choro.html#statistical-fit",
    "title": "Visualization for Area Unit Data",
    "section": "Statistical Fit",
    "text": "Statistical Fit\n\ny = south_gdf.HR60\nq10 = mapclassify.Quantiles(y, k=10)\nmb10 = mapclassify.MaximumBreaks(y, k=10)\nfj10 = mapclassify.FisherJenks(y, k=10)\nprint(f'Deciles: {q10.adcm:.1f}, MB: {mb10.adcm:.1f}, FJ: {fj10.adcm:.1f}')\n\nDeciles: 1140.3, MB: 5688.1, FJ: 1027.5"
  },
  {
    "objectID": "lectures/week05/choro.html#section-1",
    "href": "lectures/week05/choro.html#section-1",
    "title": "Visualization for Area Unit Data",
    "section": "",
    "text": "Statistical Fit\n\ny = south_gdf.HR60\nq10 = mapclassify.Quantiles(y, k=10)\nmb10 = mapclassify.MaximumBreaks(y, k=10)\nfj10 = mapclassify.FisherJenks(y, k=10)\nprint(f'Deciles: {q10.adcm:.1f}, MB: {mb10.adcm:.1f}, FJ: {fj10.adcm:.1f}')\n\nDeciles: 1140.3, MB: 5688.1, FJ: 1027.5"
  },
  {
    "objectID": "lectures/week05/choro.html#recap-of-key-points",
    "href": "lectures/week05/choro.html#recap-of-key-points",
    "title": "Visualization for Area Unit Data",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nAreal Unit Data\nChoropleth Mapping\nClassification Schemes\nMap Customization"
  },
  {
    "objectID": "lectures/week05/choro.html#questions",
    "href": "lectures/week05/choro.html#questions",
    "title": "Visualization for Area Unit Data",
    "section": "Questions",
    "text": "Questions"
  },
  {
    "objectID": "lectures/week05/choro.html#references",
    "href": "lectures/week05/choro.html#references",
    "title": "Visualization for Area Unit Data",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "assignments/python_course.html#definition-of-spatial-data-analysis",
    "href": "assignments/python_course.html#definition-of-spatial-data-analysis",
    "title": "Python Primer",
    "section": "Definition of Spatial Data Analysis",
    "text": "Definition of Spatial Data Analysis\n\nSpatial data analysis involves examining locations, attributes, and relationships of features in spatial data using statistical and computational techniques."
  },
  {
    "objectID": "assignments/python_course.html#importance-of-spatial-data-analysis",
    "href": "assignments/python_course.html#importance-of-spatial-data-analysis",
    "title": "Python Primer",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nApplications in various fields: urban planning, environmental science, public health, economics, etc.\nGrowing relevance with the rise of Geographic Information Systems (GIS) and spatial technologies."
  },
  {
    "objectID": "assignments/python_course.html#historical-context",
    "href": "assignments/python_course.html#historical-context",
    "title": "Python Primer",
    "section": "Historical Context",
    "text": "Historical Context\n\nEarly use in geography and epidemiology.\nEvolution with the development of GIS and advanced computational tools."
  },
  {
    "objectID": "assignments/python_course.html#vector-data",
    "href": "assignments/python_course.html#vector-data",
    "title": "Python Primer",
    "section": "Vector Data",
    "text": "Vector Data\n\nDefinition: Represents spatial features using points, lines, and polygons.\nExamples:\n\nPoints: Locations of cities, schools, or hospitals.\nLines: Roads, rivers, or pipelines.\nPolygons: Land parcels, administrative boundaries, or lakes.\n\nApplications: Urban planning, transportation networks, cadastral mapping."
  },
  {
    "objectID": "assignments/python_course.html#vector-data-1",
    "href": "assignments/python_course.html#vector-data-1",
    "title": "Python Primer",
    "section": "Vector Data",
    "text": "Vector Data"
  },
  {
    "objectID": "assignments/python_course.html#raster-data",
    "href": "assignments/python_course.html#raster-data",
    "title": "Python Primer",
    "section": "Raster Data",
    "text": "Raster Data\n\nDefinition: Represents spatial phenomena as a grid of cells or pixels, each with a value representing a specific attribute.\nExamples:\n\nSatellite images, digital elevation models (DEMs), land cover maps.\n\nApplications: Environmental monitoring, remote sensing, agricultural analysis."
  },
  {
    "objectID": "assignments/python_course.html#attribute-data",
    "href": "assignments/python_course.html#attribute-data",
    "title": "Python Primer",
    "section": "Attribute Data",
    "text": "Attribute Data\n\nDefinition: Non-spatial information associated with spatial features.\nExamples:\n\nPopulation data linked to census tracts, land use types associated with parcels.\n\nImportance: Provides context and meaning to spatial locations and features."
  },
  {
    "objectID": "assignments/python_course.html#attribute-data-1",
    "href": "assignments/python_course.html#attribute-data-1",
    "title": "Python Primer",
    "section": "Attribute Data",
    "text": "Attribute Data"
  },
  {
    "objectID": "assignments/python_course.html#temporal-spatial-data",
    "href": "assignments/python_course.html#temporal-spatial-data",
    "title": "Python Primer",
    "section": "Temporal-Spatial Data",
    "text": "Temporal-Spatial Data\n\nDefinition: Spatial data that includes a time component, showing how spatial phenomena change over time.\nExamples:\n\nSpread of diseases, changes in land use, migration patterns.\n\nApplications: Epidemiology, climate change studies, urban development."
  },
  {
    "objectID": "assignments/python_course.html#remote-sensing",
    "href": "assignments/python_course.html#remote-sensing",
    "title": "Python Primer",
    "section": "Remote Sensing",
    "text": "Remote Sensing\n\nDefinition: The process of collecting data about the Earth’s surface from a distance, typically using satellites or aircraft.\nExamples: Landsat, MODIS, LiDAR.\nApplications: Environmental monitoring, disaster management, agricultural assessments."
  },
  {
    "objectID": "assignments/python_course.html#geographic-information-systems-gis",
    "href": "assignments/python_course.html#geographic-information-systems-gis",
    "title": "Python Primer",
    "section": "Geographic Information Systems (GIS)",
    "text": "Geographic Information Systems (GIS)\n\nDefinition: A system designed to capture, store, manipulate, analyze, manage, and present spatial or geographic data.\nComponents: Hardware, software, data, methods, and people.\nApplications: Urban planning, transportation, environmental management."
  },
  {
    "objectID": "assignments/python_course.html#global-positioning-system-gps",
    "href": "assignments/python_course.html#global-positioning-system-gps",
    "title": "Python Primer",
    "section": "Global Positioning System (GPS)",
    "text": "Global Positioning System (GPS)\n\nDefinition: A satellite-based navigation system that provides location and time information.\nApplications: Navigation, mapping, field data collection."
  },
  {
    "objectID": "assignments/python_course.html#crowdsourced-data",
    "href": "assignments/python_course.html#crowdsourced-data",
    "title": "Python Primer",
    "section": "Crowdsourced Data",
    "text": "Crowdsourced Data\n\nDefinition: Data collected from a large number of people, often through mobile devices or online platforms.\nExamples: OpenStreetMap, social media check-ins.\nApplications: Disaster response, urban planning, public health monitoring."
  },
  {
    "objectID": "assignments/python_course.html#spatial-autocorrelation",
    "href": "assignments/python_course.html#spatial-autocorrelation",
    "title": "Python Primer",
    "section": "Spatial Autocorrelation",
    "text": "Spatial Autocorrelation\n\nDefinition: The degree to which objects close to each other in space are also similar in other attributes.\nExamples: Clustered patterns of disease, similar land uses in neighboring areas.\nMeasurement: Moran’s I, Geary’s C."
  },
  {
    "objectID": "assignments/python_course.html#spatial-scale-and-resolution",
    "href": "assignments/python_course.html#spatial-scale-and-resolution",
    "title": "Python Primer",
    "section": "Spatial Scale and Resolution",
    "text": "Spatial Scale and Resolution\n\nDefinition: The level of detail at which spatial data is observed or represented.\nExamples: Global, regional, local scales.\nImplications: Affects the analysis and interpretation of spatial data."
  },
  {
    "objectID": "assignments/python_course.html#modifiable-areal-unit-problem-maup",
    "href": "assignments/python_course.html#modifiable-areal-unit-problem-maup",
    "title": "Python Primer",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)\n\nDefinition: The issue that the results of spatial analysis can vary depending on the spatial units used.\nExamples: Changing the boundaries of districts can change the outcomes of an analysis.\nConsiderations: Important in the design and interpretation of spatial studies."
  },
  {
    "objectID": "assignments/python_course.html#modifiable-areal-unit-problem-maup-1",
    "href": "assignments/python_course.html#modifiable-areal-unit-problem-maup-1",
    "title": "Python Primer",
    "section": "Modifiable Areal Unit Problem (MAUP)",
    "text": "Modifiable Areal Unit Problem (MAUP)"
  },
  {
    "objectID": "assignments/python_course.html#spatial-interpolation",
    "href": "assignments/python_course.html#spatial-interpolation",
    "title": "Python Primer",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation\n\nDefinition: The process of estimating unknown values at certain locations based on known values at other locations.\nExamples: Estimating temperature or pollution levels across a region.\nMethods: Kriging, Inverse Distance Weighting (IDW)."
  },
  {
    "objectID": "assignments/python_course.html#spatial-interpolation-1",
    "href": "assignments/python_course.html#spatial-interpolation-1",
    "title": "Python Primer",
    "section": "Spatial Interpolation",
    "text": "Spatial Interpolation"
  },
  {
    "objectID": "assignments/python_course.html#public-health",
    "href": "assignments/python_course.html#public-health",
    "title": "Python Primer",
    "section": "Public Health",
    "text": "Public Health\n\nTracking disease outbreaks, identifying health disparities."
  },
  {
    "objectID": "assignments/python_course.html#environmental-management",
    "href": "assignments/python_course.html#environmental-management",
    "title": "Python Primer",
    "section": "Environmental Management",
    "text": "Environmental Management\n\nMonitoring deforestation, analyzing pollution patterns."
  },
  {
    "objectID": "assignments/python_course.html#urban-planning",
    "href": "assignments/python_course.html#urban-planning",
    "title": "Python Primer",
    "section": "Urban Planning",
    "text": "Urban Planning\n\nInfrastructure development, zoning, transportation networks."
  },
  {
    "objectID": "assignments/python_course.html#emergency-response",
    "href": "assignments/python_course.html#emergency-response",
    "title": "Python Primer",
    "section": "Emergency Response",
    "text": "Emergency Response\n\nDisaster management, evacuation planning, resource allocation."
  },
  {
    "objectID": "assignments/python_course.html#conclusion-and-qa-3-minutes",
    "href": "assignments/python_course.html#conclusion-and-qa-3-minutes",
    "title": "Python Primer",
    "section": "Conclusion and Q&A (3 minutes)",
    "text": "Conclusion and Q&A (3 minutes)"
  },
  {
    "objectID": "assignments/python_course.html#recap-of-key-points",
    "href": "assignments/python_course.html#recap-of-key-points",
    "title": "Python Primer",
    "section": "Recap of Key Points",
    "text": "Recap of Key Points\n\nOverview of spatial data types, key concepts, and applications."
  },
  {
    "objectID": "assignments/python_course.html#importance-of-spatial-data-analysis-1",
    "href": "assignments/python_course.html#importance-of-spatial-data-analysis-1",
    "title": "Python Primer",
    "section": "Importance of Spatial Data Analysis",
    "text": "Importance of Spatial Data Analysis\n\nEmphasis on its growing relevance in various fields."
  },
  {
    "objectID": "assignments/python_course.html#open-floor-for-questions",
    "href": "assignments/python_course.html#open-floor-for-questions",
    "title": "Python Primer",
    "section": "Open Floor for Questions",
    "text": "Open Floor for Questions\n\nEncourage students to ask questions or discuss topics of interest."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Geography 385 Spatial Data Analysis is an introduction to exploratory spatial data analysis taught by Professor Sergio Rey at San Diego State University."
  }
]